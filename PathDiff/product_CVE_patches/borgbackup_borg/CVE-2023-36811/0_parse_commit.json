{
    "current_hash": "3eb070191da10c2d3f7bc6484cf3d51c3045f884",
    "parent_hash": "6aa350aeb46ccaf2ce9f4a16a84e08614e02eec0",
    "modified_file_0": {
        "mod_filename": "docs/changes_1.x.rst",
        "status": "modified",
        "add_lines": 68,
        "dele_lines": 0,
        "patch": "@@ -5,6 +5,74 @@ Important notes 1.x\n \n This section provides information about security and corruption issues.\n \n+.. _archives_tam_vuln:\n+\n+Pre-1.2.5 archives spoofing vulnerability (CVE-2023-36811)\n+----------------------------------------------------------\n+\n+A flaw in the cryptographic authentication scheme in Borg allowed an attacker to\n+fake archives and potentially indirectly cause backup data loss in the repository.\n+\n+The attack requires an attacker to be able to\n+\n+1. insert files (with no additional headers) into backups\n+2. gain write access to the repository\n+\n+This vulnerability does not disclose plaintext to the attacker, nor does it\n+affect the authenticity of existing archives.\n+\n+Creating plausible fake archives may be feasible for empty or small archives,\n+but is unlikely for large archives.\n+\n+The fix enforces checking the TAM authentication tag of archives at critical\n+places. Borg now considers archives without TAM as garbage or an attack.\n+\n+We are not aware of others having discovered, disclosed or exploited this vulnerability.\n+\n+Below, if we speak of borg 1.2.5, we mean a borg version >= 1.2.5 **or** a\n+borg version that has the relevant security patches for this vulnerability applied\n+(could be also an older version in that case).\n+\n+Steps you must take to upgrade a repository:\n+\n+1. Upgrade all clients using this repository to borg 1.2.5.\n+   Note: it is not required to upgrade a server, except if the server-side borg\n+   is also used as a client (and not just for \"borg serve\").\n+\n+   Do **not** run ``borg check`` with borg 1.2.5 before completing the upgrade steps.\n+\n+2. Run ``borg info --debug <repository> 2>&1 | grep TAM | grep -i manifest``.\n+\n+   a) If you get \"TAM-verified manifest\", continue with 3.\n+   b) If you get \"Manifest TAM not found and not required\", run\n+      ``borg upgrade --tam --force <repository>`` *on every client*.\n+\n+3. Run ``borg list --format='{name} {time} tam:{tam}{NL}' <repository>``.\n+   \"tam:verified\" means that the archive has a valid TAM authentication.\n+   \"tam:none\" is expected as output for archives created by borg <1.0.9.\n+   \"tam:none\" could also come from archives created by an attacker.\n+   You should verify that \"tam:none\" archives are authentic and not malicious\n+   (== have good content, have correct timestamp, can be extracted successfully).\n+   In case you find crappy/malicious archives, you must delete them before proceeding.\n+   In low-risk, trusted environments, you may decide on your own risk to skip step 3\n+   and just trust in everything being OK.\n+\n+4. If there are no tam:non archives left at this point, you can skip this step.\n+   Run ``borg upgrade --archives-tam <repository>``.\n+   This will make sure all archives are TAM authenticated (an archive TAM will be added\n+   for all archives still missing one).\n+   ``borg check`` would consider TAM-less archives as garbage or a potential attack.\n+   Optionally run the same command as in step 3 to see that all archives now are \"tam:verified\".\n+\n+\n+Vulnerability time line:\n+\n+* 2023-06-13: Vulnerability discovered during code review by Thomas Waldmann\n+* 2023-06-13...: Work on fixing the issue, upgrade procedure, docs.\n+* 2023-06-30: CVE was assigned via Github CNA\n+* 2023-06-30 .. 2023-08-29: Fixed issue, code review, docs, testing.\n+* 2023-08-30: Released fixed version 1.2.5\n+\n .. _hashindex_set_bug:\n \n Pre-1.1.11 potential index corruption / data loss issue"
    },
    "modified_file_1": {
        "mod_filename": "src/borg/archive.py",
        "status": "modified",
        "add_lines": 30,
        "dele_lines": 4,
        "patch": "@@ -493,6 +493,7 @@ def __init__(\n         self.name = name  # overwritten later with name from archive metadata\n         self.name_in_manifest = name  # can differ from .name later (if borg check fixed duplicate archive names)\n         self.comment = None\n+        self.tam_verified = False\n         self.numeric_ids = numeric_ids\n         self.noatime = noatime\n         self.noctime = noctime\n@@ -532,7 +533,9 @@ def __init__(\n     def _load_meta(self, id):\n         cdata = self.repository.get(id)\n         _, data = self.repo_objs.parse(id, cdata)\n-        metadata = ArchiveItem(internal_dict=msgpack.unpackb(data))\n+        # we do not require TAM for archives, otherwise we can not even borg list a repo with old archives.\n+        archive, self.tam_verified, _ = self.key.unpack_and_verify_archive(data, force_tam_not_required=True)\n+        metadata = ArchiveItem(internal_dict=archive)\n         if metadata.version not in (1, 2):  # legacy: still need to read v1 archives\n             raise Exception(\"Unknown archive metadata version\")\n         # note: metadata.items must not get written to disk!\n@@ -1024,7 +1027,7 @@ def set_meta(self, key, value):\n         setattr(metadata, key, value)\n         if \"items\" in metadata:\n             del metadata.items\n-        data = msgpack.packb(metadata.as_dict())\n+        data = self.key.pack_and_authenticate_metadata(metadata.as_dict(), context=b\"archive\")\n         new_id = self.key.id_hash(data)\n         self.cache.add_chunk(new_id, {}, data, stats=self.stats)\n         self.manifest.archives[self.name] = (new_id, metadata.time)\n@@ -1992,6 +1995,19 @@ def valid_archive(obj):\n             except msgpack.UnpackException:\n                 continue\n             if valid_archive(archive):\n+                # **after** doing the low-level checks and having a strong indication that we\n+                # are likely looking at an archive item here, also check the TAM authentication:\n+                try:\n+                    archive, verified, _ = self.key.unpack_and_verify_archive(data, force_tam_not_required=False)\n+                except IntegrityError:\n+                    # TAM issues - do not accept this archive!\n+                    # either somebody is trying to attack us with a fake archive data or\n+                    # we have an ancient archive made before TAM was a thing (borg < 1.0.9) **and** this repo\n+                    # was not correctly upgraded to borg 1.2.5 (see advisory at top of the changelog).\n+                    # borg can't tell the difference, so it has to assume this archive might be an attack\n+                    # and drops this archive.\n+                    continue\n+                # note: if we get here and verified is False, a TAM is not required.\n                 archive = ArchiveItem(internal_dict=archive)\n                 name = archive.name\n                 logger.info(\"Found archive %s\", name)\n@@ -2248,7 +2264,17 @@ def valid_item(obj):\n                     self.error_found = True\n                     del self.manifest.archives[info.name]\n                     continue\n-                archive = ArchiveItem(internal_dict=msgpack.unpackb(data))\n+                try:\n+                    archive, verified, salt = self.key.unpack_and_verify_archive(data, force_tam_not_required=False)\n+                except IntegrityError as integrity_error:\n+                    # looks like there is a TAM issue with this archive, this might be an attack!\n+                    # when upgrading to borg 1.2.5, users are expected to TAM-authenticate all archives they\n+                    # trust, so there shouldn't be any without TAM.\n+                    logger.error(\"Archive TAM authentication issue for archive %s: %s\", info.name, integrity_error)\n+                    self.error_found = True\n+                    del self.manifest.archives[info.name]\n+                    continue\n+                archive = ArchiveItem(internal_dict=archive)\n                 if archive.version != 2:\n                     raise Exception(\"Unknown archive metadata version\")\n                 items_buffer = ChunkBuffer(self.key)\n@@ -2267,7 +2293,7 @@ def valid_item(obj):\n                 archive.item_ptrs = archive_put_items(\n                     items_buffer.chunks, repo_objs=self.repo_objs, add_reference=add_reference\n                 )\n-                data = msgpack.packb(archive.as_dict())\n+                data = self.key.pack_and_authenticate_metadata(archive.as_dict(), context=b\"archive\", salt=salt)\n                 new_archive_id = self.key.id_hash(data)\n                 cdata = self.repo_objs.format(new_archive_id, {}, data)\n                 add_reference(new_archive_id, len(data), cdata)"
    },
    "modified_file_2": {
        "mod_filename": "src/borg/cache.py",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 1,
        "patch": "@@ -755,7 +755,8 @@ def fetch_and_build_idx(archive_id, decrypted_repository, chunk_idx):\n             nonlocal processed_item_metadata_chunks\n             csize, data = decrypted_repository.get(archive_id)\n             chunk_idx.add(archive_id, 1, len(data))\n-            archive = ArchiveItem(internal_dict=msgpack.unpackb(data))\n+            archive, verified, _ = self.key.unpack_and_verify_archive(data, force_tam_not_required=True)\n+            archive = ArchiveItem(internal_dict=archive)\n             if archive.version not in (1, 2):  # legacy\n                 raise Exception(\"Unknown archive metadata version\")\n             if archive.version == 1:"
    },
    "modified_file_3": {
        "mod_filename": "src/borg/crypto/key.py",
        "status": "modified",
        "add_lines": 73,
        "dele_lines": 5,
        "patch": "@@ -72,6 +72,15 @@ class TAMRequiredError(IntegrityError):\n     traceback = False\n \n \n+class ArchiveTAMRequiredError(TAMRequiredError):\n+    __doc__ = textwrap.dedent(\n+        \"\"\"\n+    Archive '{}' is unauthenticated, but it is required for this repository.\n+    \"\"\"\n+    ).strip()\n+    traceback = False\n+\n+\n class TAMInvalid(IntegrityError):\n     __doc__ = IntegrityError.__doc__\n     traceback = False\n@@ -81,6 +90,15 @@ def __init__(self):\n         super().__init__(\"Manifest authentication did not verify\")\n \n \n+class ArchiveTAMInvalid(IntegrityError):\n+    __doc__ = IntegrityError.__doc__\n+    traceback = False\n+\n+    def __init__(self):\n+        # Error message becomes: \"Data integrity error: Archive authentication did not verify\"\n+        super().__init__(\"Archive authentication did not verify\")\n+\n+\n class TAMUnsupportedSuiteError(IntegrityError):\n     \"\"\"Could not verify manifest: Unsupported suite {!r}; a newer version is needed.\"\"\"\n \n@@ -225,11 +243,13 @@ def _tam_key(self, salt, context):\n             output_length=64,\n         )\n \n-    def pack_and_authenticate_metadata(self, metadata_dict, context=b\"manifest\"):\n+    def pack_and_authenticate_metadata(self, metadata_dict, context=b\"manifest\", salt=None):\n+        if salt is None:\n+            salt = os.urandom(64)\n         metadata_dict = StableDict(metadata_dict)\n-        tam = metadata_dict[\"tam\"] = StableDict({\"type\": \"HKDF_HMAC_SHA512\", \"hmac\": bytes(64), \"salt\": os.urandom(64)})\n+        tam = metadata_dict[\"tam\"] = StableDict({\"type\": \"HKDF_HMAC_SHA512\", \"hmac\": bytes(64), \"salt\": salt})\n         packed = msgpack.packb(metadata_dict)\n-        tam_key = self._tam_key(tam[\"salt\"], context)\n+        tam_key = self._tam_key(salt, context)\n         tam[\"hmac\"] = hmac.digest(tam_key, packed, \"sha512\")\n         return msgpack.packb(metadata_dict)\n \n@@ -252,7 +272,7 @@ def unpack_and_verify_manifest(self, data, force_tam_not_required=False):\n             if tam_required:\n                 raise TAMRequiredError(self.repository._location.canonical_path())\n             else:\n-                logger.debug(\"TAM not found and not required\")\n+                logger.debug(\"Manifest TAM not found and not required\")\n                 return unpacked, False\n         tam = unpacked.pop(\"tam\", None)\n         if not isinstance(tam, dict):\n@@ -262,7 +282,9 @@ def unpack_and_verify_manifest(self, data, force_tam_not_required=False):\n             if tam_required:\n                 raise TAMUnsupportedSuiteError(repr(tam_type))\n             else:\n-                logger.debug(\"Ignoring TAM made with unsupported suite, since TAM is not required: %r\", tam_type)\n+                logger.debug(\n+                    \"Ignoring manifest TAM made with unsupported suite, since TAM is not required: %r\", tam_type\n+                )\n                 return unpacked, False\n         tam_hmac = tam.get(\"hmac\")\n         tam_salt = tam.get(\"salt\")\n@@ -279,6 +301,52 @@ def unpack_and_verify_manifest(self, data, force_tam_not_required=False):\n         logger.debug(\"TAM-verified manifest\")\n         return unpacked, True\n \n+    def unpack_and_verify_archive(self, data, force_tam_not_required=False):\n+        \"\"\"Unpack msgpacked *data* and return (object, did_verify).\"\"\"\n+        tam_required = self.tam_required\n+        if force_tam_not_required and tam_required:\n+            # for a long time, borg only checked manifest for \"tam_required\" and\n+            # people might have archives without TAM, so don't be too annoyingly loud here:\n+            logger.debug(\"Archive authentication DISABLED.\")\n+            tam_required = False\n+        data = bytearray(data)\n+        unpacker = get_limited_unpacker(\"archive\")\n+        unpacker.feed(data)\n+        unpacked = unpacker.unpack()\n+        if \"tam\" not in unpacked:\n+            if tam_required:\n+                archive_name = unpacked.get(\"name\", \"<unknown>\")\n+                raise ArchiveTAMRequiredError(archive_name)\n+            else:\n+                logger.debug(\"Archive TAM not found and not required\")\n+                return unpacked, False, None\n+        tam = unpacked.pop(\"tam\", None)\n+        if not isinstance(tam, dict):\n+            raise ArchiveTAMInvalid()\n+        tam_type = tam.get(\"type\", \"<none>\")\n+        if tam_type != \"HKDF_HMAC_SHA512\":\n+            if tam_required:\n+                raise TAMUnsupportedSuiteError(repr(tam_type))\n+            else:\n+                logger.debug(\n+                    \"Ignoring archive TAM made with unsupported suite, since TAM is not required: %r\", tam_type\n+                )\n+                return unpacked, False, None\n+        tam_hmac = tam.get(\"hmac\")\n+        tam_salt = tam.get(\"salt\")\n+        if not isinstance(tam_salt, (bytes, str)) or not isinstance(tam_hmac, (bytes, str)):\n+            raise ArchiveTAMInvalid()\n+        tam_hmac = want_bytes(tam_hmac)  # legacy\n+        tam_salt = want_bytes(tam_salt)  # legacy\n+        offset = data.index(tam_hmac)\n+        data[offset : offset + 64] = bytes(64)\n+        tam_key = self._tam_key(tam_salt, context=b\"archive\")\n+        calculated_hmac = hmac.digest(tam_key, data, \"sha512\")\n+        if not hmac.compare_digest(calculated_hmac, tam_hmac):\n+            raise ArchiveTAMInvalid()\n+        logger.debug(\"TAM-verified archive\")\n+        return unpacked, True, tam_salt\n+\n \n class PlaintextKey(KeyBase):\n     TYPE = KeyType.PLAINTEXT"
    },
    "modified_file_4": {
        "mod_filename": "src/borg/helpers/msgpack.py",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 2,
        "patch": "@@ -219,10 +219,10 @@ def get_limited_unpacker(kind):\n     args = dict(use_list=False, max_buffer_size=3 * max(BUFSIZE, MAX_OBJECT_SIZE))  # return tuples, not lists\n     if kind in (\"server\", \"client\"):\n         pass  # nothing special\n-    elif kind in (\"manifest\", \"key\"):\n+    elif kind in (\"manifest\", \"archive\", \"key\"):\n         args.update(dict(use_list=True, object_hook=StableDict))  # default value\n     else:\n-        raise ValueError('kind must be \"server\", \"client\", \"manifest\" or \"key\"')\n+        raise ValueError('kind must be \"server\", \"client\", \"manifest\", \"archive\" or \"key\"')\n     return Unpacker(**args)\n \n "
    },
    "modified_file_5": {
        "mod_filename": "src/borg/helpers/parseformat.py",
        "status": "modified",
        "add_lines": 6,
        "dele_lines": 1,
        "patch": "@@ -723,11 +723,12 @@ class ArchiveFormatter(BaseFormatter):\n         \"id\": \"internal ID of the archive\",\n         \"hostname\": \"hostname of host on which this archive was created\",\n         \"username\": \"username of user who created this archive\",\n+        \"tam\": \"TAM authentication state of this archive\",\n         \"size\": \"size of this archive (data plus metadata, not considering compression and deduplication)\",\n         \"nfiles\": \"count of files in this archive\",\n     }\n     KEY_GROUPS = (\n-        (\"archive\", \"name\", \"comment\", \"id\"),\n+        (\"archive\", \"name\", \"comment\", \"id\", \"tam\"),\n         (\"start\", \"time\", \"end\", \"command_line\"),\n         (\"hostname\", \"username\"),\n         (\"size\", \"nfiles\"),\n@@ -750,6 +751,7 @@ def __init__(self, format, repository, manifest, key, *, iec=False):\n             \"username\": partial(self.get_meta, \"username\", \"\"),\n             \"comment\": partial(self.get_meta, \"comment\", \"\"),\n             \"command_line\": partial(self.get_meta, \"command_line\", \"\"),\n+            \"tam\": self.get_tam,\n             \"size\": partial(self.get_meta, \"size\", 0),\n             \"nfiles\": partial(self.get_meta, \"nfiles\", 0),\n             \"end\": self.get_ts_end,\n@@ -795,6 +797,9 @@ def get_meta(self, key, default=None):\n     def get_ts_end(self):\n         return self.format_time(self.archive.ts_end)\n \n+    def get_tam(self):\n+        return \"verified\" if self.archive.tam_verified else \"none\"\n+\n     def format_time(self, ts):\n         return OutputTimestamp(ts)\n "
    },
    "modified_file_6": {
        "mod_filename": "src/borg/testsuite/archiver/check_cmd.py",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 12,
        "patch": "@@ -6,7 +6,6 @@\n from ...archive import ChunkBuffer\n from ...constants import *  # NOQA\n from ...helpers import bin_to_hex\n-from ...helpers import msgpack\n from ...manifest import Manifest\n from ...repository import Repository\n from . import cmd, src_file, create_src_archive, open_archive, generate_archiver_tests, RK_ENCRYPTION\n@@ -233,17 +232,16 @@ def test_manifest_rebuild_duplicate_archive(archivers, request):\n         manifest = repository.get(Manifest.MANIFEST_ID)\n         corrupted_manifest = manifest + b\"corrupted!\"\n         repository.put(Manifest.MANIFEST_ID, corrupted_manifest)\n-        archive = msgpack.packb(\n-            {\n-                \"command_line\": \"\",\n-                \"item_ptrs\": [],\n-                \"hostname\": \"foo\",\n-                \"username\": \"bar\",\n-                \"name\": \"archive1\",\n-                \"time\": \"2016-12-15T18:49:51.849711\",\n-                \"version\": 2,\n-            }\n-        )\n+        archive_dict = {\n+            \"command_line\": \"\",\n+            \"item_ptrs\": [],\n+            \"hostname\": \"foo\",\n+            \"username\": \"bar\",\n+            \"name\": \"archive1\",\n+            \"time\": \"2016-12-15T18:49:51.849711\",\n+            \"version\": 2,\n+        }\n+        archive = repo_objs.key.pack_and_authenticate_metadata(archive_dict, context=b\"archive\")\n         archive_id = repo_objs.id_hash(archive)\n         repository.put(archive_id, repo_objs.format(archive_id, {}, archive))\n         repository.commit(compact=False)"
    },
    "modified_file_7": {
        "mod_filename": "src/borg/testsuite/archiver/checks.py",
        "status": "modified",
        "add_lines": 58,
        "dele_lines": 2,
        "patch": "@@ -8,7 +8,7 @@\n from ...cache import Cache, LocalCache\n from ...constants import *  # NOQA\n from ...crypto.key import TAMRequiredError\n-from ...helpers import Location, get_security_dir, bin_to_hex\n+from ...helpers import Location, get_security_dir, bin_to_hex, archive_ts_now\n from ...helpers import EXIT_ERROR\n from ...helpers import msgpack\n from ...manifest import Manifest, MandatoryFeatureUnsupported\n@@ -322,7 +322,7 @@ def test_check_cache(archivers, request):\n         check_cache(archiver)\n \n \n-#  Begin manifest tests\n+#  Begin manifest TAM tests\n def spoof_manifest(repository):\n     with repository:\n         manifest = Manifest.load(repository, Manifest.NO_OPERATION_CHECK)\n@@ -380,6 +380,62 @@ def test_not_required(archiver):\n         cmd(archiver, \"rlist\")\n \n \n+#  Begin archive TAM tests\n+def write_archive_without_tam(repository, archive_name):\n+    manifest = Manifest.load(repository, Manifest.NO_OPERATION_CHECK)\n+    archive_data = msgpack.packb(\n+        {\n+            \"version\": 2,\n+            \"name\": archive_name,\n+            \"item_ptrs\": [],\n+            \"command_line\": \"\",\n+            \"hostname\": \"\",\n+            \"username\": \"\",\n+            \"time\": archive_ts_now().isoformat(timespec=\"microseconds\"),\n+            \"size\": 0,\n+            \"nfiles\": 0,\n+        }\n+    )\n+    archive_id = manifest.repo_objs.id_hash(archive_data)\n+    cdata = manifest.repo_objs.format(archive_id, {}, archive_data)\n+    repository.put(archive_id, cdata)\n+    manifest.archives[archive_name] = (archive_id, datetime.now())\n+    manifest.write()\n+    repository.commit(compact=False)\n+\n+\n+def test_check_rebuild_manifest(archiver):\n+    cmd(archiver, \"rcreate\", RK_ENCRYPTION)\n+    create_src_archive(archiver, \"archive_tam\")\n+    repository = Repository(archiver.repository_path, exclusive=True)\n+    with repository:\n+        write_archive_without_tam(repository, \"archive_no_tam\")\n+        repository.delete(Manifest.MANIFEST_ID)  # kill manifest, so check has to rebuild it\n+        repository.commit(compact=False)\n+    cmd(archiver, \"check\", \"--repair\")\n+    output = cmd(archiver, \"rlist\", \"--format='{name} tam:{tam}{NL}'\")\n+    assert \"archive_tam tam:verified\" in output  # TAM-verified archive is in rebuilt manifest\n+    assert \"archive_no_tam\" not in output  # check got rid of untrusted not TAM-verified archive\n+\n+\n+def test_check_rebuild_refcounts(archiver):\n+    cmd(archiver, \"rcreate\", RK_ENCRYPTION)\n+    create_src_archive(archiver, \"archive_tam\")\n+    archive_id_pre_check = cmd(archiver, \"rlist\", \"--format='{name} {id}{NL}'\")\n+    repository = Repository(archiver.repository_path, exclusive=True)\n+    with repository:\n+        write_archive_without_tam(repository, \"archive_no_tam\")\n+    output = cmd(archiver, \"rlist\", \"--format='{name} tam:{tam}{NL}'\")\n+    assert \"archive_tam tam:verified\" in output  # good\n+    assert \"archive_no_tam tam:none\" in output  # could be borg < 1.0.9 archive or fake\n+    cmd(archiver, \"check\", \"--repair\")\n+    output = cmd(archiver, \"rlist\", \"--format='{name} tam:{tam}{NL}'\")\n+    assert \"archive_tam tam:verified\" in output  # TAM-verified archive still there\n+    assert \"archive_no_tam\" not in output  # check got rid of untrusted not TAM-verified archive\n+    archive_id_post_check = cmd(archiver, \"rlist\", \"--format='{name} {id}{NL}'\")\n+    assert archive_id_post_check == archive_id_pre_check  # rebuild_refcounts didn't change archive_tam archive id\n+\n+\n # Begin Remote Tests\n def test_remote_repo_restrict_to_path(remote_archiver):\n     original_location, repo_path = remote_archiver.repository_location, remote_archiver.repository_path"
    },
    "modified_file_8": {
        "mod_filename": "src/borg/testsuite/key.py",
        "status": "modified",
        "add_lines": 61,
        "dele_lines": 12,
        "patch": "@@ -11,13 +11,8 @@\n from ..crypto.key import AESOCBRepoKey, AESOCBKeyfileKey, CHPORepoKey, CHPOKeyfileKey\n from ..crypto.key import Blake2AESOCBRepoKey, Blake2AESOCBKeyfileKey, Blake2CHPORepoKey, Blake2CHPOKeyfileKey\n from ..crypto.key import ID_HMAC_SHA_256, ID_BLAKE2b_256\n-from ..crypto.key import (\n-    TAMRequiredError,\n-    TAMInvalid,\n-    TAMUnsupportedSuiteError,\n-    UnsupportedManifestError,\n-    UnsupportedKeyFormatError,\n-)\n+from ..crypto.key import TAMRequiredError, TAMInvalid, TAMUnsupportedSuiteError, ArchiveTAMInvalid\n+from ..crypto.key import UnsupportedManifestError, UnsupportedKeyFormatError\n from ..crypto.key import identify_key\n from ..crypto.low_level import IntegrityError as IntegrityErrorBase\n from ..helpers import IntegrityError\n@@ -281,25 +276,35 @@ def test_missing_when_required(self, key):\n         blob = msgpack.packb({})\n         with pytest.raises(TAMRequiredError):\n             key.unpack_and_verify_manifest(blob)\n+        with pytest.raises(TAMRequiredError):\n+            key.unpack_and_verify_archive(blob)\n \n     def test_missing(self, key):\n         blob = msgpack.packb({})\n         key.tam_required = False\n         unpacked, verified = key.unpack_and_verify_manifest(blob)\n         assert unpacked == {}\n         assert not verified\n+        unpacked, verified, _ = key.unpack_and_verify_archive(blob)\n+        assert unpacked == {}\n+        assert not verified\n \n     def test_unknown_type_when_required(self, key):\n         blob = msgpack.packb({\"tam\": {\"type\": \"HMAC_VOLLBIT\"}})\n         with pytest.raises(TAMUnsupportedSuiteError):\n             key.unpack_and_verify_manifest(blob)\n+        with pytest.raises(TAMUnsupportedSuiteError):\n+            key.unpack_and_verify_archive(blob)\n \n     def test_unknown_type(self, key):\n         blob = msgpack.packb({\"tam\": {\"type\": \"HMAC_VOLLBIT\"}})\n         key.tam_required = False\n         unpacked, verified = key.unpack_and_verify_manifest(blob)\n         assert unpacked == {}\n         assert not verified\n+        unpacked, verified, _ = key.unpack_and_verify_archive(blob)\n+        assert unpacked == {}\n+        assert not verified\n \n     @pytest.mark.parametrize(\n         \"tam, exc\",\n@@ -310,11 +315,25 @@ def test_unknown_type(self, key):\n             (1234, TAMInvalid),\n         ),\n     )\n-    def test_invalid(self, key, tam, exc):\n+    def test_invalid_manifest(self, key, tam, exc):\n         blob = msgpack.packb({\"tam\": tam})\n         with pytest.raises(exc):\n             key.unpack_and_verify_manifest(blob)\n \n+    @pytest.mark.parametrize(\n+        \"tam, exc\",\n+        (\n+            ({}, TAMUnsupportedSuiteError),\n+            ({\"type\": b\"\\xff\"}, TAMUnsupportedSuiteError),\n+            (None, ArchiveTAMInvalid),\n+            (1234, ArchiveTAMInvalid),\n+        ),\n+    )\n+    def test_invalid_archive(self, key, tam, exc):\n+        blob = msgpack.packb({\"tam\": tam})\n+        with pytest.raises(exc):\n+            key.unpack_and_verify_archive(blob)\n+\n     @pytest.mark.parametrize(\n         \"hmac, salt\",\n         (({}, bytes(64)), (bytes(64), {}), (None, bytes(64)), (bytes(64), None)),\n@@ -330,10 +349,12 @@ def test_wrong_types(self, key, hmac, salt):\n         blob = msgpack.packb(data)\n         with pytest.raises(TAMInvalid):\n             key.unpack_and_verify_manifest(blob)\n+        with pytest.raises(ArchiveTAMInvalid):\n+            key.unpack_and_verify_archive(blob)\n \n-    def test_round_trip(self, key):\n+    def test_round_trip_manifest(self, key):\n         data = {\"foo\": \"bar\"}\n-        blob = key.pack_and_authenticate_metadata(data)\n+        blob = key.pack_and_authenticate_metadata(data, context=b\"manifest\")\n         assert blob.startswith(b\"\\x82\")\n \n         unpacked = msgpack.unpackb(blob)\n@@ -344,10 +365,23 @@ def test_round_trip(self, key):\n         assert unpacked[\"foo\"] == \"bar\"\n         assert \"tam\" not in unpacked\n \n+    def test_round_trip_archive(self, key):\n+        data = {\"foo\": \"bar\"}\n+        blob = key.pack_and_authenticate_metadata(data, context=b\"archive\")\n+        assert blob.startswith(b\"\\x82\")\n+\n+        unpacked = msgpack.unpackb(blob)\n+        assert unpacked[\"tam\"][\"type\"] == \"HKDF_HMAC_SHA512\"\n+\n+        unpacked, verified, _ = key.unpack_and_verify_archive(blob)\n+        assert verified\n+        assert unpacked[\"foo\"] == \"bar\"\n+        assert \"tam\" not in unpacked\n+\n     @pytest.mark.parametrize(\"which\", (\"hmac\", \"salt\"))\n-    def test_tampered(self, key, which):\n+    def test_tampered_manifest(self, key, which):\n         data = {\"foo\": \"bar\"}\n-        blob = key.pack_and_authenticate_metadata(data)\n+        blob = key.pack_and_authenticate_metadata(data, context=b\"manifest\")\n         assert blob.startswith(b\"\\x82\")\n \n         unpacked = msgpack.unpackb(blob, object_hook=StableDict)\n@@ -359,6 +393,21 @@ def test_tampered(self, key, which):\n         with pytest.raises(TAMInvalid):\n             key.unpack_and_verify_manifest(blob)\n \n+    @pytest.mark.parametrize(\"which\", (\"hmac\", \"salt\"))\n+    def test_tampered_archive(self, key, which):\n+        data = {\"foo\": \"bar\"}\n+        blob = key.pack_and_authenticate_metadata(data, context=b\"archive\")\n+        assert blob.startswith(b\"\\x82\")\n+\n+        unpacked = msgpack.unpackb(blob, object_hook=StableDict)\n+        assert len(unpacked[\"tam\"][which]) == 64\n+        unpacked[\"tam\"][which] = unpacked[\"tam\"][which][0:32] + bytes(32)\n+        assert len(unpacked[\"tam\"][which]) == 64\n+        blob = msgpack.packb(unpacked)\n+\n+        with pytest.raises(ArchiveTAMInvalid):\n+            key.unpack_and_verify_archive(blob)\n+\n \n def test_decrypt_key_file_unsupported_algorithm():\n     \"\"\"We will add more algorithms in the future. We should raise a helpful error.\"\"\""
    }
}