{
    "current_hash": "db4f9717c41bccc3ce10099ab61996b246099892",
    "parent_hash": "f7fe61a15a63a078e8dfe8044490a5ff20aa7002",
    "modified_file_0": {
        "mod_filename": "tensorflow/core/kernels/segment_reduction_ops.cc",
        "status": "modified",
        "add_lines": 9,
        "dele_lines": 10,
        "patch": "@@ -376,18 +376,17 @@ namespace functor {\n template <typename T, typename Index, typename InitialValueF,\n           typename ReductionF>\n struct UnsortedSegmentFunctor<CPUDevice, T, Index, InitialValueF, ReductionF> {\n-  void operator()(OpKernelContext* ctx, const Index num_segments,\n-                  const TensorShape& segment_ids_shape,\n+  void operator()(OpKernelContext* ctx, const TensorShape& segment_ids_shape,\n                   typename TTypes<Index>::ConstFlat segment_ids,\n-                  const Index data_size, const T* data,\n+                  typename TTypes<T, 2>::ConstTensor data,\n                   typename TTypes<T, 2>::Tensor output) {\n     output.setConstant(InitialValueF()());\n-    if (data_size == 0) {\n+    if (data.size() == 0) {\n       return;\n     }\n     const int64 N = segment_ids.dimension(0);\n+    const int64 num_segments = output.dimension(0);\n     ReductionF reduction;\n-    auto data_flat = typename TTypes<T, 2>::ConstTensor(data, N, data_size / N);\n     for (int64 i = 0; i < N; ++i) {\n       Index j = internal::SubtleMustCopy(segment_ids(i));\n       if (j < 0) {\n@@ -397,7 +396,7 @@ struct UnsortedSegmentFunctor<CPUDevice, T, Index, InitialValueF, ReductionF> {\n                   errors::InvalidArgument(\n                       \"segment_ids\", SliceDebugString(segment_ids_shape, i),\n                       \" = \", j, \" is out of range [0, \", num_segments, \")\"));\n-      reduction(data_flat.template chip<0>(i), output.template chip<0>(j));\n+      reduction(data.template chip<0>(i), output.template chip<0>(j));\n     }\n   }\n };\n@@ -485,7 +484,7 @@ class UnsortedSegmentReductionOp : public OpKernel {\n       return;\n     }\n     const auto segment_flat = segment_ids.flat<Index>();\n-    const Index output_rows = internal::SubtleMustCopy(static_cast<Index>(\n+    const int64 output_rows = internal::SubtleMustCopy(static_cast<int64>(\n         num_segments.dtype() == DT_INT32 ? num_segments.scalar<int32>()()\n                                          : num_segments.scalar<int64>()()));\n     OP_REQUIRES(context, output_rows >= 0,\n@@ -499,9 +498,9 @@ class UnsortedSegmentReductionOp : public OpKernel {\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n     auto output_flat = output->flat_outer_dims<T>();\n-    auto data_ptr = data.template flat<T>().data();\n-    reduction_functor_(context, output_rows, segment_ids.shape(), segment_flat,\n-                       data.NumElements(), data_ptr, output_flat);\n+    auto data_flat = data.flat_inner_outer_dims<T, 2>(segment_ids.dims() - 1);\n+    reduction_functor_(context, segment_ids.shape(), segment_flat, data_flat,\n+                       output_flat);\n   }\n \n  protected:"
    },
    "modified_file_1": {
        "mod_filename": "tensorflow/core/kernels/segment_reduction_ops.h",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 3,
        "patch": "@@ -59,10 +59,9 @@ struct SegmentSumFunctor {\n template <typename Device, typename T, typename Index, typename InitialValueF,\n           typename ReductionF>\n struct UnsortedSegmentFunctor {\n-  void operator()(OpKernelContext* ctx, const Index num_segments,\n-                  const TensorShape& segment_ids_shape,\n+  void operator()(OpKernelContext* ctx, const TensorShape& segment_ids_shape,\n                   typename TTypes<Index>::ConstFlat segment_ids,\n-                  const Index data_size, const T* data,\n+                  typename TTypes<T, 2>::ConstTensor data,\n                   typename TTypes<T, 2>::Tensor output);\n };\n "
    },
    "modified_file_2": {
        "mod_filename": "tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc",
        "status": "modified",
        "add_lines": 21,
        "dele_lines": 20,
        "patch": "@@ -106,21 +106,21 @@ __global__ void SortedSegmentSumCustomKernel(const Index input_outer_dim_size,\n // Each element is mapped from input to output by a combination of its\n // 'segment_ids' mapping and 'inner_dim_size'.\n template <typename T, typename Index, typename KernelReductionFunctor>\n-__global__ void UnsortedSegmentCustomKernel(const Index input_outer_dim_size,\n-                                            const Index inner_dim_size,\n-                                            const Index output_outer_dim_size,\n+__global__ void UnsortedSegmentCustomKernel(const int64 input_outer_dim_size,\n+                                            const int64 inner_dim_size,\n+                                            const int64 output_outer_dim_size,\n                                             const Index* segment_ids,\n                                             const T* input, T* output) {\n-  const Index input_total_size = input_outer_dim_size * inner_dim_size;\n-  const Index output_total_size = output_outer_dim_size * inner_dim_size;\n-  for (int input_index : GpuGridRangeX(input_total_size)) {\n-    const Index input_segment_index = input_index / inner_dim_size;\n-    const Index segment_offset = input_index % inner_dim_size;\n+  const int64 input_total_size = input_outer_dim_size * inner_dim_size;\n+  for (int64 input_index : GpuGridRangeX(input_total_size)) {\n+    const int64 input_segment_index = input_index / inner_dim_size;\n+    const int64 segment_offset = input_index % inner_dim_size;\n     const Index output_segment_index = segment_ids[input_segment_index];\n-    if (output_segment_index < 0 || output_segment_index >= output_total_size) {\n+    if (output_segment_index < 0 ||\n+        output_segment_index >= output_outer_dim_size) {\n       continue;\n     }\n-    const Index output_index =\n+    const int64 output_index =\n         output_segment_index * inner_dim_size + segment_offset;\n     KernelReductionFunctor()(output + output_index, ldg(input + input_index));\n   }\n@@ -174,10 +174,9 @@ void SegmentSumFunctor<T, Index>::operator()(\n template <typename T, typename Index, typename InitialValueF,\n           typename ReductionF>\n struct UnsortedSegmentFunctor<GPUDevice, T, Index, InitialValueF, ReductionF> {\n-  void operator()(OpKernelContext* ctx, const Index num_segments,\n-                  const TensorShape& segment_ids_shape,\n+  void operator()(OpKernelContext* ctx, const TensorShape& segment_ids_shape,\n                   typename TTypes<Index>::ConstFlat segment_ids,\n-                  const Index data_size, const T* data,\n+                  typename TTypes<T, 2>::ConstTensor data,\n                   typename TTypes<T, 2>::Tensor output) {\n     if (output.size() == 0) {\n       return;\n@@ -188,6 +187,7 @@ struct UnsortedSegmentFunctor<GPUDevice, T, Index, InitialValueF, ReductionF> {\n     TF_CHECK_OK(GpuLaunchKernel(\n         SetToValue<T>, config.block_count, config.thread_per_block, 0,\n         d.stream(), output.size(), output.data(), InitialValueF()()));\n+    const int64 data_size = data.size();\n     if (data_size == 0 || segment_ids_shape.num_elements() == 0) {\n       return;\n     }\n@@ -196,15 +196,16 @@ struct UnsortedSegmentFunctor<GPUDevice, T, Index, InitialValueF, ReductionF> {\n     // *) 'data_size' is the total number of elements to process.\n     // *) 'segment_ids.shape' is a prefix of data's shape.\n     // *) 'input_outer_dim_size' is the total number of segments to process.\n-    const Index input_outer_dim_size = segment_ids.dimension(0);\n-    const Index input_inner_dim_size = data_size / input_outer_dim_size;\n+    const int64 input_outer_dim_size = segment_ids.dimension(0);\n+    const int64 input_inner_dim_size = data.dimension(1);\n+    const int64 output_outer_dim_size = output.dimension(0);\n     config = GetGpuLaunchConfig(data_size, d);\n \n-    TF_CHECK_OK(\n-        GpuLaunchKernel(UnsortedSegmentCustomKernel<T, Index, ReductionF>,\n-                        config.block_count, config.thread_per_block, 0,\n-                        d.stream(), input_outer_dim_size, input_inner_dim_size,\n-                        num_segments, segment_ids.data(), data, output.data()));\n+    TF_CHECK_OK(GpuLaunchKernel(\n+        UnsortedSegmentCustomKernel<T, Index, ReductionF>, config.block_count,\n+        config.thread_per_block, 0, d.stream(), input_outer_dim_size,\n+        input_inner_dim_size, output_outer_dim_size, segment_ids.data(),\n+        data.data(), output.data()));\n   }\n };\n "
    }
}