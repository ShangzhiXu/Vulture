{
    "current_hash": "ca8c013b5e97b1373b3bb1c97ea655e69f31a575",
    "parent_hash": "b9465214656c42204d86945eca80d211f50043a1",
    "modified_file_0": {
        "mod_filename": "tensorflow/core/kernels/boosted_trees/prediction_ops.cc",
        "status": "modified",
        "add_lines": 3,
        "dele_lines": 3,
        "patch": "@@ -121,7 +121,7 @@ class BoostedTreesTrainingPredictOp : public OpKernel {\n       auto do_work = [&resource, &bucketized_features, &cached_tree_ids,\n                       &cached_node_ids, &output_partial_logits,\n                       &output_node_ids, latest_tree,\n-                      this](int32 start, int32 end) {\n+                      this](int64 start, int64 end) {\n         for (int32 i = start; i < end; ++i) {\n           int32 tree_id = cached_tree_ids(i);\n           int32 node_id = cached_node_ids(i);\n@@ -237,7 +237,7 @@ class BoostedTreesPredictOp : public OpKernel {\n \n     const int32 last_tree = resource->num_trees() - 1;\n     auto do_work = [&resource, &bucketized_features, &output_logits, last_tree,\n-                    this](int32 start, int32 end) {\n+                    this](int64 start, int64 end) {\n       for (int32 i = start; i < end; ++i) {\n         std::vector<float> tree_logits(logits_dimension_, 0.0);\n         int32 tree_id = 0;\n@@ -340,7 +340,7 @@ class BoostedTreesExampleDebugOutputsOp : public OpKernel {\n     // path. Note: feature_ids has one less value than logits_path because the\n     // first value of each logit path will be the bias.\n     auto do_work = [&resource, &bucketized_features, &output_debug_info,\n-                    last_tree](int32 start, int32 end) {\n+                    last_tree](int64 start, int64 end) {\n       for (int32 i = start; i < end; ++i) {\n         // Proto to store debug outputs, per example.\n         boosted_trees::DebugOutput example_debug_info;"
    },
    "modified_file_1": {
        "mod_filename": "tensorflow/core/kernels/image/crop_and_resize_op.cc",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 2,
        "patch": "@@ -223,7 +223,7 @@ struct CropAndResize<CPUDevice, T> {\n     const int depth = crops.dimension(3);\n \n     // Sharding across boxes.\n-    auto CropAndResizePerBox = [&](int start_box, int limit_box) {\n+    auto CropAndResizePerBox = [&](int64 start_box, int64 limit_box) {\n       for (int b = start_box; b < limit_box; ++b) {\n         const float y1 = boxes(b, 0);\n         const float x1 = boxes(b, 1);\n@@ -449,7 +449,7 @@ struct CropAndResizeBackpropImage<CPUDevice, T> {\n \n     grads_image.setZero();\n \n-    auto CropAndResizeBackImgPerBox = [&](int start_box, int limit_box) {\n+    auto CropAndResizeBackImgPerBox = [&](int64 start_box, int64 limit_box) {\n       for (int b = start_box; b < limit_box; ++b) {\n         const float y1 = boxes(b, 0);\n         const float x1 = boxes(b, 1);"
    },
    "modified_file_2": {
        "mod_filename": "tensorflow/core/kernels/linalg/banded_triangular_solve_op.cc",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 1,
        "patch": "@@ -193,7 +193,8 @@ struct LaunchBatchBandedTriangularSolve {\n \n     Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n           cost_per_unit,\n-          [&in_x, &in_y, adjoint, lower, &bcast, out](int start, int limit) {\n+          [&in_x, &in_y, adjoint, lower, &bcast, out](int64 start,\n+                                                      int64 limit) {\n             SequentialBandedTriangularSolveKernel<Scalar>::Run(\n                 in_x, in_y, lower, adjoint, bcast, out, start, limit);\n           });"
    },
    "modified_file_3": {
        "mod_filename": "tensorflow/core/kernels/nth_element_op.cc",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 1,
        "patch": "@@ -95,7 +95,8 @@ struct NthElementFunctor<CPUDevice, T> {\n     const int last_dim = input_tensor.dim_size(input_tensor.dims() - 1);\n \n     // Allocate each row to different shard.\n-    auto SubNthElement = [&, input, output, last_dim, n](int start, int limit) {\n+    auto SubNthElement = [&, input, output, last_dim, n](int64 start,\n+                                                         int64 limit) {\n       // std::nth_element would rearrange the array, so we need a new buffer.\n       std::vector<T> buf(last_dim);\n "
    },
    "modified_file_4": {
        "mod_filename": "tensorflow/core/kernels/parameterized_truncated_normal_op.cc",
        "status": "modified",
        "add_lines": 4,
        "dele_lines": 4,
        "patch": "@@ -70,8 +70,8 @@ struct TruncatedNormalFunctor<CPUDevice, T> {\n \n     auto do_work = [samples_per_batch, num_elements, &ctx, &means, &stddevs,\n                     &minvals, &maxvals, &gen, &output,\n-                    kStdDevsInsideBoundsToUseRandnSampler](int start_batch,\n-                                                           int limit_batch) {\n+                    kStdDevsInsideBoundsToUseRandnSampler](int64 start_batch,\n+                                                           int64 limit_batch) {\n       // Capturing \"gen\" by-value would only make a copy for the _shared_\n       // lambda.  Since we want to let each worker have its own copy, we pass\n       // \"gen\" by reference and explicitly do a copy assignment here.\n@@ -333,8 +333,8 @@ struct TruncatedNormalFunctorV2<CPUDevice, T> {\n \n     auto do_work = [num_batches, samples_per_batch, &ctx, &bcast, &means,\n                     &stddevs, &minvals, &maxvals, &gen, &output,\n-                    kStdDevsInsideBoundsToUseRandnSampler](int start_output,\n-                                                           int limit_output) {\n+                    kStdDevsInsideBoundsToUseRandnSampler](int64 start_output,\n+                                                           int64 limit_output) {\n       // Capturing \"gen\" by-value would only make a copy for the _shared_\n       // lambda.  Since we want to let each worker have its own copy, we pass\n       // \"gen\" by reference and explicitly do a copy assignment here."
    },
    "modified_file_5": {
        "mod_filename": "tensorflow/core/kernels/random_binomial_op.cc",
        "status": "modified",
        "add_lines": 1,
        "dele_lines": 1,
        "patch": "@@ -184,7 +184,7 @@ struct RandomBinomialFunctor<CPUDevice, T, U> {\n     // the sample shape and [H1, ... Hm] for the batch shape of the samples.\n     // We have B1 * ... * Bk samples per batch member we need.\n     auto DoWork = [num_batches, samples_per_batch, &bcast, &counts, &probs,\n-                   &gen, &output](int start_output, int limit_output) {\n+                   &gen, &output](int64 start_output, int64 limit_output) {\n       // Vectorized intermediate calculations for uniform rejection sampling.\n       // We always generate at most 4 samples.\n       Eigen::array<T, 4> z;"
    },
    "modified_file_6": {
        "mod_filename": "tensorflow/core/kernels/random_poisson_op.cc",
        "status": "modified",
        "add_lines": 1,
        "dele_lines": 1,
        "patch": "@@ -97,7 +97,7 @@ struct PoissonFunctor<CPUDevice, T, U> {\n     typedef random::UniformDistribution<random::PhiloxRandom, CT> Uniform;\n \n     auto DoWork = [num_samples, num_rate, &rng, samples_flat, rate_flat](\n-                      int start_output, int limit_output) {\n+                      int64 start_output, int64 limit_output) {\n       // Capturing \"rng\" by value would only make a copy for the _shared_\n       // lambda.  Since we want to let each worker have its own copy, we pass\n       // \"rng\" by reference and explicitly do a copy assignment."
    },
    "modified_file_7": {
        "mod_filename": "tensorflow/core/kernels/stateless_random_ops.cc",
        "status": "modified",
        "add_lines": 1,
        "dele_lines": 1,
        "patch": "@@ -252,7 +252,7 @@ class StatelessRandomGammaOp : public StatelessRandomOpBase {\n     // avoid a couple flops which can be done on a per-alpha basis.\n \n     auto DoWork = [samples_per_alpha, num_alphas, &random, samples_flat,\n-                   alpha_flat](int start_output, int limit_output) {\n+                   alpha_flat](int64 start_output, int64 limit_output) {\n       // Capturing \"random\" by-value would only make a copy for the _shared_\n       // lambda.  Since we want to let each worker have its own copy, we pass\n       // \"random\" by reference and explicitly do a copy assignment."
    },
    "modified_file_8": {
        "mod_filename": "tensorflow/core/kernels/topk_op.cc",
        "status": "modified",
        "add_lines": 1,
        "dele_lines": 1,
        "patch": "@@ -136,7 +136,7 @@ struct TopKFunctor<CPUDevice, T> {\n       return Status::OK();\n     }\n \n-    auto SortIndices = [&](int start_batch, int limit_batch) {\n+    auto SortIndices = [&](int64 start_batch, int64 limit_batch) {\n       for (int32 b = start_batch; b < limit_batch; ++b) {\n         const T* input_data = &input(b, 0);\n         const auto stable_comp = [input_data](const int32 a, const int32 b) {"
    }
}