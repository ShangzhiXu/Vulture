{
    "current_hash": "1970c2158b1ffa416d159d03c3370b9a462aee35",
    "parent_hash": "fff2c8326280c07733828f990548979bdc893859",
    "modified_file_0": {
        "mod_filename": "tensorflow/lite/kernels/activations.cc",
        "status": "modified",
        "add_lines": 88,
        "dele_lines": 44,
        "patch": "@@ -252,8 +252,10 @@ void* HardSwishInit(TfLiteContext* context, const char* buffer, size_t length) {\n TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   return context->ResizeTensor(context, output,\n@@ -272,8 +274,10 @@ TfLiteStatus ReluPrepare(TfLiteContext* context, TfLiteNode* node) {\n   ReluOpData* data = reinterpret_cast<ReluOpData*>(node->user_data);\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   if (input->type == kTfLiteInt8 || input->type == kTfLiteUInt8) {\n@@ -300,12 +304,14 @@ void HardSwishFree(TfLiteContext* context, void* buffer) {\n \n TfLiteStatus HardSwishPrepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_STATUS(GenericPrepare(context, node));\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n \n   if (output->type == kTfLiteUInt8 || output->type == kTfLiteInt8) {\n     HardSwishData* data = static_cast<HardSwishData*>(node->user_data);\n     HardSwishParams* params = &data->params;\n-    const TfLiteTensor* input = GetInput(context, node, 0);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n     params->input_zero_point = input->params.zero_point;\n     params->output_zero_point = output->params.zero_point;\n     const float input_scale = input->params.scale;\n@@ -337,8 +343,10 @@ TfLiteStatus HardSwishPrepare(TfLiteContext* context, TfLiteNode* node) {\n TfLiteStatus LeakyReluPrepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   LeakyReluOpData* data = reinterpret_cast<LeakyReluOpData*>(node->user_data);\n@@ -366,8 +374,10 @@ TfLiteStatus TanhPrepare(TfLiteContext* context, TfLiteNode* node) {\n \n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   if (kernel_type == kFixedPointOptimized) {\n@@ -451,8 +461,10 @@ TfLiteStatus SigmoidPrepare(TfLiteContext* context, TfLiteNode* node) {\n \n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   if (kernel_type == kFixedPointOptimized) {\n@@ -546,8 +558,10 @@ TfLiteStatus SoftmaxPrepare(TfLiteContext* context, TfLiteNode* node) {\n \n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   if (output->type == kTfLiteInt16) {\n     TF_LITE_ENSURE(context, input->type == kTfLiteInt8 ||\n                                 input->type == kTfLiteUInt8 ||\n@@ -614,8 +628,10 @@ TfLiteStatus LogSoftmaxPrepare(TfLiteContext* context, TfLiteNode* node) {\n \n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8) {\n@@ -650,9 +666,12 @@ TfLiteStatus LogSoftmaxPrepare(TfLiteContext* context, TfLiteNode* node) {\n TfLiteStatus PreluPrepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* alpha = GetInput(context, node, 1);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* alpha;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &alpha));\n   PreluOpData* data = reinterpret_cast<PreluOpData*>(node->user_data);\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, alpha->type);\n@@ -704,8 +723,10 @@ TfLiteStatus PreluPrepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus ReluEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   const ReluOpData* data = reinterpret_cast<ReluOpData*>(node->user_data);\n   switch (input->type) {\n     case kTfLiteFloat32: {\n@@ -732,8 +753,10 @@ TfLiteStatus ReluEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Relu1Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   const ReluOpData* data = reinterpret_cast<ReluOpData*>(node->user_data);\n   switch (input->type) {\n     case kTfLiteFloat32: {\n@@ -763,8 +786,10 @@ template <KernelType kernel_type>\n TfLiteStatus HardSwishEval(TfLiteContext* context, TfLiteNode* node) {\n   HardSwishData* data = static_cast<HardSwishData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   switch (input->type) {\n     case kTfLiteFloat32: {\n       if (kernel_type == kReference) {\n@@ -814,8 +839,10 @@ TfLiteStatus HardSwishEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Relu6Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   ReluOpData* data = reinterpret_cast<ReluOpData*>(node->user_data);\n   switch (input->type) {\n     case kTfLiteFloat32: {\n@@ -845,8 +872,10 @@ TfLiteStatus Relu6Eval(TfLiteContext* context, TfLiteNode* node) {\n template <KernelType kernel_type>\n TfLiteStatus TanhEval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   switch (input->type) {\n     case kTfLiteFloat32: {\n       if (kernel_type == kReference) {\n@@ -919,8 +948,10 @@ template <KernelType kernel_type>\n TfLiteStatus SigmoidEval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   switch (input->type) {\n     case kTfLiteFloat32: {\n       if (kernel_type == kReference) {\n@@ -1067,8 +1098,10 @@ TfLiteStatus SoftmaxEval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteSoftmaxParams*>(node->builtin_data);\n   SoftmaxOpData* data = reinterpret_cast<SoftmaxOpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n \n   switch (input->type) {\n     case kTfLiteFloat32: {\n@@ -1122,8 +1155,10 @@ template <KernelType kernel_type>\n TfLiteStatus LogSoftmaxEval(TfLiteContext* context, TfLiteNode* node) {\n   const LogSoftmaxOpData* data =\n       reinterpret_cast<LogSoftmaxOpData*>(node->user_data);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   switch (input->type) {\n     case kTfLiteFloat32: {\n       SoftmaxParams op_params;\n@@ -1183,9 +1218,12 @@ T ApplyPrelu(T input, T alpha) {\n \n template <KernelType kernel_type>\n TfLiteStatus PreluEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  const TfLiteTensor* alpha = GetInput(context, node, 1);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  const TfLiteTensor* alpha;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &alpha));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   const PreluOpData* data = reinterpret_cast<PreluOpData*>(node->user_data);\n   switch (input->type) {\n     case kTfLiteFloat32: {\n@@ -1294,8 +1332,10 @@ void QuantizeLeakyRelu(const TfLiteTensor* input, TfLiteTensor* output,\n }\n \n TfLiteStatus LeakyReluEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   const auto* params =\n       reinterpret_cast<TfLiteLeakyReluParams*>(node->builtin_data);\n   const LeakyReluOpData* data =\n@@ -1332,8 +1372,10 @@ TfLiteStatus LeakyReluEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus EluPrepare(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   // Use LUT to handle quantized elu path.\n@@ -1346,8 +1388,10 @@ TfLiteStatus EluPrepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus EluEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   switch (input->type) {\n     case kTfLiteFloat32: {\n       optimized_ops::Elu(GetTensorShape(input), GetTensorData<float>(input),"
    },
    "modified_file_1": {
        "mod_filename": "tensorflow/lite/kernels/add.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -91,9 +91,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n   output->type = input2->type;\n@@ -358,9 +364,15 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteAddParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n     EvalAdd<kernel_type>(context, node, params, data, input1, input2, output);"
    },
    "modified_file_2": {
        "mod_filename": "tensorflow/lite/kernels/add_n.cc",
        "status": "modified",
        "add_lines": 16,
        "dele_lines": 4,
        "patch": "@@ -33,13 +33,18 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE(context, num_inputs >= 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = input1->type;\n \n   // Check that all input tensors have the same shape and type.\n   for (int i = kInputTensor1 + 1; i < num_inputs; ++i) {\n-    const TfLiteTensor* input = GetInput(context, node, i);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &input));\n     TF_LITE_ENSURE(context, HaveSameShapes(input1, input));\n     TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input->type);\n   }\n@@ -55,15 +60,22 @@ template <typename T>\n void EvalAddN(TfLiteContext* context, TfLiteNode* node) {\n   // TODO(haoliang): Initialize all_inputs only once during init.\n   VectorOfTensors<T> all_inputs(*context, *node->inputs);\n+  // Safe to use unchecked since caller checks that tensor is valid\n   TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n   int num_inputs = NumInputs(node);\n+  // Safe to use unchecked since caller checks that tensor is valid\n   const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n   reference_ops::AddN<T>(GetTensorShape(input1), num_inputs, all_inputs.data(),\n                          GetTensorData<T>(output));\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   if (output->type == kTfLiteFloat32) {\n     EvalAddN<float>(context, node);\n   } else if (output->type == kTfLiteInt32) {"
    },
    "modified_file_3": {
        "mod_filename": "tensorflow/lite/kernels/arg_min_max.cc",
        "status": "modified",
        "add_lines": 14,
        "dele_lines": 6,
        "patch": "@@ -58,15 +58,19 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* axis = GetInput(context, node, kAxis);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* axis;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kAxis, &axis));\n   // Make sure the axis is only 1 dimension.\n   TF_LITE_ENSURE_EQ(context, NumElements(axis), 1);\n   // Make sure the axis is only either int32 or int64.\n   TF_LITE_ENSURE(context,\n                  axis->type == kTfLiteInt32 || axis->type == kTfLiteInt64);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   auto* params = reinterpret_cast<TfLiteArgMaxParams*>(node->builtin_data);\n   switch (params->output_type) {\n@@ -119,9 +123,13 @@ std::function<bool(T, T)> GetComparefunction(bool is_arg_max) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node, bool is_arg_max) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* axis = GetInput(context, node, kAxis);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* axis;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kAxis, &axis));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_STATUS(ResizeOutput(context, input, axis, output));\n   }"
    },
    "modified_file_4": {
        "mod_filename": "tensorflow/lite/kernels/assign_variable.cc",
        "status": "modified",
        "add_lines": 9,
        "dele_lines": 5,
        "patch": "@@ -40,8 +40,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   //   everything still works fine when variable ops aren't used.\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 0);\n \n-  const TfLiteTensor* input_resource_id_tensor =\n-      GetInput(context, node, kInputVariableId);\n+  const TfLiteTensor* input_resource_id_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputVariableId,\n+                                          &input_resource_id_tensor));\n   TF_LITE_ENSURE_EQ(context, input_resource_id_tensor->type, kTfLiteInt32);\n   TF_LITE_ENSURE_EQ(context, NumElements(input_resource_id_tensor), 1);\n \n@@ -51,9 +52,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   Subgraph* subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n \n-  const TfLiteTensor* input_resource_id_tensor =\n-      GetInput(context, node, kInputVariableId);\n-  const TfLiteTensor* input_value_tensor = GetInput(context, node, kInputValue);\n+  const TfLiteTensor* input_resource_id_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputVariableId,\n+                                          &input_resource_id_tensor));\n+  const TfLiteTensor* input_value_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputValue, &input_value_tensor));\n \n   int resource_id = input_resource_id_tensor->data.i32[0];\n   auto& resources = subgraph->resources();"
    },
    "modified_file_5": {
        "mod_filename": "tensorflow/lite/kernels/audio_spectrogram.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -76,8 +76,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 2);\n \n@@ -106,8 +109,11 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteAudioSpectrogramParams*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE(context, params->spectrogram->Initialize(params->window_size,\n                                                           params->stride));"
    },
    "modified_file_6": {
        "mod_filename": "tensorflow/lite/kernels/basic_rnn.cc",
        "status": "modified",
        "add_lines": 68,
        "dele_lines": 28,
        "patch": "@@ -60,13 +60,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* input_weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* recurrent_weights =\n-      GetInput(context, node, kRecurrentWeightsTensor);\n-  const TfLiteTensor* bias = GetInput(context, node, kBiasTensor);\n-  const TfLiteTensor* hidden_state =\n-      GetInput(context, node, kHiddenStateTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* input_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTensor, &input_weights));\n+  const TfLiteTensor* recurrent_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, kRecurrentWeightsTensor, &recurrent_weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n+  const TfLiteTensor* hidden_state;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kHiddenStateTensor, &hidden_state));\n \n   // Check all the parameters of tensor match within themselves and match the\n   // input configuration.\n@@ -86,7 +93,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, hidden_state->dims->data[0], batch_size);\n   TF_LITE_ENSURE_EQ(context, hidden_state->dims->data[1], num_units);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Resize output.\n   TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n@@ -105,7 +114,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     TfLiteIntArrayFree(node->temporaries);\n     node->temporaries = TfLiteIntArrayCreate(6);\n     node->temporaries->data[0] = op_data->scratch_tensor_index;\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/0);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n+                                                &input_quantized));\n     input_quantized->type = input_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -114,8 +125,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        input_quantized_size));\n     }\n     node->temporaries->data[1] = op_data->scratch_tensor_index + 1;\n-    TfLiteTensor* hidden_state_quantized =\n-        GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &hidden_state_quantized));\n     hidden_state_quantized->type = input_weights->type;\n     hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(hidden_state_quantized->dims,\n@@ -127,7 +139,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                               hidden_state_quantized_size));\n     }\n     node->temporaries->data[2] = op_data->scratch_tensor_index + 2;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -138,7 +152,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        scaling_factors_size));\n     }\n     node->temporaries->data[3] = op_data->scratch_tensor_index + 3;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/3, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {num_units, batch_size};\n@@ -151,7 +167,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        accum_scratch_size));\n     }\n     node->temporaries->data[4] = op_data->scratch_tensor_index + 4;\n-    TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n     zero_points->type = kTfLiteInt32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -162,7 +180,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        zero_points_size));\n     }\n     node->temporaries->data[5] = op_data->scratch_tensor_index + 5;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[2] = {2, num_units};\n@@ -260,14 +280,23 @@ TfLiteStatus EvalHybrid(const TfLiteTensor* input,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteRNNParams*>(node->builtin_data);\n   auto* op_data = reinterpret_cast<OpData*>(node->user_data);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* input_weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* recurrent_weights =\n-      GetInput(context, node, kRecurrentWeightsTensor);\n-  const TfLiteTensor* bias = GetInput(context, node, kBiasTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* input_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTensor, &input_weights));\n+  const TfLiteTensor* recurrent_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, kRecurrentWeightsTensor, &recurrent_weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n   TfLiteTensor* hidden_state =\n-      &context->tensors[node->inputs->data[kHiddenStateTensor]];\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+      GetVariableInput(context, node, kHiddenStateTensor);\n+  TF_LITE_ENSURE(context, hidden_state != nullptr);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // We already checked that weight types are consistent, so branch on one.\n   switch (input_weights->type) {\n@@ -277,12 +306,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n       // TODO(mirkov): implement eval with quantized inputs as well.\n-      TfLiteTensor* input_quantized = GetTemporary(context, node, 0);\n-      TfLiteTensor* hidden_state_quantized = GetTemporary(context, node, 1);\n-      TfLiteTensor* scaling_factors = GetTemporary(context, node, 2);\n-      TfLiteTensor* accum_scratch = GetTemporary(context, node, 3);\n-      TfLiteTensor* zero_points = GetTemporary(context, node, 4);\n-      TfLiteTensor* row_sums = GetTemporary(context, node, 5);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 0, &input_quantized));\n+      TfLiteTensor* hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, 1, &hidden_state_quantized));\n+      TfLiteTensor* scaling_factors;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 2, &scaling_factors));\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 3, &accum_scratch));\n+      TfLiteTensor* zero_points;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 4, &zero_points));\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, 5, &row_sums));\n       return EvalHybrid(input, input_weights, recurrent_weights, bias, params,\n                         input_quantized, hidden_state_quantized,\n                         scaling_factors, hidden_state, output, zero_points,"
    },
    "modified_file_7": {
        "mod_filename": "tensorflow/lite/kernels/batch_matmul.cc",
        "status": "modified",
        "add_lines": 62,
        "dele_lines": 18,
        "patch": "@@ -154,7 +154,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n   // Temp tensor for Transposed LHS;\n   {\n     node->temporaries->data[0] = op_data->scratch_tensor_index;\n-    TfLiteTensor* scratch_buffer = GetTemporary(context, node, /*index=*/0);\n+    TfLiteTensor* scratch_buffer;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/0, &scratch_buffer));\n     TfLiteIntArray* scratch_buffer_size = TfLiteIntArrayCreate(lhs_rank);\n     for (int i = 0; i < lhs_rank - 2; ++i) {\n       scratch_buffer_size->data[i] = lhs->dims->data[i];\n@@ -175,7 +177,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n   // is set by the caller, the data is already in the desired layout.\n   {\n     node->temporaries->data[1] = op_data->scratch_tensor_index + 1;\n-    TfLiteTensor* scratch_buffer = GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* scratch_buffer;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/1, &scratch_buffer));\n     const TfLiteTensor* rhs = op_context->rhs;\n     int rhs_rank = NumDimensions(rhs);\n     TfLiteIntArray* scratch_buffer_size = TfLiteIntArrayCreate(rhs_rank);\n@@ -215,7 +219,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n     }\n     op_data->compute_row_sums = true;\n     node->temporaries->data[2] = op_data->scratch_tensor_index + 2;\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &input_quantized));\n     input_quantized->type = op_context->rhs->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n \n@@ -225,7 +231,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n                                                      input_quantized_size));\n \n     node->temporaries->data[3] = op_data->scratch_tensor_index + 3;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     // Total size of scaling factors is batch size * number of total batches\n@@ -238,7 +246,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n     }\n \n     node->temporaries->data[4] = op_data->scratch_tensor_index + 4;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {num_units, batch_size};\n@@ -252,7 +262,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n     }\n \n     node->temporaries->data[5] = op_data->scratch_tensor_index + 5;\n-    TfLiteTensor* input_offsets = GetTemporary(context, node, /*index=*/5);\n+    TfLiteTensor* input_offsets;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/5, &input_offsets));\n     input_offsets->type = kTfLiteInt32;\n     input_offsets->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n@@ -262,7 +274,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n                                                        input_offsets_size));\n     }\n     node->temporaries->data[6] = op_data->scratch_tensor_index + 6;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/6);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/6, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[1] = {num_weights_matrices * num_units};\n@@ -288,9 +302,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   bool adj_x = op_context.params->adj_x;\n   bool adj_y = op_context.params->adj_y;\n \n-  const TfLiteTensor* lhs_data = GetInput(context, node, kInputLHSTensor);\n-  const TfLiteTensor* rhs_data = GetInput(context, node, kInputRHSTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* lhs_data;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputLHSTensor, &lhs_data));\n+  const TfLiteTensor* rhs_data;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputRHSTensor, &rhs_data));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Note that quantized inference requires that all tensors have their\n   // parameters set. This is usually done during quantized training.\n@@ -502,11 +522,21 @@ TfLiteStatus EvalQuantized(TfLiteContext* context, TfLiteNode* node,\n                            const RuntimeShape& rhs_shape,\n                            const TfLiteTensor* rhs, TfLiteTensor* output) {\n   if (lhs->type == kTfLiteFloat32) {\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/2);\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/3);\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/4);\n-    TfLiteTensor* input_offsets = GetTemporary(context, node, /*index=*/5);\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/6);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &input_quantized));\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n+                                                &scaling_factors));\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &accum_scratch));\n+    TfLiteTensor* input_offsets;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/5, &input_offsets));\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/6, &row_sums));\n     return EvalHybrid<kernel_type>(\n         context, node, data, lhs_shape, lhs, rhs_shape, rhs, input_quantized,\n         scaling_factors, accum_scratch, row_sums, input_offsets, output);\n@@ -524,6 +554,10 @@ TfLiteStatus EvalQuantized(TfLiteContext* context, TfLiteNode* node,\n TfLiteTensor* GetTempRhs(TfLiteContext* context, TfLiteNode* node,\n                          const TfLiteTensor* rhs) {\n   TfLiteTensor* transposed_rhs = GetTemporary(context, node, 1);\n+  if (transposed_rhs == nullptr) {\n+    return nullptr;\n+  }\n+\n   if (rhs->type == kTfLiteInt8) {\n     // Get the quantization params from the RHS tensor.\n     transposed_rhs->params.scale = rhs->params.scale;\n@@ -535,6 +569,10 @@ TfLiteTensor* GetTempRhs(TfLiteContext* context, TfLiteNode* node,\n TfLiteTensor* GetTempLhs(TfLiteContext* context, TfLiteNode* node,\n                          const TfLiteTensor* lhs) {\n   TfLiteTensor* transposed_lhs = GetTemporary(context, node, 0);\n+  if (transposed_lhs == nullptr) {\n+    return nullptr;\n+  }\n+\n   if (lhs->type == kTfLiteInt8) {\n     // Get the quantization params from the LHS tensor.\n     transposed_lhs->params.scale = lhs->params.scale;\n@@ -558,9 +596,15 @@ template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpContext op_context(context, node);\n   OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n-  const TfLiteTensor* lhs = GetInput(context, node, kInputLHSTensor);\n-  const TfLiteTensor* rhs = GetInput(context, node, kInputRHSTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* lhs;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputLHSTensor, &lhs));\n+  const TfLiteTensor* rhs;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputRHSTensor, &rhs));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   RuntimeShape orig_lhs_shape = GetTensorShape(lhs);\n   RuntimeShape orig_rhs_shape = GetTensorShape(rhs);\n "
    },
    "modified_file_8": {
        "mod_filename": "tensorflow/lite/kernels/bidirectional_sequence_lstm.cc",
        "status": "modified",
        "add_lines": 249,
        "dele_lines": 125,
        "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n #include \"tensorflow/lite/kernels/cpu_backend_context.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/internal/kernel_utils.h\"\n #include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n@@ -192,8 +193,10 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n   TF_LITE_ENSURE(context, params->cell_clip >= 0);\n   TF_LITE_ENSURE(context, params->proj_clip >= 0);\n \n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, input_to_forget_weights_tensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, input_to_forget_weights_tensor,\n+                                 &input_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[1], n_input);\n@@ -211,16 +214,20 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n                             input_to_forget_weights->type);\n   }\n \n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, input_to_cell_weights_tensor);\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, input_to_cell_weights_tensor,\n+                                 &input_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[1], n_input);\n   TF_LITE_ENSURE_TYPES_EQ(context, input_to_cell_weights->type,\n                           input_to_forget_weights->type);\n \n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, input_to_output_weights_tensor);\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, input_to_output_weights_tensor,\n+                                 &input_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[1], n_input);\n@@ -239,8 +246,10 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n                             input_to_forget_weights->type);\n   }\n \n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, recurrent_to_forget_weights_tensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, recurrent_to_forget_weights_tensor,\n+                            &recurrent_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[0],\n                     n_cell);\n@@ -249,8 +258,10 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n   TF_LITE_ENSURE_TYPES_EQ(context, recurrent_to_forget_weights->type,\n                           input_to_forget_weights->type);\n \n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, recurrent_to_cell_weights_tensor);\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, recurrent_to_cell_weights_tensor,\n+                            &recurrent_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[1],\n@@ -316,20 +327,25 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n     TF_LITE_ENSURE_TYPES_EQ(context, input_gate_bias->type, kTfLiteFloat32);\n   }\n \n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, forget_gate_bias_tensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, forget_gate_bias_tensor, &forget_gate_bias));\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->data[0], n_cell);\n   TF_LITE_ENSURE_TYPES_EQ(context, forget_gate_bias->type, kTfLiteFloat32);\n \n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, cell_gate_bias_tensor);\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, cell_gate_bias_tensor,\n+                                          &cell_gate_bias));\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->type, kTfLiteFloat32);\n \n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, output_gate_bias_tensor);\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, output_gate_bias_tensor, &output_gate_bias));\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->data[0], n_cell);\n   TF_LITE_ENSURE_TYPES_EQ(context, output_gate_bias->type, kTfLiteFloat32);\n@@ -413,41 +429,50 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Inferring batch size, number of outputs and sequence length and\n   // number of cells from the input tensors.\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, input->dims->size, 3);\n   const bool time_major = params->time_major;\n   const int max_time = time_major ? input->dims->data[0] : input->dims->data[1];\n   const int n_batch = time_major ? input->dims->data[1] : input->dims->data[0];\n   const int n_input = input->dims->data[2];\n \n-  const TfLiteTensor* fw_input_to_output_weights =\n-      GetInput(context, node, kFwInputToOutputWeightsTensor);\n+  const TfLiteTensor* fw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToOutputWeightsTensor,\n+                                 &fw_input_to_output_weights));\n   const int n_fw_cell = fw_input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, fw_input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, fw_input_to_output_weights->dims->data[1],\n                     n_input);\n \n-  const TfLiteTensor* bw_input_to_output_weights =\n-      GetInput(context, node, kBwInputToOutputWeightsTensor);\n+  const TfLiteTensor* bw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToOutputWeightsTensor,\n+                                 &bw_input_to_output_weights));\n   const int n_bw_cell = bw_input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, bw_input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, bw_input_to_output_weights->dims->data[1],\n                     n_input);\n   TF_LITE_ENSURE_EQ(context, bw_input_to_output_weights->type,\n                     fw_input_to_output_weights->type);\n \n-  const TfLiteTensor* fw_recurrent_to_output_weights =\n-      GetInput(context, node, kFwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* fw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kFwRecurrentToOutputWeightsTensor,\n+                            &fw_recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, fw_recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, fw_recurrent_to_output_weights->dims->data[0],\n                     n_fw_cell);\n   TF_LITE_ENSURE_EQ(context, fw_recurrent_to_output_weights->type,\n                     fw_input_to_output_weights->type);\n   const int n_fw_output = fw_recurrent_to_output_weights->dims->data[1];\n \n-  const TfLiteTensor* bw_recurrent_to_output_weights =\n-      GetInput(context, node, kBwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* bw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kBwRecurrentToOutputWeightsTensor,\n+                            &bw_recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, bw_recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, bw_recurrent_to_output_weights->dims->data[0],\n                     n_bw_cell);\n@@ -504,7 +529,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Get the pointer to output, activation_state and cell_state buffer tensors.\n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n   TfLiteTensor* fw_activation_state =\n       GetVariableInput(context, node, kFwInputActivationStateTensor);\n   TF_LITE_ENSURE(context, fw_activation_state != nullptr);\n@@ -541,8 +568,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Create a scratch buffer tensor.\n   node->temporaries->data[kFwScratchBuffer] =\n       op_data->scratch_tensor_index + kFwScratchBuffer;\n-  TfLiteTensor* fw_scratch_buffer =\n-      GetTemporary(context, node, kFwScratchBuffer);\n+  TfLiteTensor* fw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kFwScratchBuffer,\n+                                              &fw_scratch_buffer));\n   fw_scratch_buffer->type = input->type;\n   fw_scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -581,7 +609,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Resize the output tensors.\n   if (!params->merge_outputs) {\n-    TfLiteTensor* bw_output = GetOutput(context, node, kBwOutputTensor);\n+    TfLiteTensor* bw_output;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kBwOutputTensor, &bw_output));\n     TfLiteIntArray* bw_output_size = TfLiteIntArrayCreate(3);\n     bw_output_size->data[0] = time_major ? max_time : n_batch;\n     bw_output_size->data[1] = time_major ? n_batch : max_time;\n@@ -600,8 +630,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Create a scratch buffer tensor.\n   node->temporaries->data[kBwScratchBuffer] =\n       op_data->scratch_tensor_index + kBwScratchBuffer;\n-  TfLiteTensor* bw_scratch_buffer =\n-      GetTemporary(context, node, kBwScratchBuffer);\n+  TfLiteTensor* bw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kBwScratchBuffer,\n+                                              &bw_scratch_buffer));\n   bw_scratch_buffer->type = input->type;\n   bw_scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -631,8 +662,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // (if present), activation_state and cell_state tensors.\n     node->temporaries->data[kInputQuantized] =\n         op_data->scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = fw_input_to_output_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -643,8 +675,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kFwActivationStateQuantized] =\n         op_data->scratch_tensor_index + kFwActivationStateQuantized;\n-    TfLiteTensor* fw_activation_state_quantized =\n-        GetTemporary(context, node, kFwActivationStateQuantized);\n+    TfLiteTensor* fw_activation_state_quantized;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kFwActivationStateQuantized,\n+                                  &fw_activation_state_quantized));\n     fw_activation_state_quantized->type = fw_input_to_output_weights->type;\n     fw_activation_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(fw_activation_state_quantized->dims,\n@@ -657,8 +691,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwActivationStateQuantized] =\n         op_data->scratch_tensor_index + kBwActivationStateQuantized;\n-    TfLiteTensor* bw_activation_state_quantized =\n-        GetTemporary(context, node, kBwActivationStateQuantized);\n+    TfLiteTensor* bw_activation_state_quantized;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kBwActivationStateQuantized,\n+                                  &bw_activation_state_quantized));\n     bw_activation_state_quantized->type = fw_input_to_output_weights->type;\n     bw_activation_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(bw_activation_state_quantized->dims,\n@@ -671,8 +707,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kFwCellStateQuantized] =\n         op_data->scratch_tensor_index + kFwCellStateQuantized;\n-    TfLiteTensor* fw_cell_state_quantized =\n-        GetTemporary(context, node, kFwCellStateQuantized);\n+    TfLiteTensor* fw_cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kFwCellStateQuantized,\n+                                       &fw_cell_state_quantized));\n     fw_cell_state_quantized->type = fw_input_to_output_weights->type;\n     fw_cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(fw_cell_state_quantized->dims,\n@@ -685,8 +723,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwCellStateQuantized] =\n         op_data->scratch_tensor_index + kBwCellStateQuantized;\n-    TfLiteTensor* bw_cell_state_quantized =\n-        GetTemporary(context, node, kBwCellStateQuantized);\n+    TfLiteTensor* bw_cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kBwCellStateQuantized,\n+                                       &bw_cell_state_quantized));\n     bw_cell_state_quantized->type = fw_input_to_output_weights->type;\n     bw_cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(bw_cell_state_quantized->dims,\n@@ -705,7 +745,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // the scaling factor of the matrix).\n     node->temporaries->data[kInputScalingFactors] =\n         op_data->scratch_tensor_index + kInputScalingFactors;\n-    TfLiteTensor* input_sf = GetTemporary(context, node, kInputScalingFactors);\n+    TfLiteTensor* input_sf;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kInputScalingFactors, &input_sf));\n     input_sf->type = kTfLiteFloat32;\n     input_sf->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {n_batch};\n@@ -717,8 +760,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kAuxInputScalingFactors] =\n         op_data->scratch_tensor_index + kAuxInputScalingFactors;\n-    TfLiteTensor* aux_input_sf =\n-        GetTemporary(context, node, kAuxInputScalingFactors);\n+    TfLiteTensor* aux_input_sf;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kAuxInputScalingFactors,\n+                                       &aux_input_sf));\n     aux_input_sf->type = kTfLiteFloat32;\n     aux_input_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(aux_input_sf->dims, 1, scaling_dims)) {\n@@ -729,8 +774,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateScalingFactors] =\n         op_data->scratch_tensor_index + kOutputStateScalingFactors;\n-    TfLiteTensor* output_state_sf =\n-        GetTemporary(context, node, kOutputStateScalingFactors);\n+    TfLiteTensor* output_state_sf;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kOutputStateScalingFactors,\n+                                  &output_state_sf));\n     output_state_sf->type = kTfLiteFloat32;\n     output_state_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_sf->dims, 1, scaling_dims)) {\n@@ -741,8 +788,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kProductScalingFactors] =\n         op_data->scratch_tensor_index + kProductScalingFactors;\n-    TfLiteTensor* prod_scaling_factors =\n-        GetTemporary(context, node, kProductScalingFactors);\n+    TfLiteTensor* prod_scaling_factors;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kProductScalingFactors,\n+                                       &prod_scaling_factors));\n     prod_scaling_factors->type = kTfLiteFloat32;\n     prod_scaling_factors->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(prod_scaling_factors->dims, 1,\n@@ -758,8 +807,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // this is used for diagonal matrices, only need to store n_cell values.\n     node->temporaries->data[kRecoveredCellWeights] =\n         op_data->scratch_tensor_index + kRecoveredCellWeights;\n-    TfLiteTensor* recovered_cell_weights =\n-        GetTemporary(context, node, kRecoveredCellWeights);\n+    TfLiteTensor* recovered_cell_weights;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                       &recovered_cell_weights));\n     recovered_cell_weights->type = kTfLiteFloat32;\n     recovered_cell_weights->allocation_type = kTfLiteArenaRw;\n     int recovered_cell_dims[1] = {n_fw_cell};\n@@ -775,8 +826,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate a temporary tensor to store the accumulated int32 values.\n     node->temporaries->data[kAccumScratchBuffer] =\n         op_data->scratch_tensor_index + kAccumScratchBuffer;\n-    TfLiteTensor* accum_scratch =\n-        GetTemporary(context, node, kAccumScratchBuffer);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kAccumScratchBuffer, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int n_cell = std::max(n_fw_cell, n_bw_cell);\n@@ -797,7 +850,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate temporary tensors for storing zero-points.\n     node->temporaries->data[kInputZeroPoints] =\n         op_data->scratch_tensor_index + kInputZeroPoints;\n-    TfLiteTensor* input_zp = GetTemporary(context, node, kInputZeroPoints);\n+    TfLiteTensor* input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kInputZeroPoints, &input_zp));\n     input_zp->type = kTfLiteFloat32;\n     input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_zp->dims, 1, scaling_dims)) {\n@@ -808,8 +863,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kAuxInputZeroPoints] =\n         op_data->scratch_tensor_index + kAuxInputZeroPoints;\n-    TfLiteTensor* aux_input_zp =\n-        GetTemporary(context, node, kAuxInputZeroPoints);\n+    TfLiteTensor* aux_input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kAuxInputZeroPoints, &aux_input_zp));\n     aux_input_zp->type = kTfLiteFloat32;\n     aux_input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(aux_input_zp->dims, 1, scaling_dims)) {\n@@ -820,8 +877,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateZeroPoints] =\n         op_data->scratch_tensor_index + kOutputStateZeroPoints;\n-    TfLiteTensor* output_state_zp =\n-        GetTemporary(context, node, kOutputStateZeroPoints);\n+    TfLiteTensor* output_state_zp;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateZeroPoints,\n+                                       &output_state_zp));\n     output_state_zp->type = kTfLiteFloat32;\n     output_state_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_zp->dims, 1, scaling_dims)) {\n@@ -844,7 +903,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kFwRowSums] =\n         op_data->scratch_tensor_index + kFwRowSums;\n-    TfLiteTensor* fw_row_sums = GetTemporary(context, node, kFwRowSums);\n+    TfLiteTensor* fw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kFwRowSums, &fw_row_sums));\n     fw_row_sums->type = kTfLiteInt32;\n     fw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int fw_row_sums_dims[2] = {fw_row_sums_rows, n_fw_cell};\n@@ -867,7 +928,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwRowSums] =\n         op_data->scratch_tensor_index + kBwRowSums;\n-    TfLiteTensor* bw_row_sums = GetTemporary(context, node, kBwRowSums);\n+    TfLiteTensor* bw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kBwRowSums, &bw_row_sums));\n     bw_row_sums->type = kTfLiteInt32;\n     bw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int bw_row_sums_dims[2] = {bw_row_sums_rows, n_bw_cell};\n@@ -884,8 +947,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     if (has_aux_input) {\n       node->temporaries->data[kAuxInputQuantized] =\n           op_data->scratch_tensor_index + kAuxInputQuantized;\n-      TfLiteTensor* aux_input_quantized =\n-          GetTemporary(context, node, kAuxInputQuantized);\n+      TfLiteTensor* aux_input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kAuxInputQuantized,\n+                                         &aux_input_quantized));\n       aux_input_quantized->type = fw_input_to_output_weights->type;\n       aux_input_quantized->allocation_type = kTfLiteArenaRw;\n       if (!TfLiteIntArrayEqual(aux_input_quantized->dims, aux_input->dims)) {\n@@ -906,26 +971,39 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       node->builtin_data);\n   auto* op_data = reinterpret_cast<OpData*>(node->user_data);\n   // Input tensor.\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n \n   // Tensors for the forward cell.\n   const TfLiteTensor* fw_input_to_input_weights =\n       GetOptionalInputTensor(context, node, kFwInputToInputWeightsTensor);\n-  const TfLiteTensor* fw_input_to_forget_weights =\n-      GetInput(context, node, kFwInputToForgetWeightsTensor);\n-  const TfLiteTensor* fw_input_to_cell_weights =\n-      GetInput(context, node, kFwInputToCellWeightsTensor);\n-  const TfLiteTensor* fw_input_to_output_weights =\n-      GetInput(context, node, kFwInputToOutputWeightsTensor);\n+  const TfLiteTensor* fw_input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToForgetWeightsTensor,\n+                                 &fw_input_to_forget_weights));\n+  const TfLiteTensor* fw_input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToCellWeightsTensor,\n+                                 &fw_input_to_cell_weights));\n+  const TfLiteTensor* fw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToOutputWeightsTensor,\n+                                 &fw_input_to_output_weights));\n \n   const TfLiteTensor* fw_recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kFwRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_to_forget_weights =\n-      GetInput(context, node, kFwRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_to_cell_weights =\n-      GetInput(context, node, kFwRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_to_output_weights =\n-      GetInput(context, node, kFwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* fw_recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kFwRecurrentToForgetWeightsTensor,\n+                            &fw_recurrent_to_forget_weights));\n+  const TfLiteTensor* fw_recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwRecurrentToCellWeightsTensor,\n+                                 &fw_recurrent_to_cell_weights));\n+  const TfLiteTensor* fw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kFwRecurrentToOutputWeightsTensor,\n+                            &fw_recurrent_to_output_weights));\n \n   const TfLiteTensor* fw_cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kFwCellToInputWeightsTensor);\n@@ -936,12 +1014,17 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* fw_input_gate_bias =\n       GetOptionalInputTensor(context, node, kFwInputGateBiasTensor);\n-  const TfLiteTensor* fw_forget_gate_bias =\n-      GetInput(context, node, kFwForgetGateBiasTensor);\n-  const TfLiteTensor* fw_cell_gate_bias =\n-      GetInput(context, node, kFwCellGateBiasTensor);\n-  const TfLiteTensor* fw_output_gate_bias =\n-      GetInput(context, node, kFwOutputGateBiasTensor);\n+  const TfLiteTensor* fw_forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwForgetGateBiasTensor,\n+                                 &fw_forget_gate_bias));\n+  const TfLiteTensor* fw_cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwCellGateBiasTensor,\n+                                          &fw_cell_gate_bias));\n+  const TfLiteTensor* fw_output_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwOutputGateBiasTensor,\n+                                 &fw_output_gate_bias));\n \n   const TfLiteTensor* fw_projection_weights =\n       GetOptionalInputTensor(context, node, kFwProjectionWeightsTensor);\n@@ -950,30 +1033,44 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   TfLiteTensor* fw_activation_state =\n       GetVariableInput(context, node, kFwInputActivationStateTensor);\n-  TF_LITE_ENSURE(context, fw_activation_state != nullptr);\n+  TFLITE_DCHECK(fw_activation_state != nullptr);\n   TfLiteTensor* fw_cell_state =\n       GetVariableInput(context, node, kFwInputCellStateTensor);\n-  TF_LITE_ENSURE(context, fw_cell_state != nullptr);\n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TFLITE_DCHECK(fw_cell_state != nullptr);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n \n   // Tensors for the backward cell.\n   const TfLiteTensor* bw_input_to_input_weights =\n       GetOptionalInputTensor(context, node, kBwInputToInputWeightsTensor);\n-  const TfLiteTensor* bw_input_to_forget_weights =\n-      GetInput(context, node, kBwInputToForgetWeightsTensor);\n-  const TfLiteTensor* bw_input_to_cell_weights =\n-      GetInput(context, node, kBwInputToCellWeightsTensor);\n-  const TfLiteTensor* bw_input_to_output_weights =\n-      GetInput(context, node, kBwInputToOutputWeightsTensor);\n+  const TfLiteTensor* bw_input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToForgetWeightsTensor,\n+                                 &bw_input_to_forget_weights));\n+  const TfLiteTensor* bw_input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToCellWeightsTensor,\n+                                 &bw_input_to_cell_weights));\n+  const TfLiteTensor* bw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToOutputWeightsTensor,\n+                                 &bw_input_to_output_weights));\n \n   const TfLiteTensor* bw_recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kBwRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_to_forget_weights =\n-      GetInput(context, node, kBwRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_to_cell_weights =\n-      GetInput(context, node, kBwRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_to_output_weights =\n-      GetInput(context, node, kBwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* bw_recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kBwRecurrentToForgetWeightsTensor,\n+                            &bw_recurrent_to_forget_weights));\n+  const TfLiteTensor* bw_recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwRecurrentToCellWeightsTensor,\n+                                 &bw_recurrent_to_cell_weights));\n+  const TfLiteTensor* bw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kBwRecurrentToOutputWeightsTensor,\n+                            &bw_recurrent_to_output_weights));\n \n   const TfLiteTensor* bw_cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kBwCellToInputWeightsTensor);\n@@ -984,12 +1081,17 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* bw_input_gate_bias =\n       GetOptionalInputTensor(context, node, kBwInputGateBiasTensor);\n-  const TfLiteTensor* bw_forget_gate_bias =\n-      GetInput(context, node, kBwForgetGateBiasTensor);\n-  const TfLiteTensor* bw_cell_gate_bias =\n-      GetInput(context, node, kBwCellGateBiasTensor);\n-  const TfLiteTensor* bw_output_gate_bias =\n-      GetInput(context, node, kBwOutputGateBiasTensor);\n+  const TfLiteTensor* bw_forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwForgetGateBiasTensor,\n+                                 &bw_forget_gate_bias));\n+  const TfLiteTensor* bw_cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwCellGateBiasTensor,\n+                                          &bw_cell_gate_bias));\n+  const TfLiteTensor* bw_output_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwOutputGateBiasTensor,\n+                                 &bw_output_gate_bias));\n \n   const TfLiteTensor* bw_projection_weights =\n       GetOptionalInputTensor(context, node, kBwProjectionWeightsTensor);\n@@ -999,19 +1101,21 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   // State tensors.\n   TfLiteTensor* bw_activation_state =\n       GetVariableInput(context, node, kBwInputActivationStateTensor);\n-  TF_LITE_ENSURE(context, bw_activation_state != nullptr);\n+  TFLITE_DCHECK(bw_activation_state != nullptr);\n   TfLiteTensor* bw_cell_state =\n       GetVariableInput(context, node, kBwInputCellStateTensor);\n-  TF_LITE_ENSURE(context, bw_cell_state != nullptr);\n+  TFLITE_DCHECK(bw_cell_state != nullptr);\n   TfLiteTensor* bw_output = params->merge_outputs\n                                 ? nullptr\n                                 : GetOutput(context, node, kBwOutputTensor);\n \n   // Temporary tensors.\n-  TfLiteTensor* fw_scratch_buffer =\n-      GetTemporary(context, node, kFwScratchBuffer);\n-  TfLiteTensor* bw_scratch_buffer =\n-      GetTemporary(context, node, kBwScratchBuffer);\n+  TfLiteTensor* fw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kFwScratchBuffer,\n+                                              &fw_scratch_buffer));\n+  TfLiteTensor* bw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kBwScratchBuffer,\n+                                              &bw_scratch_buffer));\n \n   // (Optional) auxiliary inputs.\n   const TfLiteTensor* aux_input =\n@@ -1112,27 +1216,47 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     }\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n-      TfLiteTensor* input_quantized =\n-          GetTemporary(context, node, kInputQuantized);\n-      TfLiteTensor* fw_activation_state_quantized =\n-          GetTemporary(context, node, kFwActivationStateQuantized);\n-      TfLiteTensor* bw_activation_state_quantized =\n-          GetTemporary(context, node, kBwActivationStateQuantized);\n-      TfLiteTensor* fw_cell_state_quantized =\n-          GetTemporary(context, node, kFwCellStateQuantized);\n-      TfLiteTensor* bw_cell_state_quantized =\n-          GetTemporary(context, node, kBwCellStateQuantized);\n-      TfLiteTensor* prod_scaling_factors =\n-          GetTemporary(context, node, kProductScalingFactors);\n-      TfLiteTensor* recovered_cell_weights =\n-          GetTemporary(context, node, kRecoveredCellWeights);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kInputQuantized, &input_quantized));\n+      TfLiteTensor* fw_activation_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kFwActivationStateQuantized,\n+                                    &fw_activation_state_quantized));\n+      TfLiteTensor* bw_activation_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kBwActivationStateQuantized,\n+                                    &bw_activation_state_quantized));\n+      TfLiteTensor* fw_cell_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kFwCellStateQuantized,\n+                                         &fw_cell_state_quantized));\n+      TfLiteTensor* bw_cell_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kBwCellStateQuantized,\n+                                         &bw_cell_state_quantized));\n+      TfLiteTensor* prod_scaling_factors;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kProductScalingFactors,\n+                                         &prod_scaling_factors));\n+      TfLiteTensor* recovered_cell_weights;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                         &recovered_cell_weights));\n       TfLiteTensor* aux_input_quantized =\n           use_aux_input ? GetTemporary(context, node, kAuxInputQuantized)\n                         : nullptr;\n-      TfLiteTensor* accum_scratch =\n-          GetTemporary(context, node, kAccumScratchBuffer);\n-      TfLiteTensor* fw_row_sums = GetTemporary(context, node, kFwRowSums);\n-      TfLiteTensor* bw_row_sums = GetTemporary(context, node, kBwRowSums);\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kAccumScratchBuffer, &accum_scratch));\n+      TfLiteTensor* fw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kFwRowSums, &fw_row_sums));\n+      TfLiteTensor* bw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kBwRowSums, &bw_row_sums));\n       const int fw_row_sums_size = fw_row_sums->dims->data[0];\n       const int bw_row_sums_size = bw_row_sums->dims->data[0];\n       TfLiteStatus fw_pass_status = lstm_eval::EvalHybrid("
    },
    "modified_file_9": {
        "mod_filename": "tensorflow/lite/kernels/bidirectional_sequence_rnn.cc",
        "status": "modified",
        "add_lines": 122,
        "dele_lines": 60,
        "patch": "@@ -97,21 +97,34 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->outputs->size,\n                     params->merge_outputs ? 1 : 2);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* fw_input_weights =\n-      GetInput(context, node, kFwWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_weights =\n-      GetInput(context, node, kFwRecurrentWeightsTensor);\n-  const TfLiteTensor* fw_bias = GetInput(context, node, kFwBiasTensor);\n-  const TfLiteTensor* fw_hidden_state =\n-      GetInput(context, node, kFwHiddenStateTensor);\n-  const TfLiteTensor* bw_input_weights =\n-      GetInput(context, node, kBwWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_weights =\n-      GetInput(context, node, kBwRecurrentWeightsTensor);\n-  const TfLiteTensor* bw_bias = GetInput(context, node, kBwBiasTensor);\n-  const TfLiteTensor* bw_hidden_state =\n-      GetInput(context, node, kBwHiddenStateTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* fw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwWeightsTensor,\n+                                          &fw_input_weights));\n+  const TfLiteTensor* fw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwRecurrentWeightsTensor,\n+                                 &fw_recurrent_weights));\n+  const TfLiteTensor* fw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwBiasTensor, &fw_bias));\n+  const TfLiteTensor* fw_hidden_state;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwHiddenStateTensor,\n+                                          &fw_hidden_state));\n+  const TfLiteTensor* bw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwWeightsTensor,\n+                                          &bw_input_weights));\n+  const TfLiteTensor* bw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwRecurrentWeightsTensor,\n+                                 &bw_recurrent_weights));\n+  const TfLiteTensor* bw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwBiasTensor, &bw_bias));\n+  const TfLiteTensor* bw_hidden_state;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwHiddenStateTensor,\n+                                          &bw_hidden_state));\n \n   const TfLiteTensor* aux_input =\n       GetOptionalInputTensor(context, node, kAuxInputTensor);\n@@ -186,8 +199,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kInputQuantized] =\n         op_data->scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = fw_input_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -198,8 +212,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kFwHiddenStateQuantized] =\n         op_data->scratch_tensor_index + kFwHiddenStateQuantized;\n-    TfLiteTensor* fw_hidden_state_quantized =\n-        GetTemporary(context, node, kFwHiddenStateQuantized);\n+    TfLiteTensor* fw_hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kFwHiddenStateQuantized,\n+                                       &fw_hidden_state_quantized));\n     fw_hidden_state_quantized->type = fw_input_weights->type;\n     fw_hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(fw_hidden_state_quantized->dims,\n@@ -213,8 +229,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kBwHiddenStateQuantized] =\n         op_data->scratch_tensor_index + kBwHiddenStateQuantized;\n-    TfLiteTensor* bw_hidden_state_quantized =\n-        GetTemporary(context, node, kBwHiddenStateQuantized);\n+    TfLiteTensor* bw_hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kBwHiddenStateQuantized,\n+                                       &bw_hidden_state_quantized));\n     bw_hidden_state_quantized->type = fw_input_weights->type;\n     bw_hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(bw_hidden_state_quantized->dims,\n@@ -229,8 +247,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate temporary tensors to store scaling factors of quantization.\n     node->temporaries->data[kScalingFactors] =\n         op_data->scratch_tensor_index + kScalingFactors;\n-    TfLiteTensor* scaling_factors =\n-        GetTemporary(context, node, kScalingFactors);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScalingFactors,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -242,7 +261,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kAccumScratch] =\n         op_data->scratch_tensor_index + kAccumScratch;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {std::max(fw_num_units, bw_num_units),\n@@ -257,8 +278,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kZeroPoints] =\n         op_data->scratch_tensor_index + kZeroPoints;\n-    TfLiteTensor* zero_points =\n-        GetTemporary(context, node, /*index=*/kZeroPoints);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, /*index=*/kZeroPoints, &zero_points));\n     zero_points->type = kTfLiteInt32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -271,8 +294,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     const int num_row_sums = has_aux_input ? 3 : 2;\n     node->temporaries->data[kFwRowSums] =\n         op_data->scratch_tensor_index + kFwRowSums;\n-    TfLiteTensor* fw_row_sums =\n-        GetTemporary(context, node, /*index=*/kFwRowSums);\n+    TfLiteTensor* fw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, /*index=*/kFwRowSums, &fw_row_sums));\n     fw_row_sums->type = kTfLiteInt32;\n     fw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int fw_row_sums_dims[2] = {num_row_sums, fw_num_units};\n@@ -285,8 +310,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwRowSums] =\n         op_data->scratch_tensor_index + kBwRowSums;\n-    TfLiteTensor* bw_row_sums = GetTemporary(context, node,\n-                                             /*index=*/kBwRowSums);\n+    TfLiteTensor* bw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, /*index=*/kBwRowSums, &bw_row_sums));\n     bw_row_sums->type = kTfLiteInt32;\n     bw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int bw_row_sums_dims[2] = {num_row_sums, bw_num_units};\n@@ -300,8 +327,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     if (has_aux_input) {\n       node->temporaries->data[kAuxInputQuantized] =\n           op_data->scratch_tensor_index + kAuxInputQuantized;\n-      TfLiteTensor* aux_input_quantized =\n-          GetTemporary(context, node, kAuxInputQuantized);\n+      TfLiteTensor* aux_input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kAuxInputQuantized,\n+                                         &aux_input_quantized));\n       aux_input_quantized->type = fw_input_weights->type;\n       aux_input_quantized->allocation_type = kTfLiteArenaRw;\n       if (!TfLiteIntArrayEqual(aux_input_quantized->dims, aux_input->dims)) {\n@@ -315,7 +344,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Resize outputs.\n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n   TfLiteIntArray* fw_output_size_array = TfLiteIntArrayCreate(3);\n   fw_output_size_array->data[0] = (time_major) ? max_time : batch_size;\n   fw_output_size_array->data[1] = (time_major) ? batch_size : max_time;\n@@ -324,7 +355,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(\n       context, context->ResizeTensor(context, fw_output, fw_output_size_array));\n   if (!params->merge_outputs) {\n-    TfLiteTensor* bw_output = GetOutput(context, node, kBwOutputTensor);\n+    TfLiteTensor* bw_output;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kBwOutputTensor, &bw_output));\n     TfLiteIntArray* bw_output_size_array = TfLiteIntArrayCreate(3);\n     bw_output_size_array->data[0] = batch_size;\n     bw_output_size_array->data[1] = max_time;\n@@ -678,17 +711,28 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const auto* params = reinterpret_cast<TfLiteBidirectionalSequenceRNNParams*>(\n       node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* fw_input_weights =\n-      GetInput(context, node, kFwWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_weights =\n-      GetInput(context, node, kFwRecurrentWeightsTensor);\n-  const TfLiteTensor* fw_bias = GetInput(context, node, kFwBiasTensor);\n-  const TfLiteTensor* bw_input_weights =\n-      GetInput(context, node, kBwWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_weights =\n-      GetInput(context, node, kBwRecurrentWeightsTensor);\n-  const TfLiteTensor* bw_bias = GetInput(context, node, kBwBiasTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* fw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwWeightsTensor,\n+                                          &fw_input_weights));\n+  const TfLiteTensor* fw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwRecurrentWeightsTensor,\n+                                 &fw_recurrent_weights));\n+  const TfLiteTensor* fw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwBiasTensor, &fw_bias));\n+  const TfLiteTensor* bw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwWeightsTensor,\n+                                          &bw_input_weights));\n+  const TfLiteTensor* bw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwRecurrentWeightsTensor,\n+                                 &bw_recurrent_weights));\n+  const TfLiteTensor* bw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwBiasTensor, &bw_bias));\n \n   // Get auxiliary inputs.\n   const TfLiteTensor* aux_input =\n@@ -700,12 +744,14 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   TfLiteTensor* fw_hidden_state =\n       GetVariableInput(context, node, kFwHiddenStateTensor);\n-  TF_LITE_ENSURE(context, fw_hidden_state != nullptr);\n+  TFLITE_DCHECK(fw_hidden_state != nullptr);\n   TfLiteTensor* bw_hidden_state =\n       GetVariableInput(context, node, kBwHiddenStateTensor);\n-  TF_LITE_ENSURE(context, bw_hidden_state != nullptr);\n+  TFLITE_DCHECK(bw_hidden_state != nullptr);\n \n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n   TfLiteTensor* bw_output = params->merge_outputs\n                                 ? nullptr\n                                 : GetOutput(context, node, kBwOutputTensor);\n@@ -741,18 +787,34 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                        bw_hidden_state, bw_output);\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n-      TfLiteTensor* input_quantized =\n-          GetTemporary(context, node, kInputQuantized);\n-      TfLiteTensor* fw_hidden_state_quantized =\n-          GetTemporary(context, node, kFwHiddenStateQuantized);\n-      TfLiteTensor* bw_hidden_state_quantized =\n-          GetTemporary(context, node, kBwHiddenStateQuantized);\n-      TfLiteTensor* scaling_factors =\n-          GetTemporary(context, node, kScalingFactors);\n-      TfLiteTensor* zero_points = GetTemporary(context, node, kZeroPoints);\n-      TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n-      TfLiteTensor* fw_row_sums = GetTemporary(context, node, kFwRowSums);\n-      TfLiteTensor* bw_row_sums = GetTemporary(context, node, kBwRowSums);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kInputQuantized, &input_quantized));\n+      TfLiteTensor* fw_hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kFwHiddenStateQuantized,\n+                                         &fw_hidden_state_quantized));\n+      TfLiteTensor* bw_hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kBwHiddenStateQuantized,\n+                                         &bw_hidden_state_quantized));\n+      TfLiteTensor* scaling_factors;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kScalingFactors, &scaling_factors));\n+      TfLiteTensor* zero_points;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kZeroPoints, &zero_points));\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                  &accum_scratch));\n+      TfLiteTensor* fw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kFwRowSums, &fw_row_sums));\n+      TfLiteTensor* bw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kBwRowSums, &bw_row_sums));\n       TfLiteTensor* aux_input_quantized =\n           use_aux_input ? GetTemporary(context, node, kAuxInputQuantized)\n                         : nullptr;"
    },
    "modified_file_10": {
        "mod_filename": "tensorflow/lite/kernels/cast.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -32,8 +32,11 @@ constexpr int kOutputTensor = 0;\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // TODO(ahentz): these two checks would make the new implementation\n   // incompatible with some existing models, where params is not specified. It\n@@ -98,8 +101,11 @@ TfLiteStatus copyToTensor(TfLiteContext* context, const FromT* in,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   const int num_elements = NumElements(input);\n   TF_LITE_ENSURE_EQ(context, num_elements, NumElements(output));\n   switch (input->type) {"
    },
    "modified_file_11": {
        "mod_filename": "tensorflow/lite/kernels/ceil.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -29,8 +29,11 @@ constexpr int kInputTensor = 0;\n constexpr int kOutputTensor = 0;\n \n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n@@ -40,8 +43,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   if (input->type != kTfLiteFloat32) {\n     TF_LITE_UNSUPPORTED_TYPE(context, input->type, \"Ceil\");\n   }"
    },
    "modified_file_12": {
        "mod_filename": "tensorflow/lite/kernels/comparisons.cc",
        "status": "modified",
        "add_lines": 63,
        "dele_lines": 21,
        "patch": "@@ -41,9 +41,15 @@ TfLiteStatus ComparisonPrepareCommon(TfLiteContext* context, TfLiteNode* node,\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Don't support string.\n   if (!is_string_allowed) {\n@@ -145,9 +151,15 @@ void ComparisonString(bool (*opname)(const StringRef&, const StringRef&),\n }\n \n TfLiteStatus EqualEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   bool requires_broadcast = !HaveSameShapes(input1, input2);\n   switch (input1->type) {\n     case kTfLiteBool:\n@@ -189,9 +201,15 @@ TfLiteStatus EqualEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus NotEqualEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   bool requires_broadcast = !HaveSameShapes(input1, input2);\n   switch (input1->type) {\n     case kTfLiteBool:\n@@ -233,9 +251,15 @@ TfLiteStatus NotEqualEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus GreaterEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   bool requires_broadcast = !HaveSameShapes(input1, input2);\n   switch (input1->type) {\n     case kTfLiteFloat32:\n@@ -268,9 +292,15 @@ TfLiteStatus GreaterEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus GreaterEqualEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   bool requires_broadcast = !HaveSameShapes(input1, input2);\n   switch (input1->type) {\n     case kTfLiteFloat32:\n@@ -303,9 +333,15 @@ TfLiteStatus GreaterEqualEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus LessEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   bool requires_broadcast = !HaveSameShapes(input1, input2);\n   switch (input1->type) {\n     case kTfLiteFloat32:\n@@ -338,9 +374,15 @@ TfLiteStatus LessEval(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus LessEqualEval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   bool requires_broadcast = !HaveSameShapes(input1, input2);\n   switch (input1->type) {\n     case kTfLiteFloat32:"
    },
    "modified_file_13": {
        "mod_filename": "tensorflow/lite/kernels/concatenation.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 5,
        "patch": "@@ -45,7 +45,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // The number of dimensions of the input tensors must match, and all\n   // dimensions except 'axis' must be equal.\n-  const TfLiteTensor* t0 = GetInput(context, node, 0);\n+  const TfLiteTensor* t0;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &t0));\n   TfLiteType input_type = t0->type;\n   if (axis < 0) axis += t0->dims->size;\n   TF_LITE_ENSURE(context, axis >= 0);\n@@ -63,7 +64,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // will be the sum of inputs\n   int sum_axis = t0->dims->data[axis];\n   for (int i = 1; i < num_inputs; ++i) {\n-    const TfLiteTensor* t = GetInput(context, node, i);\n+    const TfLiteTensor* t;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &t));\n     TF_LITE_ENSURE_EQ(context, t->dims->size, t0->dims->size);\n     TF_LITE_ENSURE_EQ(context, t->type, input_type);\n     for (int d = 0; d < t0->dims->size; ++d) {\n@@ -80,15 +82,17 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     output_size->data[d] = (d == axis) ? sum_axis : t0->dims->data[d];\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);\n \n   if (input_type == kTfLiteInt8) {\n     // Make sure there is no re-scaling needed for Int8 quantized kernel. This\n     // is a restriction we introduced to Int8 kernels.\n     VectorOfTensors<int8_t> all_inputs(*context, *node->inputs);\n     for (int i = 0; i < node->inputs->size; ++i) {\n-      const TfLiteTensor* t = GetInput(context, node, i);\n+      const TfLiteTensor* t;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &t));\n       TF_LITE_ENSURE_EQ(context, t->params.scale, output->params.scale);\n       TF_LITE_ENSURE_EQ(context, t->params.zero_point,\n                         output->params.zero_point);\n@@ -103,7 +107,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteConcatenationParams*>(node->builtin_data);\n   int axis = params->axis;\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   if (axis < 0) axis += output->dims->size;\n \n // TODO(ahentz): Creating 'all_inputs' below is not very efficient. We should"
    },
    "modified_file_14": {
        "mod_filename": "tensorflow/lite/kernels/conv.cc",
        "status": "modified",
        "add_lines": 96,
        "dele_lines": 48,
        "patch": "@@ -222,8 +222,10 @@ static TfLiteStatus AllocateTemporaryTensorsIfRequired(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   TF_LITE_ENSURE(context, node->inputs->size >= 2);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  const TfLiteTensor* filter = GetInput(context, node, 1);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));\n \n   // If we're using the optimized multithreaded EigenTensor implementation of\n   // convolution, it expects the filter weights to be transposed compared to\n@@ -316,9 +318,12 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n   // Check number of inputs/outputs\n   TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  const TfLiteTensor* filter = GetInput(context, node, 1);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));\n \n   // Check dimensionality of input, filter\n   TF_LITE_ENSURE_EQ(context, input->dims->size, 4);\n@@ -340,7 +345,7 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n   TF_LITE_ENSURE(context, has_bias);\n \n   if (has_bias) {\n-    bias = GetInput(context, node, 2);\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &bias));\n     if (input_type == kTfLiteUInt8 || input_type == kTfLiteInt8) {\n       TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n       TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n@@ -493,8 +498,10 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n   if (is_hybrid) {\n     node->temporaries->data[data->input_quantized_index] =\n         data->input_quantized_id;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, data->input_quantized_index);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, data->input_quantized_index,\n+                                  &input_quantized));\n     input_quantized->type = kTfLiteInt8;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -505,8 +512,10 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n \n     node->temporaries->data[data->scaling_factors_index] =\n         data->scaling_factors_id;\n-    TfLiteTensor* scaling_factors =\n-        GetTemporary(context, node, data->scaling_factors_index);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n+                                  &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     // Only one scale factor per batch is typically necessary. See optimized\n@@ -522,8 +531,10 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n     }\n \n     node->temporaries->data[data->accum_scratch_index] = data->accum_scratch_id;\n-    TfLiteTensor* accum_scratch =\n-        GetTemporary(context, node, data->accum_scratch_index);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, data->accum_scratch_index,\n+                                       &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     const int scratch_width = batches * out_height * out_width;\n@@ -545,8 +556,10 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n           context, affine_quantization->scale->size,\n           filter->dims->data[affine_quantization->quantized_dimension]);\n       node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n-      TfLiteTensor* input_offsets =\n-          GetTemporary(context, node, data->input_offset_index);\n+      TfLiteTensor* input_offsets;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->input_offset_index,\n+                                    &input_offsets));\n       input_offsets->type = kTfLiteInt32;\n       input_offsets->allocation_type = kTfLiteArenaRw;\n       // See above comment for the need to allocate for height of inputs.\n@@ -560,8 +573,10 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n                                                          input_offsets_size));\n       }\n       node->temporaries->data[data->row_sums_index] = data->row_sums_id;\n-      TfLiteTensor* row_sums =\n-          GetTemporary(context, node, data->row_sums_index);\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, data->row_sums_index, &row_sums));\n       row_sums->type = kTfLiteInt32;\n       row_sums->allocation_type = kTfLiteArenaRwPersistent;\n       // See above comment for the need to allocate for height of inputs.\n@@ -802,23 +817,34 @@ void EvalFloat(TfLiteContext* context, TfLiteNode* node,\n }\n \n template <KernelType kernel_type>\n-void EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n-                          TfLiteConvParams* params, OpData* data,\n-                          const TfLiteTensor* input, const TfLiteTensor* filter,\n-                          const TfLiteTensor* bias, TfLiteTensor* im2col,\n-                          TfLiteTensor* output) {\n+TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n+                                  TfLiteConvParams* params, OpData* data,\n+                                  const TfLiteTensor* input,\n+                                  const TfLiteTensor* filter,\n+                                  const TfLiteTensor* bias,\n+                                  TfLiteTensor* im2col, TfLiteTensor* output) {\n   float output_activation_min, output_activation_max;\n   CalculateActivationRange(params->activation, &output_activation_min,\n                            &output_activation_max);\n \n   const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n   const int batch_size = SizeOfDimension(input, 0);\n-  int8_t* quantized_input_ptr_batch = GetTensorData<int8_t>(\n-      GetTemporary(context, node, data->input_quantized_index));\n-  float* scaling_factors_ptr = GetTensorData<float>(\n-      GetTemporary(context, node, data->scaling_factors_index));\n-  int32_t* input_offset_ptr = GetTensorData<int32_t>(\n-      GetTemporary(context, node, data->input_offset_index));\n+  TfLiteTensor* quantized_input_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->input_quantized_index,\n+                                     &quantized_input_tensor));\n+  int8_t* quantized_input_ptr_batch =\n+      GetTensorData<int8_t>(quantized_input_tensor);\n+  TfLiteTensor* scaling_factors_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->scaling_factors_index,\n+                                     &scaling_factors_tensor));\n+  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n+  TfLiteTensor* input_offset_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->input_offset_index,\n+                                     &input_offset_tensor));\n+  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n \n   for (int b = 0; b < batch_size; ++b) {\n     const int offset = b * input_size;\n@@ -859,10 +885,14 @@ void EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n     case kGenericOptimized:\n     case kMultithreadOptimized:\n     case kCblasOptimized: {\n-      TfLiteTensor* row_sums =\n-          GetTemporary(context, node, data->row_sums_index);\n-      TfLiteTensor* scratch =\n-          GetTemporary(context, node, data->accum_scratch_index);\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, data->row_sums_index, &row_sums));\n+      TfLiteTensor* scratch;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, data->accum_scratch_index, &scratch));\n       optimized_ops::HybridConvPerChannel(\n           op_params, scaling_factors_ptr, GetTensorShape(input),\n           quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,\n@@ -877,14 +907,16 @@ void EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n       break;\n     }\n   }\n+\n+  return kTfLiteOk;\n }\n \n template <KernelType kernel_type>\n-void EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n-                TfLiteConvParams* params, OpData* data,\n-                const TfLiteTensor* input, const TfLiteTensor* filter,\n-                const TfLiteTensor* bias, TfLiteTensor* im2col,\n-                TfLiteTensor* accum_scratch, TfLiteTensor* output) {\n+TfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n+                        TfLiteConvParams* params, OpData* data,\n+                        const TfLiteTensor* input, const TfLiteTensor* filter,\n+                        const TfLiteTensor* bias, TfLiteTensor* im2col,\n+                        TfLiteTensor* accum_scratch, TfLiteTensor* output) {\n   float output_activation_min, output_activation_max;\n   CalculateActivationRange(params->activation, &output_activation_min,\n                            &output_activation_max);\n@@ -893,10 +925,17 @@ void EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n   const int batch_size = SizeOfDimension(input, 0);\n \n   const float* input_ptr = GetTensorData<float>(input);\n-  int8_t* quantized_input_ptr_batch = GetTensorData<int8_t>(\n-      GetTemporary(context, node, data->input_quantized_index));\n-  float* scaling_factors_ptr = GetTensorData<float>(\n-      GetTemporary(context, node, data->scaling_factors_index));\n+  TfLiteTensor* quantized_input_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->input_quantized_index,\n+                                     &quantized_input_tensor));\n+  int8_t* quantized_input_ptr_batch =\n+      GetTensorData<int8_t>(quantized_input_tensor);\n+  TfLiteTensor* scaling_factors_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->scaling_factors_index,\n+                                     &scaling_factors_tensor));\n+  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n \n   // Per-batch input quantization for higher accuracy.\n   {\n@@ -939,16 +978,21 @@ void EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n       break;\n     }\n   }\n+\n+  return kTfLiteOk;\n }\n \n template <KernelType kernel_type, TfLiteType input_type>\n TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  const TfLiteTensor* filter = GetInput(context, node, 1);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));\n   bool has_bias = node->inputs->size == 3;\n   const TfLiteTensor* bias = has_bias ? GetInput(context, node, 2) : nullptr;\n   TfLiteTensor* im2col =\n@@ -970,14 +1014,17 @@ TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteFloat32:\n       if (filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8) {\n         if (data->is_hybrid_per_channel) {\n-          EvalHybridPerChannel<kernel_type>(context, node, params, data, input,\n-                                            filter, bias, im2col, output);\n+          TF_LITE_ENSURE_OK(context, EvalHybridPerChannel<kernel_type>(\n+                                         context, node, params, data, input,\n+                                         filter, bias, im2col, output));\n         } else {\n           TfLiteTensor* accum_scratch =\n               &context->tensors[node->temporaries\n                                     ->data[data->accum_scratch_index]];\n-          EvalHybrid<kernel_type>(context, node, params, data, input, filter,\n-                                  bias, im2col, accum_scratch, output);\n+          TF_LITE_ENSURE_OK(context,\n+                            EvalHybrid<kernel_type>(context, node, params, data,\n+                                                    input, filter, bias, im2col,\n+                                                    accum_scratch, output));\n         }\n       } else {\n         EvalFloat<kernel_type>(context, node, params, data, input, filter, bias,\n@@ -1006,7 +1053,8 @@ TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node) {\n \n template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n \n   switch (input->type) {\n     case kTfLiteFloat32:"
    },
    "modified_file_15": {
        "mod_filename": "tensorflow/lite/kernels/depth_to_space.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -45,8 +45,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n \n@@ -84,8 +87,11 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteDepthToSpaceParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n #define TF_LITE_DEPTH_TO_SPACE(type, scalar)                               \\\n   tflite::DepthToSpaceParams op_params;                                    \\"
    },
    "modified_file_16": {
        "mod_filename": "tensorflow/lite/kernels/depthwise_conv.cc",
        "status": "modified",
        "add_lines": 45,
        "dele_lines": 20,
        "patch": "@@ -104,12 +104,17 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   bool hasBias = NumInputs(node) == 3;\n \n   TF_LITE_ENSURE(context, hasBias || NumInputs(node) == 2);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFilterTensor, &filter));\n   const TfLiteTensor* bias = nullptr;\n \n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n@@ -132,7 +137,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);\n \n   if (hasBias) {\n-    bias = GetInput(context, node, kBiasTensor);\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n     if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {\n       TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n       TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n@@ -224,8 +229,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[data->input_quantized_index] =\n         data->input_quantized_id;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, data->input_quantized_index);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, data->input_quantized_index,\n+                                  &input_quantized));\n     input_quantized->type = kTfLiteInt8;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -235,8 +242,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[data->scaling_factors_index] =\n         data->scaling_factors_id;\n-    TfLiteTensor* scaling_factors =\n-        GetTemporary(context, node, data->scaling_factors_index);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n+                                  &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     const int batch_size = SizeOfDimension(input, 0);\n@@ -248,8 +257,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        scaling_factors_size));\n     }\n     node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n-    TfLiteTensor* input_offsets =\n-        GetTemporary(context, node, data->input_offset_index);\n+    TfLiteTensor* input_offsets;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, data->input_offset_index,\n+                                       &input_offsets));\n     input_offsets->type = kTfLiteInt32;\n     input_offsets->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n@@ -446,13 +457,21 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                            &output_activation_max);\n   const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n   const int batch_size = SizeOfDimension(input, 0);\n-  const TfLiteTensor* input_quantized =\n-      GetTemporary(context, node, data->input_quantized_index);\n+  TfLiteTensor* input_quantized;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->input_quantized_index,\n+                                     &input_quantized));\n   int8_t* quantized_input_ptr_batch = input_quantized->data.int8;\n-  float* scaling_factors_ptr = GetTensorData<float>(\n-      GetTemporary(context, node, data->scaling_factors_index));\n-  int32_t* input_offset_ptr = GetTensorData<int32_t>(\n-      GetTemporary(context, node, data->input_offset_index));\n+  TfLiteTensor* scaling_factors_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->scaling_factors_index,\n+                                     &scaling_factors_tensor));\n+  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n+  TfLiteTensor* input_offset_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, data->input_offset_index,\n+                                     &input_offset_tensor));\n+  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n \n   for (int b = 0; b < batch_size; ++b) {\n     const int offset = b * input_size;\n@@ -504,9 +523,14 @@ TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node) {\n       reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* filter = GetInput(context, node, kFilterTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFilterTensor, &filter));\n   const TfLiteTensor* bias =\n       (NumInputs(node) == 3) ? GetInput(context, node, kBiasTensor) : nullptr;\n   TFLITE_DCHECK_EQ(input_type, input->type);\n@@ -547,7 +571,8 @@ TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node) {\n \n template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n \n   switch (input->type) {  // Already know in/out types are same.\n     case kTfLiteFloat32:"
    },
    "modified_file_17": {
        "mod_filename": "tensorflow/lite/kernels/detection_postprocess.cc",
        "status": "modified",
        "add_lines": 94,
        "dele_lines": 48,
        "patch": "@@ -146,12 +146,17 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   auto* op_data = static_cast<OpData*>(node->user_data);\n   // Inputs: box_encodings, scores, anchors\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 3);\n-  const TfLiteTensor* input_box_encodings =\n-      GetInput(context, node, kInputTensorBoxEncodings);\n-  const TfLiteTensor* input_class_predictions =\n-      GetInput(context, node, kInputTensorClassPredictions);\n-  const TfLiteTensor* input_anchors =\n-      GetInput(context, node, kInputTensorAnchors);\n+  const TfLiteTensor* input_box_encodings;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorBoxEncodings,\n+                                 &input_box_encodings));\n+  const TfLiteTensor* input_class_predictions;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorClassPredictions,\n+                                 &input_class_predictions));\n+  const TfLiteTensor* input_anchors;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensorAnchors,\n+                                          &input_anchors));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_box_encodings), 3);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_class_predictions), 3);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_anchors), 2);\n@@ -163,27 +168,35 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // num_detections\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 4);\n   // Output Tensor detection_boxes: size is set to (1, num_detected_boxes, 4)\n-  TfLiteTensor* detection_boxes =\n-      GetOutput(context, node, kOutputTensorDetectionBoxes);\n+  TfLiteTensor* detection_boxes;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionBoxes,\n+                                  &detection_boxes));\n   detection_boxes->type = kTfLiteFloat32;\n   SetTensorSizes(context, detection_boxes,\n                  {kBatchSize, num_detected_boxes, kNumCoordBox});\n \n   // Output Tensor detection_classes: size is set to (1, num_detected_boxes)\n-  TfLiteTensor* detection_classes =\n-      GetOutput(context, node, kOutputTensorDetectionClasses);\n+  TfLiteTensor* detection_classes;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionClasses,\n+                                  &detection_classes));\n   detection_classes->type = kTfLiteFloat32;\n   SetTensorSizes(context, detection_classes, {kBatchSize, num_detected_boxes});\n \n   // Output Tensor detection_scores: size is set to (1, num_detected_boxes)\n-  TfLiteTensor* detection_scores =\n-      GetOutput(context, node, kOutputTensorDetectionScores);\n+  TfLiteTensor* detection_scores;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionScores,\n+                                  &detection_scores));\n   detection_scores->type = kTfLiteFloat32;\n   SetTensorSizes(context, detection_scores, {kBatchSize, num_detected_boxes});\n \n   // Output Tensor num_detections: size is set to 1\n-  TfLiteTensor* num_detections =\n-      GetOutput(context, node, kOutputTensorNumDetections);\n+  TfLiteTensor* num_detections;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorNumDetections,\n+                                  &num_detections));\n   num_detections->type = kTfLiteFloat32;\n   // TODO (chowdhery): Make it a scalar when available\n   SetTensorSizes(context, num_detections, {1});\n@@ -269,13 +282,16 @@ T ReInterpretTensor(TfLiteTensor* tensor) {\n TfLiteStatus DecodeCenterSizeBoxes(TfLiteContext* context, TfLiteNode* node,\n                                    OpData* op_data) {\n   // Parse input tensor boxencodings\n-  const TfLiteTensor* input_box_encodings =\n-      GetInput(context, node, kInputTensorBoxEncodings);\n+  const TfLiteTensor* input_box_encodings;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorBoxEncodings,\n+                                 &input_box_encodings));\n   TF_LITE_ENSURE_EQ(context, input_box_encodings->dims->data[0], kBatchSize);\n   const int num_boxes = input_box_encodings->dims->data[1];\n   TF_LITE_ENSURE(context, input_box_encodings->dims->data[2] >= kNumCoordBox);\n-  const TfLiteTensor* input_anchors =\n-      GetInput(context, node, kInputTensorAnchors);\n+  const TfLiteTensor* input_anchors;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensorAnchors,\n+                                          &input_anchors));\n \n   // Decode the boxes to get (ymin, xmin, ymax, xmax) based on the anchors\n   CenterSizeEncoding box_centersize;\n@@ -389,8 +405,10 @@ TfLiteStatus NonMaxSuppressionSingleClassHelper(\n     TfLiteContext* context, TfLiteNode* node, OpData* op_data,\n     const std::vector<float>& scores, std::vector<int>* selected,\n     int max_detections) {\n-  const TfLiteTensor* input_box_encodings =\n-      GetInput(context, node, kInputTensorBoxEncodings);\n+  const TfLiteTensor* input_box_encodings;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorBoxEncodings,\n+                                 &input_box_encodings));\n   const TfLiteTensor* decoded_boxes =\n       &context->tensors[op_data->decoded_boxes_index];\n   const int num_boxes = input_box_encodings->dims->data[1];\n@@ -468,21 +486,33 @@ TfLiteStatus NonMaxSuppressionMultiClassRegularHelper(TfLiteContext* context,\n                                                       TfLiteNode* node,\n                                                       OpData* op_data,\n                                                       const float* scores) {\n-  const TfLiteTensor* input_box_encodings =\n-      GetInput(context, node, kInputTensorBoxEncodings);\n-  const TfLiteTensor* input_class_predictions =\n-      GetInput(context, node, kInputTensorClassPredictions);\n+  const TfLiteTensor* input_box_encodings;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorBoxEncodings,\n+                                 &input_box_encodings));\n+  const TfLiteTensor* input_class_predictions;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorClassPredictions,\n+                                 &input_class_predictions));\n   const TfLiteTensor* decoded_boxes =\n       &context->tensors[op_data->decoded_boxes_index];\n \n-  TfLiteTensor* detection_boxes =\n-      GetOutput(context, node, kOutputTensorDetectionBoxes);\n-  TfLiteTensor* detection_classes =\n-      GetOutput(context, node, kOutputTensorDetectionClasses);\n-  TfLiteTensor* detection_scores =\n-      GetOutput(context, node, kOutputTensorDetectionScores);\n-  TfLiteTensor* num_detections =\n-      GetOutput(context, node, kOutputTensorNumDetections);\n+  TfLiteTensor* detection_boxes;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionBoxes,\n+                                  &detection_boxes));\n+  TfLiteTensor* detection_classes;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionClasses,\n+                                  &detection_classes));\n+  TfLiteTensor* detection_scores;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionScores,\n+                                  &detection_scores));\n+  TfLiteTensor* num_detections;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorNumDetections,\n+                                  &num_detections));\n \n   const int num_boxes = input_box_encodings->dims->data[1];\n   const int num_classes = op_data->num_classes;\n@@ -595,21 +625,33 @@ TfLiteStatus NonMaxSuppressionMultiClassFastHelper(TfLiteContext* context,\n                                                    TfLiteNode* node,\n                                                    OpData* op_data,\n                                                    const float* scores) {\n-  const TfLiteTensor* input_box_encodings =\n-      GetInput(context, node, kInputTensorBoxEncodings);\n-  const TfLiteTensor* input_class_predictions =\n-      GetInput(context, node, kInputTensorClassPredictions);\n+  const TfLiteTensor* input_box_encodings;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorBoxEncodings,\n+                                 &input_box_encodings));\n+  const TfLiteTensor* input_class_predictions;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorClassPredictions,\n+                                 &input_class_predictions));\n   const TfLiteTensor* decoded_boxes =\n       &context->tensors[op_data->decoded_boxes_index];\n \n-  TfLiteTensor* detection_boxes =\n-      GetOutput(context, node, kOutputTensorDetectionBoxes);\n-  TfLiteTensor* detection_classes =\n-      GetOutput(context, node, kOutputTensorDetectionClasses);\n-  TfLiteTensor* detection_scores =\n-      GetOutput(context, node, kOutputTensorDetectionScores);\n-  TfLiteTensor* num_detections =\n-      GetOutput(context, node, kOutputTensorNumDetections);\n+  TfLiteTensor* detection_boxes;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionBoxes,\n+                                  &detection_boxes));\n+  TfLiteTensor* detection_classes;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionClasses,\n+                                  &detection_classes));\n+  TfLiteTensor* detection_scores;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorDetectionScores,\n+                                  &detection_scores));\n+  TfLiteTensor* num_detections;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensorNumDetections,\n+                                  &num_detections));\n \n   const int num_boxes = input_box_encodings->dims->data[1];\n   const int num_classes = op_data->num_classes;\n@@ -680,10 +722,14 @@ void DequantizeClassPredictions(const TfLiteTensor* input_class_predictions,\n TfLiteStatus NonMaxSuppressionMultiClass(TfLiteContext* context,\n                                          TfLiteNode* node, OpData* op_data) {\n   // Get the input tensors\n-  const TfLiteTensor* input_box_encodings =\n-      GetInput(context, node, kInputTensorBoxEncodings);\n-  const TfLiteTensor* input_class_predictions =\n-      GetInput(context, node, kInputTensorClassPredictions);\n+  const TfLiteTensor* input_box_encodings;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorBoxEncodings,\n+                                 &input_box_encodings));\n+  const TfLiteTensor* input_class_predictions;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorClassPredictions,\n+                                 &input_class_predictions));\n   const int num_boxes = input_box_encodings->dims->data[1];\n   const int num_classes = op_data->num_classes;\n   TF_LITE_ENSURE_EQ(context, input_class_predictions->dims->data[0],"
    },
    "modified_file_18": {
        "mod_filename": "tensorflow/lite/kernels/div.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -74,9 +74,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n   output->type = input2->type;\n@@ -200,9 +206,15 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteDivParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n     EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);"
    },
    "modified_file_19": {
        "mod_filename": "tensorflow/lite/kernels/elementwise.cc",
        "status": "modified",
        "add_lines": 8,
        "dele_lines": 4,
        "patch": "@@ -66,8 +66,10 @@ template <IsSupportedType is_supported_type, const char* op_name>\n TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n   if (!is_supported_type(input->type)) {\n     TF_LITE_UNSUPPORTED_TYPE(context, input->type, op_name);\n@@ -114,8 +116,10 @@ template <typename T>\n inline TfLiteStatus EvalImpl(TfLiteContext* context, TfLiteNode* node,\n                              std::function<T(T)> func,\n                              TfLiteType expected_type) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, expected_type);\n   const int64_t num_elements = NumElements(input);\n   const T* in_data = GetTensorData<T>(input);"
    },
    "modified_file_20": {
        "mod_filename": "tensorflow/lite/kernels/embedding_lookup.cc",
        "status": "modified",
        "add_lines": 12,
        "dele_lines": 6,
        "patch": "@@ -46,14 +46,17 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* lookup = GetInput(context, node, 0);\n+  const TfLiteTensor* lookup;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(lookup), 1);\n   TF_LITE_ENSURE_EQ(context, lookup->type, kTfLiteInt32);\n \n-  const TfLiteTensor* value = GetInput(context, node, 1);\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &value));\n   TF_LITE_ENSURE(context, NumDimensions(value) >= 2);\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TfLiteIntArray* outputSize = TfLiteIntArrayCreate(NumDimensions(value));\n \n   outputSize->data[0] = SizeOfDimension(lookup, 0);\n@@ -129,9 +132,12 @@ TfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* lookup = GetInput(context, node, 0);\n-  const TfLiteTensor* value = GetInput(context, node, 1);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* lookup;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &value));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   switch (value->type) {\n     case kTfLiteFloat32:\n       return EvalSimple(context, node, lookup, value, output);"
    },
    "modified_file_21": {
        "mod_filename": "tensorflow/lite/kernels/embedding_lookup_sparse.cc",
        "status": "modified",
        "add_lines": 24,
        "dele_lines": 12,
        "patch": "@@ -83,19 +83,23 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 5);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* ids = GetInput(context, node, 0);\n+  const TfLiteTensor* ids;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &ids));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(ids), 1);\n   TF_LITE_ENSURE_EQ(context, ids->type, kTfLiteInt32);\n \n-  const TfLiteTensor* indices = GetInput(context, node, 1);\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &indices));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(indices), 2);\n   TF_LITE_ENSURE_EQ(context, indices->type, kTfLiteInt32);\n \n-  const TfLiteTensor* shape = GetInput(context, node, 2);\n+  const TfLiteTensor* shape;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &shape));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(shape), 1);\n   TF_LITE_ENSURE_EQ(context, shape->type, kTfLiteInt32);\n \n-  const TfLiteTensor* weights = GetInput(context, node, 3);\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 3, &weights));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(weights), 1);\n   TF_LITE_ENSURE_EQ(context, weights->type, kTfLiteFloat32);\n \n@@ -104,11 +108,13 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, SizeOfDimension(indices, 0),\n                     SizeOfDimension(weights, 0));\n \n-  const TfLiteTensor* value = GetInput(context, node, 4);\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 4, &value));\n   TF_LITE_ENSURE(context, NumDimensions(value) >= 2);\n \n   // Mark the output as a dynamic tensor.\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, kTfLiteFloat32);\n   output->allocation_type = kTfLiteDynamic;\n \n@@ -140,12 +146,18 @@ void FinalizeAggregation(TfLiteCombinerType combiner, int num_elements,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteEmbeddingLookupSparseParams*>(node->builtin_data);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* ids = GetInput(context, node, 0);\n-  const TfLiteTensor* indices = GetInput(context, node, 1);\n-  const TfLiteTensor* dense_shape = GetInput(context, node, 2);\n-  const TfLiteTensor* weights = GetInput(context, node, 3);\n-  const TfLiteTensor* value = GetInput(context, node, 4);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* ids;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &ids));\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &indices));\n+  const TfLiteTensor* dense_shape;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &dense_shape));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 3, &weights));\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 4, &value));\n \n   const int lookup_rank = SizeOfDimension(indices, 1);\n   const int embedding_rank = NumDimensions(value);"
    },
    "modified_file_22": {
        "mod_filename": "tensorflow/lite/kernels/expand_dims.cc",
        "status": "modified",
        "add_lines": 12,
        "dele_lines": 6,
        "patch": "@@ -73,9 +73,12 @@ TfLiteStatus GetAxisValueFromTensor(TfLiteContext* context,\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, kInput);\n-  const TfLiteTensor* axis = GetInput(context, node, kAxis);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInput, &input));\n+  const TfLiteTensor* axis;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kAxis, &axis));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   output->type = input->type;\n   if (IsConstantTensor(axis)) {\n     int axis_value;\n@@ -89,9 +92,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   // Just copy input to output.\n-  const TfLiteTensor* input = GetInput(context, node, kInput);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* axis = GetInput(context, node, kAxis);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInput, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* axis;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kAxis, &axis));\n   if (IsDynamicTensor(output)) {\n     int axis_value;\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_23": {
        "mod_filename": "tensorflow/lite/kernels/fill.cc",
        "status": "modified",
        "add_lines": 14,
        "dele_lines": 6,
        "patch": "@@ -72,8 +72,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* dims = GetInput(context, node, kDimsTensor);\n-  const TfLiteTensor* value = GetInput(context, node, kValueTensor);\n+  const TfLiteTensor* dims;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kDimsTensor, &dims));\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kValueTensor, &value));\n \n   // Make sure the 1st input tensor is 1-D.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(dims), 1);\n@@ -85,7 +87,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Make sure the 2nd input tensor is a scalar.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(value), 0);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = value->type;\n \n   if (IsConstantTensor(dims)) {\n@@ -111,12 +115,16 @@ TfLiteStatus FillString(const TfLiteTensor* value, TfLiteTensor* output) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* value = GetInput(context, node, kValueTensor);\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kValueTensor, &value));\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (IsDynamicTensor(output)) {\n-    const TfLiteTensor* dims = GetInput(context, node, kDimsTensor);\n+    const TfLiteTensor* dims;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kDimsTensor, &dims));\n     TF_LITE_ENSURE_OK(context, ResizeOutput(context, dims, output));\n   }\n #define TF_LITE_FILL(data_type)                                               \\"
    },
    "modified_file_24": {
        "mod_filename": "tensorflow/lite/kernels/floor.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -35,8 +35,11 @@ enum KernelType {\n };\n \n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n@@ -47,8 +50,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n template <KernelType type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (type == kGenericOptimized) {\n     optimized_ops::Floor(GetTensorShape(input), GetTensorData<float>(input),"
    },
    "modified_file_25": {
        "mod_filename": "tensorflow/lite/kernels/floor_div.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -64,9 +64,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Reinterprete the opaque data provided by user.\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n \n@@ -126,9 +132,15 @@ TfLiteStatus EvalImpl(TfLiteContext* context, bool requires_broadcast,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (input1->type) {\n     case kTfLiteInt32: {"
    },
    "modified_file_26": {
        "mod_filename": "tensorflow/lite/kernels/floor_mod.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -58,9 +58,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Reinterprete the opaque data provided by user.\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n \n@@ -120,9 +126,15 @@ TfLiteStatus EvalImpl(TfLiteContext* context, bool requires_broadcast,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (input1->type) {\n     case kTfLiteInt32: {"
    },
    "modified_file_27": {
        "mod_filename": "tensorflow/lite/kernels/fully_connected.cc",
        "status": "modified",
        "add_lines": 55,
        "dele_lines": 20,
        "patch": "@@ -155,13 +155,18 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n                                                                           : 2;\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, expected_outputs_count);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* filter = GetInput(context, node, kWeightsTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &filter));\n   const TfLiteTensor* bias =\n       (node->inputs->size == 3)\n           ? GetOptionalInputTensor(context, node, kBiasTensor)\n           : nullptr;\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Check proper datatype match among all Input Tensors\n   TF_LITE_ENSURE_STATUS(\n@@ -214,7 +219,9 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n     node->temporaries = TfLiteIntArrayCreate(5);\n     node->temporaries->data[0] = data->scratch_tensor_index;\n \n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/0);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n+                                                &input_quantized));\n     input_quantized->type = filter->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n \n@@ -223,7 +230,9 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n                                                      input_quantized_size));\n \n     node->temporaries->data[1] = data->scratch_tensor_index + 1;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n \n@@ -236,7 +245,9 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n     }\n \n     node->temporaries->data[2] = data->scratch_tensor_index + 2;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/2, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {num_units, batch_size};\n@@ -250,7 +261,9 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n     }\n \n     node->temporaries->data[3] = data->scratch_tensor_index + 3;\n-    TfLiteTensor* input_offsets = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* input_offsets;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/3, &input_offsets));\n     input_offsets->type = kTfLiteInt32;\n     input_offsets->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n@@ -260,7 +273,9 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n                                                        input_offsets_size));\n     }\n     node->temporaries->data[4] = data->scratch_tensor_index + 4;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/4, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[1] = {num_units};\n@@ -300,8 +315,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Check for supported activation types.\n   auto* params =\n       reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);\n-  const TfLiteTensor* filter = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &filter));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const bool is_quantized =\n       ((filter->type == kTfLiteUInt8) || (filter->type == kTfLiteInt8));\n   const bool is_hybrid = is_quantized && (input->type == kTfLiteFloat32);\n@@ -484,11 +502,21 @@ TfLiteStatus EvalQuantized(TfLiteContext* context, TfLiteNode* node,\n   int32_t output_offset = output->params.zero_point;\n   // Only the Pie path supports quantized models and float inputs/outputs.\n   if (input->type == kTfLiteFloat32) {\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/0);\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/1);\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/2);\n-    TfLiteTensor* input_offsets = GetTemporary(context, node, /*index=*/3);\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n+                                                &input_quantized));\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &scaling_factors));\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/2, &accum_scratch));\n+    TfLiteTensor* input_offsets;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/3, &input_offsets));\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/4, &row_sums));\n     return EvalHybrid(context, node, params, data, input, filter, bias,\n                       input_quantized, scaling_factors, accum_scratch, row_sums,\n                       input_offsets, output);\n@@ -693,13 +721,18 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* filter = GetInput(context, node, kWeightsTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* filter;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &filter));\n   const TfLiteTensor* bias =\n       (node->inputs->size == 3)\n           ? GetOptionalInputTensor(context, node, kBiasTensor)\n           : nullptr;\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (filter->type) {\n     case kTfLiteFloat32:\n@@ -708,8 +741,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n       if (params->weights_format ==\n           kTfLiteFullyConnectedWeightsFormatShuffled4x16Int8) {\n-        TfLiteTensor* shuffled_input_workspace =\n-            GetOutput(context, node, kShuffledInputWorkspaceTensor);\n+        TfLiteTensor* shuffled_input_workspace;\n+        TF_LITE_ENSURE_OK(\n+            context, GetOutputSafe(context, node, kShuffledInputWorkspaceTensor,\n+                                   &shuffled_input_workspace));\n         return EvalShuffledQuantized<kernel_type>(context, node, params, data,\n                                                   input, filter, bias, output,\n                                                   shuffled_input_workspace);"
    },
    "modified_file_28": {
        "mod_filename": "tensorflow/lite/kernels/gather.cc",
        "status": "modified",
        "add_lines": 16,
        "dele_lines": 6,
        "patch": "@@ -38,9 +38,14 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   const auto* params =\n       reinterpret_cast<const TfLiteGatherParams*>(node->builtin_data);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* positions = GetInput(context, node, kInputPositions);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* positions;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputPositions, &positions));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (positions->type) {\n     case kTfLiteInt64:\n@@ -132,9 +137,14 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const auto* params =\n       reinterpret_cast<const TfLiteGatherParams*>(node->builtin_data);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* positions = GetInput(context, node, kInputPositions);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* positions;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputPositions, &positions));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (positions->type == kTfLiteInt32) {\n     switch (input->type) {"
    },
    "modified_file_29": {
        "mod_filename": "tensorflow/lite/kernels/gather_nd.cc",
        "status": "modified",
        "add_lines": 14,
        "dele_lines": 6,
        "patch": "@@ -33,9 +33,13 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* params = GetInput(context, node, kParams);\n-  const TfLiteTensor* indices = GetInput(context, node, kIndices);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* params;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (params->type) {\n     case kTfLiteFloat32:\n@@ -140,9 +144,13 @@ TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* params = GetInput(context, node, kParams);\n-  const TfLiteTensor* indices = GetInput(context, node, kIndices);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* params;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (indices->type) {\n     case kTfLiteInt32:"
    },
    "modified_file_30": {
        "mod_filename": "tensorflow/lite/kernels/hashtable_lookup.cc",
        "status": "modified",
        "add_lines": 21,
        "dele_lines": 10,
        "patch": "@@ -37,6 +37,7 @@ limitations under the License.\n #include <cstring>\n \n #include \"tensorflow/lite/c/common.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n #include \"tensorflow/lite/string_util.h\"\n \n@@ -54,28 +55,33 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 3);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 2);\n \n-  const TfLiteTensor* lookup = GetInput(context, node, 0);\n+  const TfLiteTensor* lookup;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(lookup), 1);\n   TF_LITE_ENSURE_EQ(context, lookup->type, kTfLiteInt32);\n \n-  const TfLiteTensor* key = GetInput(context, node, 1);\n+  const TfLiteTensor* key;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &key));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(key), 1);\n   TF_LITE_ENSURE_EQ(context, key->type, kTfLiteInt32);\n \n-  const TfLiteTensor* value = GetInput(context, node, 2);\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\n   TF_LITE_ENSURE(context, NumDimensions(value) >= 1);\n   TF_LITE_ENSURE_EQ(context, SizeOfDimension(key, 0),\n                     SizeOfDimension(value, 0));\n   if (value->type == kTfLiteString) {\n     TF_LITE_ENSURE_EQ(context, NumDimensions(value), 1);\n   }\n \n-  TfLiteTensor* hits = GetOutput(context, node, 1);\n+  TfLiteTensor* hits;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 1, &hits));\n   TF_LITE_ENSURE_EQ(context, hits->type, kTfLiteUInt8);\n   TfLiteIntArray* hitSize = TfLiteIntArrayCreate(1);\n   hitSize->data[0] = SizeOfDimension(lookup, 0);\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_EQ(context, value->type, output->type);\n \n   TfLiteStatus status = kTfLiteOk;\n@@ -94,11 +100,16 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  TfLiteTensor* hits = GetOutput(context, node, 1);\n-  const TfLiteTensor* lookup = GetInput(context, node, 0);\n-  const TfLiteTensor* key = GetInput(context, node, 1);\n-  const TfLiteTensor* value = GetInput(context, node, 2);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  TfLiteTensor* hits;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 1, &hits));\n+  const TfLiteTensor* lookup;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n+  const TfLiteTensor* key;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &key));\n+  const TfLiteTensor* value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\n \n   const int num_rows = SizeOfDimension(value, 0);\n   const int row_bytes = value->bytes / num_rows;"
    },
    "modified_file_31": {
        "mod_filename": "tensorflow/lite/kernels/if.cc",
        "status": "modified",
        "add_lines": 17,
        "dele_lines": 8,
        "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n #include \"tensorflow/lite/core/subgraph.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n \n namespace tflite {\n@@ -52,7 +53,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE(context, node->inputs->size > 0);\n \n   // The first input is the condition.\n-  const TfLiteTensor* cond = GetInput(context, node, 0);\n+  const TfLiteTensor* cond;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &cond));\n   // Currently only bool is supported.\n   // TODO(ycling): Support other types since TensorFlow also support\n   // non-bool types as condition.\n@@ -83,7 +85,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     for (int i = 0; i < num_inputs; ++i) {\n       // The first input of the node is the condition. The indices of the inputs\n       // passed to the subgraphs are offset by 1.\n-      const TfLiteTensor* input = GetInput(context, node, i + 1);\n+      const TfLiteTensor* input;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i + 1, &input));\n       std::vector<int> dims(input->dims->data,\n                             input->dims->data + input->dims->size);\n       subgraph->ResizeInputTensor(i, dims);\n@@ -113,7 +116,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   for (int i = 0; i < num_outputs; ++i) {\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     if (has_dynamic_output_tensors) {\n       SetTensorToDynamic(output);\n     } else {\n@@ -133,7 +137,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* cond = GetInput(context, node, 0);\n+  const TfLiteTensor* cond;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &cond));\n   bool cond_value = cond->data.b[0];\n \n   Subgraph* this_subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n@@ -147,7 +152,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   Subgraph& active_branch_subgraph =\n       *(*subgraphs)[active_branch_subgraph_index];\n   for (int i = 0; i < active_branch_subgraph.inputs().size(); ++i) {\n-    const TfLiteTensor* input = GetInput(context, node, i + 1);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i + 1, &input));\n     TfLiteTensor* subgraph_input =\n         active_branch_subgraph.tensor(active_branch_subgraph.inputs()[i]);\n     TF_LITE_ENSURE_EQ(context, input->bytes, subgraph_input->bytes);\n@@ -164,7 +170,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   bool has_dynamic_output_tensors = false;\n   for (int i = 0; i < node->outputs->size; ++i) {\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     if (IsDynamicTensor(output)) {\n       has_dynamic_output_tensors = true;\n       break;\n@@ -173,7 +180,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   if (has_dynamic_output_tensors) {\n     for (int i = 0; i < node->outputs->size; ++i) {\n-      TfLiteTensor* output = GetOutput(context, node, i);\n+      TfLiteTensor* output;\n+      TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n       TfLiteTensor* subgraph_output =\n           active_branch_subgraph.tensor(active_branch_subgraph.outputs()[i]);\n       TfLiteIntArray* output_size = TfLiteIntArrayCopy(subgraph_output->dims);\n@@ -185,7 +193,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   for (int i = 0; i < active_branch_subgraph.outputs().size(); ++i) {\n     const TfLiteTensor* subgraph_output =\n         active_branch_subgraph.tensor(active_branch_subgraph.outputs()[i]);\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     TF_LITE_ENSURE_EQ(context, output->bytes, subgraph_output->bytes);\n     memcpy(output->data.raw, subgraph_output->data.raw, output->bytes);\n   }"
    },
    "modified_file_32": {
        "mod_filename": "tensorflow/lite/kernels/l2norm.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -44,8 +44,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE(context, NumDimensions(input) <= 4);\n \n@@ -74,8 +77,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // TODO(b/143912164): instead of hardcode the epsilon here, we should read it\n   // from tensorflow, i.e., adding a params."
    },
    "modified_file_33": {
        "mod_filename": "tensorflow/lite/kernels/local_response_norm.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -39,8 +39,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n \n@@ -61,8 +64,11 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteLocalResponseNormParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type == kTfLiteFloat32) {\n #define TF_LITE_LOCAL_RESPONSE_NORM(type)                            \\"
    },
    "modified_file_34": {
        "mod_filename": "tensorflow/lite/kernels/logical.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -54,9 +54,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Reinterprete the opaque data provided by user.\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n \n@@ -84,9 +90,15 @@ TfLiteStatus LogicalImpl(TfLiteContext* context, TfLiteNode* node,\n                          bool (*func)(bool, bool)) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (data->requires_broadcast) {\n     reference_ops::BroadcastBinaryFunction4DSlow<bool, bool, bool>("
    },
    "modified_file_35": {
        "mod_filename": "tensorflow/lite/kernels/lsh_projection.cc",
        "status": "modified",
        "add_lines": 15,
        "dele_lines": 7,
        "patch": "@@ -73,22 +73,26 @@ TfLiteStatus Resize(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE(context, NumInputs(node) == 2 || NumInputs(node) == 3);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* hash = GetInput(context, node, 0);\n+  const TfLiteTensor* hash;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &hash));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(hash), 2);\n   // Support up to 32 bits.\n   TF_LITE_ENSURE(context, SizeOfDimension(hash, 1) <= 32);\n \n-  const TfLiteTensor* input = GetInput(context, node, 1);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n   TF_LITE_ENSURE(context, NumDimensions(input) >= 1);\n \n   if (NumInputs(node) == 3) {\n-    const TfLiteTensor* weight = GetInput(context, node, 2);\n+    const TfLiteTensor* weight;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &weight));\n     TF_LITE_ENSURE_EQ(context, NumDimensions(weight), 1);\n     TF_LITE_ENSURE_EQ(context, SizeOfDimension(weight, 0),\n                       SizeOfDimension(input, 0));\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n   switch (params->type) {\n     case kTfLiteLshProjectionSparse:\n@@ -170,9 +174,13 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteLSHProjectionParams*>(node->builtin_data);\n \n-  int32_t* out_buf = GetOutput(context, node, 0)->data.i32;\n-  const TfLiteTensor* hash = GetInput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 1);\n+  TfLiteTensor* out_tensor;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &out_tensor));\n+  int32_t* out_buf = out_tensor->data.i32;\n+  const TfLiteTensor* hash;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &hash));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n   const TfLiteTensor* weight =\n       NumInputs(node) == 2 ? nullptr : GetInput(context, node, 2);\n "
    },
    "modified_file_36": {
        "mod_filename": "tensorflow/lite/kernels/lstm.cc",
        "status": "modified",
        "add_lines": 326,
        "dele_lines": 153,
        "patch": "@@ -149,7 +149,9 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_16(\n   const TfLiteTensor* cell_state =\n       GetVariableInput(context, node, kCellStateTensor);\n   TF_LITE_ENSURE(context, cell_state != nullptr);\n-  const TfLiteTensor* output_tensor = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputTensor, &output_tensor));\n \n   auto* cell_state_params =\n       static_cast<TfLiteAffineQuantization*>(cell_state->quantization.params);\n@@ -173,25 +175,38 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_16(\n   OpData* op_data = static_cast<OpData*>(node->user_data);\n   const bool use_layer_norm = op_data->use_layer_norm;\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n \n   const TfLiteTensor* input_to_input_weights =\n       GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToForgetWeightsTensor,\n+                                 &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToCellWeightsTensor,\n+                                 &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToOutputWeightsTensor,\n+                                 &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToForgetWeightsTensor,\n+                                 &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToCellWeightsTensor,\n+                                 &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToOutputWeightsTensor,\n+                                 &recurrent_to_output_weights));\n \n   const TfLiteTensor* cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kCellToInputWeightsTensor);\n@@ -227,7 +242,9 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_16(\n   std::vector<int32> intermediate_zp;\n   for (int i = 0; i < 4; ++i) {\n     if (use_layer_norm) {\n-      const TfLiteTensor* intermediate = GetIntermediates(context, node, i);\n+      TfLiteTensor* intermediate;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetIntermediatesSafe(context, node, i, &intermediate));\n       auto* params = static_cast<TfLiteAffineQuantization*>(\n           intermediate->quantization.params);\n       intermediate_scale.push_back(params->scale->data[0]);\n@@ -240,7 +257,8 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_16(\n   }\n   // In the absense of projection, hidden becomes otuput and this intermediate\n   // is ignored.\n-  const TfLiteTensor* hidden = GetIntermediates(context, node, 4);\n+  TfLiteTensor* hidden;\n+  TF_LITE_ENSURE_OK(context, GetIntermediatesSafe(context, node, 4, &hidden));\n   auto* hidden_params =\n       static_cast<TfLiteAffineQuantization*>(hidden->quantization.params);\n   intermediate_scale.push_back(hidden_params->scale->data[0]);\n@@ -446,24 +464,37 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_8(\n     TfLiteContext* context, TfLiteNode* node,\n     lstm_eval::IntegerLstmParameter* integer_lstm_param) {\n   // Get all tensors.\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const TfLiteTensor* input_to_input_weights =\n       GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToForgetWeightsTensor,\n+                                 &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToCellWeightsTensor,\n+                                 &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToOutputWeightsTensor,\n+                                 &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToForgetWeightsTensor,\n+                                 &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToCellWeightsTensor,\n+                                 &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToOutputWeightsTensor,\n+                                 &recurrent_to_output_weights));\n \n   const TfLiteTensor* cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kCellToInputWeightsTensor);\n@@ -483,12 +514,15 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_8(\n \n   const TfLiteTensor* input_gate_bias =\n       GetOptionalInputTensor(context, node, kInputGateBiasTensor);\n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, kForgetGateBiasTensor);\n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, kCellGateBiasTensor);\n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, kOutputGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kForgetGateBiasTensor,\n+                                          &forget_gate_bias));\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kCellGateBiasTensor,\n+                                          &cell_gate_bias));\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kOutputGateBiasTensor,\n+                                          &output_gate_bias));\n \n   const TfLiteTensor* projection_weights =\n       GetOptionalInputTensor(context, node, kProjectionWeightsTensor);\n@@ -774,7 +808,9 @@ TfLiteStatus PopulateQuantizedLstmParams8x8_8(\n   const float cell_clip = params->cell_clip;\n   const float proj_clip = params->proj_clip;\n \n-  const TfLiteTensor* output_tensor = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputTensor, &output_tensor));\n \n   auto* cell_state_params = reinterpret_cast<TfLiteAffineQuantization*>(\n       cell_state->quantization.params);\n@@ -825,8 +861,10 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n   TF_LITE_ENSURE(context, params->cell_clip >= 0);\n   TF_LITE_ENSURE(context, params->proj_clip >= 0);\n \n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, kInputToForgetWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToForgetWeightsTensor,\n+                                 &input_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[1], n_input);\n@@ -845,8 +883,10 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n                             input_to_forget_weights->type);\n   }\n \n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, kInputToCellWeightsTensor);\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToCellWeightsTensor,\n+                                 &input_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[1], n_input);\n@@ -865,8 +905,10 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n                             input_to_forget_weights->type);\n   }\n \n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, kRecurrentToForgetWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToForgetWeightsTensor,\n+                                 &recurrent_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[0],\n                     n_cell);\n@@ -875,8 +917,10 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n   TF_LITE_ENSURE_TYPES_EQ(context, recurrent_to_forget_weights->type,\n                           input_to_forget_weights->type);\n \n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, kRecurrentToCellWeightsTensor);\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToCellWeightsTensor,\n+                                 &recurrent_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[1],\n@@ -948,8 +992,9 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     }\n   }\n \n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, kForgetGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kForgetGateBiasTensor,\n+                                          &forget_gate_bias));\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->data[0], n_cell);\n   if (is_integer) {\n@@ -958,8 +1003,9 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     TF_LITE_ENSURE_TYPES_EQ(context, forget_gate_bias->type, kTfLiteFloat32);\n   }\n \n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, kCellGateBiasTensor);\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kCellGateBiasTensor,\n+                                          &cell_gate_bias));\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->data[0], n_cell);\n   if (is_integer) {\n@@ -968,8 +1014,9 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     TF_LITE_ENSURE_TYPES_EQ(context, cell_gate_bias->type, kTfLiteFloat32);\n   }\n \n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, kOutputGateBiasTensor);\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kOutputGateBiasTensor,\n+                                          &output_gate_bias));\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->data[0], n_cell);\n   if (is_integer) {\n@@ -1105,7 +1152,8 @@ TfLiteStatus PrecomputeZeroPointTimesWeightWithBias(\n TfLiteStatus PopulatePrecomputedZPTimesWeightsWithBias(TfLiteContext* context,\n                                                        OpData* op_data,\n                                                        TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const TfLiteTensor* output_state =\n       GetVariableInput(context, node, kOutputStateTensor);\n   TF_LITE_ENSURE(context, output_state != nullptr);\n@@ -1115,21 +1163,33 @@ TfLiteStatus PopulatePrecomputedZPTimesWeightsWithBias(TfLiteContext* context,\n \n   const TfLiteTensor* input_to_input_weights =\n       GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToForgetWeightsTensor,\n+                                 &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToCellWeightsTensor,\n+                                 &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToOutputWeightsTensor,\n+                                 &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToForgetWeightsTensor,\n+                                 &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToCellWeightsTensor,\n+                                 &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToOutputWeightsTensor,\n+                                 &recurrent_to_output_weights));\n \n   const TfLiteTensor* projection_weights =\n       GetOptionalInputTensor(context, node, kProjectionWeightsTensor);\n@@ -1254,20 +1314,25 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Inferring batch size, number of outputs and number of cells from the\n   // input tensors.\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const bool is_integer = input->type == kTfLiteInt8;\n   TF_LITE_ENSURE(context, input->dims->size > 1);\n   const int n_batch = input->dims->data[0];\n   const int n_input = input->dims->data[1];\n \n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToOutputWeightsTensor,\n+                                 &input_to_output_weights));\n   const int n_cell = input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[1], n_input);\n \n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToOutputWeightsTensor,\n+                                 &recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_output_weights->dims->data[0],\n                     n_cell);\n@@ -1279,7 +1344,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                           n_cell, use_layer_norm, is_integer));\n \n   // Get the pointer to output, output_state and cell_state tensors.\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TfLiteTensor* output_state =\n       GetVariableInput(context, node, kOutputStateTensor);\n@@ -1339,7 +1406,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   if (!is_integer) {\n     node->temporaries->data[kScratchBuffer] =\n         op_data->scratch_tensor_index + kScratchBuffer;\n-    TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);\n+    TfLiteTensor* scratch_buffer;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScratchBuffer,\n+                                                &scratch_buffer));\n     scratch_buffer->type = input->type;\n     scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -1367,8 +1436,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // output_state and cell_state tensors.\n     node->temporaries->data[kInputQuantized] =\n         op_data->scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = input_to_output_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -1378,8 +1448,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateQuantized] =\n         op_data->scratch_tensor_index + kOutputStateQuantized;\n-    TfLiteTensor* output_state_quantized =\n-        GetTemporary(context, node, kOutputStateQuantized);\n+    TfLiteTensor* output_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateQuantized,\n+                                       &output_state_quantized));\n     output_state_quantized->type = input_to_output_weights->type;\n     output_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(output_state_quantized->dims,\n@@ -1392,8 +1464,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kCellStateQuantized] =\n         op_data->scratch_tensor_index + kCellStateQuantized;\n-    TfLiteTensor* cell_state_quantized =\n-        GetTemporary(context, node, kCellStateQuantized);\n+    TfLiteTensor* cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kCellStateQuantized,\n+                                       &cell_state_quantized));\n     cell_state_quantized->type = input_to_output_weights->type;\n     cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(cell_state_quantized->dims, cell_state->dims)) {\n@@ -1410,7 +1484,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // the scaling factor of the matrix).\n     node->temporaries->data[kInputScalingFactors] =\n         op_data->scratch_tensor_index + kInputScalingFactors;\n-    TfLiteTensor* input_sf = GetTemporary(context, node, kInputScalingFactors);\n+    TfLiteTensor* input_sf;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kInputScalingFactors, &input_sf));\n     input_sf->type = kTfLiteFloat32;\n     input_sf->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {n_batch};\n@@ -1422,8 +1499,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateScalingFactors] =\n         op_data->scratch_tensor_index + kOutputStateScalingFactors;\n-    TfLiteTensor* output_state_sf =\n-        GetTemporary(context, node, kOutputStateScalingFactors);\n+    TfLiteTensor* output_state_sf;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kOutputStateScalingFactors,\n+                                  &output_state_sf));\n     output_state_sf->type = kTfLiteFloat32;\n     output_state_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_sf->dims, 1, scaling_dims)) {\n@@ -1434,8 +1513,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kProductScalingFactors] =\n         op_data->scratch_tensor_index + kProductScalingFactors;\n-    TfLiteTensor* prod_scaling_factors =\n-        GetTemporary(context, node, kProductScalingFactors);\n+    TfLiteTensor* prod_scaling_factors;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kProductScalingFactors,\n+                                       &prod_scaling_factors));\n     prod_scaling_factors->type = kTfLiteFloat32;\n     prod_scaling_factors->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(prod_scaling_factors->dims, 1,\n@@ -1451,8 +1532,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // this is used for diagonal matrices, only need to store n_cell values.\n     node->temporaries->data[kRecoveredCellWeights] =\n         op_data->scratch_tensor_index + kRecoveredCellWeights;\n-    TfLiteTensor* recovered_cell_weights =\n-        GetTemporary(context, node, kRecoveredCellWeights);\n+    TfLiteTensor* recovered_cell_weights;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                       &recovered_cell_weights));\n     recovered_cell_weights->type = kTfLiteFloat32;\n     recovered_cell_weights->allocation_type = kTfLiteArenaRw;\n     int recovered_cell_dims[1] = {n_cell};\n@@ -1468,7 +1551,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // multiplication before multiplication by scaling factor\n     node->temporaries->data[kAccumScratch] =\n         op_data->scratch_tensor_index + kAccumScratch;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {n_cell, n_batch};\n@@ -1482,7 +1567,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kInputZeroPoints] =\n         op_data->scratch_tensor_index + kInputZeroPoints;\n-    TfLiteTensor* input_zp = GetTemporary(context, node, kInputZeroPoints);\n+    TfLiteTensor* input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kInputZeroPoints, &input_zp));\n     input_zp->type = kTfLiteFloat32;\n     input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_zp->dims, 1, scaling_dims)) {\n@@ -1493,8 +1580,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateZeroPoints] =\n         op_data->scratch_tensor_index + kOutputStateZeroPoints;\n-    TfLiteTensor* output_state_zp =\n-        GetTemporary(context, node, kOutputStateZeroPoints);\n+    TfLiteTensor* output_state_zp;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateZeroPoints,\n+                                       &output_state_zp));\n     output_state_zp->type = kTfLiteFloat32;\n     output_state_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_zp->dims, 1, scaling_dims)) {\n@@ -1516,7 +1605,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       row_sums_rows += ceil(static_cast<float>(n_output) / n_cell);\n     }\n \n-    TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRowSums, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     const int row_sums_dims[2] = {row_sums_rows, n_cell};\n@@ -1664,8 +1755,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       for (int scratch_index = 0; scratch_index < 6; ++scratch_index) {\n         node->temporaries->data[scratch_index] =\n             op_data->scratch_tensor_index + scratch_index;\n-        TfLiteTensor* scratch_tensor =\n-            GetTemporary(context, node, scratch_index);\n+        TfLiteTensor* scratch_tensor;\n+        TF_LITE_ENSURE_OK(\n+            context,\n+            GetTemporarySafe(context, node, scratch_index, &scratch_tensor));\n         scratch_tensor->type = kTfLiteInt16;\n         if (scratch_index == 4) {\n           scratch_tensor->type = kTfLiteInt8;\n@@ -1701,8 +1794,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       for (int scratch_index = 0; scratch_index < 8; ++scratch_index) {\n         node->temporaries->data[scratch_index] =\n             op_data->scratch_tensor_index + scratch_index;\n-        TfLiteTensor* scratch_tensor =\n-            GetTemporary(context, node, scratch_index);\n+        TfLiteTensor* scratch_tensor;\n+        TF_LITE_ENSURE_OK(\n+            context,\n+            GetTemporarySafe(context, node, scratch_index, &scratch_tensor));\n         if (scratch_index == 0 || scratch_index == 1) {\n           scratch_tensor->type = kTfLiteInt8;\n         } else {\n@@ -1731,25 +1826,38 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const auto* params = static_cast<TfLiteLSTMParams*>(node->builtin_data);\n   OpData* op_data = static_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n \n   const TfLiteTensor* input_to_input_weights =\n       GetOptionalInputTensor(context, node, kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToForgetWeightsTensor,\n+                                 &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToCellWeightsTensor,\n+                                 &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputToOutputWeightsTensor,\n+                                 &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToForgetWeightsTensor,\n+                                 &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToCellWeightsTensor,\n+                                 &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kRecurrentToOutputWeightsTensor,\n+                                 &recurrent_to_output_weights));\n \n   const TfLiteTensor* cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kCellToInputWeightsTensor);\n@@ -1769,12 +1877,15 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* input_gate_bias =\n       GetOptionalInputTensor(context, node, kInputGateBiasTensor);\n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, kForgetGateBiasTensor);\n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, kCellGateBiasTensor);\n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, kOutputGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kForgetGateBiasTensor,\n+                                          &forget_gate_bias));\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kCellGateBiasTensor,\n+                                          &cell_gate_bias));\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kOutputGateBiasTensor,\n+                                          &output_gate_bias));\n \n   const TfLiteTensor* projection_weights =\n       GetOptionalInputTensor(context, node, kProjectionWeightsTensor);\n@@ -1783,16 +1894,20 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   TfLiteTensor* output_state =\n       GetVariableInput(context, node, kOutputStateTensor);\n-  TF_LITE_ENSURE(context, output_state != nullptr);\n+  TFLITE_DCHECK(output_state != nullptr);\n   TfLiteTensor* cell_state = GetVariableInput(context, node, kCellStateTensor);\n-  TF_LITE_ENSURE(context, cell_state != nullptr);\n+  TFLITE_DCHECK(cell_state != nullptr);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (input_to_output_weights->type) {\n     case kTfLiteFloat32: {\n       // Index the scratch buffers pointers to the global scratch buffer.\n-      TfLiteTensor* scratch_buffer = GetTemporary(context, node, 0);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 0, &scratch_buffer));\n       return lstm_eval::EvalFloat(\n           input, input_to_input_weights, input_to_forget_weights,\n           input_to_cell_weights, input_to_output_weights,\n@@ -1818,7 +1933,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       const bool is_hybrid = (input->type == kTfLiteFloat32);\n       const bool is_sparse = input_to_output_weights->sparsity != nullptr;\n       if (is_hybrid) {\n-        TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);\n+        TfLiteTensor* row_sums;\n+        TF_LITE_ENSURE_OK(context,\n+                          GetTemporarySafe(context, node, kRowSums, &row_sums));\n         const int row_sums_size = row_sums->dims->data[0];\n         if (is_sparse) {\n           TfLiteTensor* input_to_input_weights_ledger =\n@@ -1957,12 +2074,24 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       } else {\n         const int num_intermediate_tensors = node->intermediates->size;\n         if (num_intermediate_tensors == 5) {\n-          TfLiteTensor* scratch0 = GetTemporary(context, node, 0);\n-          TfLiteTensor* scratch1 = GetTemporary(context, node, 1);\n-          TfLiteTensor* scratch2 = GetTemporary(context, node, 2);\n-          TfLiteTensor* scratch3 = GetTemporary(context, node, 3);\n-          TfLiteTensor* scratch4 = GetTemporary(context, node, 4);\n-          TfLiteTensor* scratch5 = GetTemporary(context, node, 5);\n+          TfLiteTensor* scratch0;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 0, &scratch0));\n+          TfLiteTensor* scratch1;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 1, &scratch1));\n+          TfLiteTensor* scratch2;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 2, &scratch2));\n+          TfLiteTensor* scratch3;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 3, &scratch3));\n+          TfLiteTensor* scratch4;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 4, &scratch4));\n+          TfLiteTensor* scratch5;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 5, &scratch5));\n           return lstm_eval::EvalInteger8x8_16(\n               input, input_to_input_weights, input_to_forget_weights,\n               input_to_cell_weights, input_to_output_weights,\n@@ -1978,14 +2107,30 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n               scratch3, scratch4, scratch5,\n               CpuBackendContext::GetFromContext(context));\n         } else {\n-          TfLiteTensor* scratch0 = GetTemporary(context, node, 0);\n-          TfLiteTensor* scratch1 = GetTemporary(context, node, 1);\n-          TfLiteTensor* scratch2 = GetTemporary(context, node, 2);\n-          TfLiteTensor* scratch3 = GetTemporary(context, node, 3);\n-          TfLiteTensor* scratch4 = GetTemporary(context, node, 4);\n-          TfLiteTensor* scratch5 = GetTemporary(context, node, 5);\n-          TfLiteTensor* scratch6 = GetTemporary(context, node, 6);\n-          TfLiteTensor* scratch7 = GetTemporary(context, node, 7);\n+          TfLiteTensor* scratch0;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 0, &scratch0));\n+          TfLiteTensor* scratch1;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 1, &scratch1));\n+          TfLiteTensor* scratch2;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 2, &scratch2));\n+          TfLiteTensor* scratch3;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 3, &scratch3));\n+          TfLiteTensor* scratch4;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 4, &scratch4));\n+          TfLiteTensor* scratch5;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 5, &scratch5));\n+          TfLiteTensor* scratch6;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 6, &scratch6));\n+          TfLiteTensor* scratch7;\n+          TF_LITE_ENSURE_OK(context,\n+                            GetTemporarySafe(context, node, 7, &scratch7));\n           return lstm_eval::EvalInteger8x8_8(\n               input, input_to_input_weights, input_to_forget_weights,\n               input_to_cell_weights, input_to_output_weights,\n@@ -2046,12 +2191,19 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE(context, node->inputs->size == kInputNum);\n   TF_LITE_ENSURE(context, node->outputs->size == kOutputNum);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputData);\n-  const TfLiteTensor* prev_activation =\n-      GetInput(context, node, kInputPrevActivation);\n-  const TfLiteTensor* weights = GetInput(context, node, kInputWeights);\n-  const TfLiteTensor* bias = GetInput(context, node, kInputBiases);\n-  const TfLiteTensor* prev_state = GetInput(context, node, kInputPrevState);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputData, &input));\n+  const TfLiteTensor* prev_activation;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputPrevActivation,\n+                                          &prev_activation));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputWeights, &weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputBiases, &bias));\n+  const TfLiteTensor* prev_state;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputPrevState, &prev_state));\n \n   TF_LITE_ENSURE_EQ(context, input->dims->size, 2);\n   const int num_batches = input->dims->data[0];\n@@ -2073,11 +2225,18 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, prev_state->dims->data[0], num_batches);\n   TF_LITE_ENSURE_EQ(context, prev_state->dims->data[1], activation_depth);\n \n-  TfLiteTensor* activation_out = GetOutput(context, node, kOutputActivation);\n-  TfLiteTensor* state_out = GetOutput(context, node, kOutputState);\n-  TfLiteTensor* concat_temp = GetOutput(context, node, kOutputConcatTemp);\n-  TfLiteTensor* activation_temp =\n-      GetOutput(context, node, kOutputActivationTemp);\n+  TfLiteTensor* activation_out;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kOutputActivation,\n+                                           &activation_out));\n+  TfLiteTensor* state_out;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputState, &state_out));\n+  TfLiteTensor* concat_temp;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputConcatTemp, &concat_temp));\n+  TfLiteTensor* activation_temp;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kOutputActivationTemp,\n+                                           &activation_temp));\n \n   TF_LITE_ENSURE_OK(context, context->ResizeTensor(\n                                  context, activation_out,\n@@ -2106,18 +2265,32 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputData);\n-  const TfLiteTensor* prev_activation =\n-      GetInput(context, node, kInputPrevActivation);\n-  const TfLiteTensor* weights = GetInput(context, node, kInputWeights);\n-  const TfLiteTensor* bias = GetInput(context, node, kInputBiases);\n-  const TfLiteTensor* prev_state = GetInput(context, node, kInputPrevState);\n-\n-  TfLiteTensor* activation_out = GetOutput(context, node, kOutputActivation);\n-  TfLiteTensor* state_out = GetOutput(context, node, kOutputState);\n-  TfLiteTensor* concat_temp = GetOutput(context, node, kOutputConcatTemp);\n-  TfLiteTensor* activation_temp =\n-      GetOutput(context, node, kOutputActivationTemp);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputData, &input));\n+  const TfLiteTensor* prev_activation;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputPrevActivation,\n+                                          &prev_activation));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputWeights, &weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputBiases, &bias));\n+  const TfLiteTensor* prev_state;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputPrevState, &prev_state));\n+\n+  TfLiteTensor* activation_out;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kOutputActivation,\n+                                           &activation_out));\n+  TfLiteTensor* state_out;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputState, &state_out));\n+  TfLiteTensor* concat_temp;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputConcatTemp, &concat_temp));\n+  TfLiteTensor* activation_temp;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kOutputActivationTemp,\n+                                           &activation_temp));\n \n   if (input->type == kTfLiteFloat32 &&\n       prev_activation->type == kTfLiteFloat32 &&"
    },
    "modified_file_37": {
        "mod_filename": "tensorflow/lite/kernels/matrix_diag.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -32,12 +32,15 @@ constexpr int kOutputTensor = 0;\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   TfLiteIntArray* input_dims = input->dims;\n   int input_dims_size = input_dims->size;\n   TF_LITE_ENSURE(context, input_dims_size >= 1);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   // Resize the output tensor.\n   TfLiteIntArray* output_shape = TfLiteIntArrayCreate(input_dims_size + 1);\n   for (int i = 0; i < input_dims_size; i++) {\n@@ -116,8 +119,11 @@ void FillDiagHelper(const TfLiteTensor* input, TfLiteTensor* output) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   FillDiagHelper(input, output);\n   return kTfLiteOk;\n }"
    },
    "modified_file_38": {
        "mod_filename": "tensorflow/lite/kernels/matrix_set_diag.cc",
        "status": "modified",
        "add_lines": 13,
        "dele_lines": 5,
        "patch": "@@ -33,12 +33,15 @@ constexpr int kOutputTensor = 0;\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   TfLiteIntArray* input_dims = input->dims;\n   int input_dims_size = input_dims->size;\n   TF_LITE_ENSURE(context, input_dims_size >= 2);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TfLiteIntArray* output_shape = TfLiteIntArrayCreate(input_dims_size);\n   for (int i = 0; i < input_dims_size; i++) {\n@@ -126,9 +129,14 @@ void FillDiagHelper(const TfLiteTensor* input, const TfLiteTensor* diag,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* diag = GetInput(context, node, kDiagonalTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* diag;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kDiagonalTensor, &diag));\n   FillDiagHelper(input, diag, output);\n   return kTfLiteOk;\n }"
    },
    "modified_file_39": {
        "mod_filename": "tensorflow/lite/kernels/mfcc.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -73,9 +73,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input_wav = GetInput(context, node, kInputTensorWav);\n-  const TfLiteTensor* input_rate = GetInput(context, node, kInputTensorRate);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input_wav;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorWav, &input_wav));\n+  const TfLiteTensor* input_rate;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorRate, &input_rate));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_wav), 3);\n   TF_LITE_ENSURE_EQ(context, NumElements(input_rate), 1);\n@@ -101,9 +107,15 @@ template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteMfccParams*>(node->user_data);\n \n-  const TfLiteTensor* input_wav = GetInput(context, node, kInputTensorWav);\n-  const TfLiteTensor* input_rate = GetInput(context, node, kInputTensorRate);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input_wav;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorWav, &input_wav));\n+  const TfLiteTensor* input_rate;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorRate, &input_rate));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   const int32 sample_rate = *GetTensorData<int>(input_rate);\n "
    },
    "modified_file_40": {
        "mod_filename": "tensorflow/lite/kernels/mirror_pad.cc",
        "status": "modified",
        "add_lines": 12,
        "dele_lines": 6,
        "patch": "@@ -162,8 +162,10 @@ struct MirrorPadWorkerTask : cpu_backend_threadpool::Task {\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   ruy::profiler::ScopeLabel label(\"MirrorPad\");\n-  const TfLiteTensor* input_tensor = GetInput(context, node, 0);\n-  const TfLiteTensor* padding_matrix = GetInput(context, node, 1);\n+  const TfLiteTensor* input_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input_tensor));\n+  const TfLiteTensor* padding_matrix;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &padding_matrix));\n   auto* params =\n       reinterpret_cast<TfLiteMirrorPaddingParams*>(node->builtin_data);\n \n@@ -172,7 +174,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   }\n   const int input_dims = NumDimensions(input_tensor);\n \n-  TfLiteTensor* output_tensor = GetOutput(context, node, 0);\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output_tensor));\n   if (IsDynamicTensor(output_tensor)) {\n     auto output_size = GetPaddedOutputShape(input_tensor, padding_matrix);\n     if (output_size == nullptr) {\n@@ -258,9 +261,12 @@ void* Init(TfLiteContext* context, const char* buffer, size_t length) {\n void Free(TfLiteContext* context, void* buffer) {}\n \n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input_tensor = GetInput(context, node, 0);\n-  const TfLiteTensor* padding_matrix = GetInput(context, node, 1);\n-  TfLiteTensor* output_tensor = GetOutput(context, node, 0);\n+  const TfLiteTensor* input_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input_tensor));\n+  const TfLiteTensor* padding_matrix;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &padding_matrix));\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output_tensor));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(padding_matrix), 2);\n   TF_LITE_ENSURE_EQ(context, SizeOfDimension(padding_matrix, 0),"
    },
    "modified_file_41": {
        "mod_filename": "tensorflow/lite/kernels/mul.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -75,9 +75,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n \n@@ -259,9 +265,15 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteMulParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n     EvalMul<kernel_type>(context, node, params, data, input1, input2, output);"
    },
    "modified_file_42": {
        "mod_filename": "tensorflow/lite/kernels/neg.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -34,17 +34,23 @@ constexpr int kOutputTensor = 0;\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   output->type = input->type;\n   return context->ResizeTensor(context, output,\n                                TfLiteIntArrayCopy(input->dims));\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   switch (input->type) {\n     case kTfLiteInt64:\n       reference_ops::Negate("
    },
    "modified_file_43": {
        "mod_filename": "tensorflow/lite/kernels/non_max_suppression.cc",
        "status": "modified",
        "add_lines": 81,
        "dele_lines": 42,
        "patch": "@@ -79,20 +79,25 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Boxes & Scores.\n-  const TfLiteTensor* input_boxes = GetInput(context, node, kInputTensorBoxes);\n+  const TfLiteTensor* input_boxes;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputTensorBoxes, &input_boxes));\n   TF_LITE_ENSURE_EQ(context, input_boxes->type, kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_boxes), 2);\n   TF_LITE_ENSURE_EQ(context, SizeOfDimension(input_boxes, 1), 4);\n   const int num_boxes = SizeOfDimension(input_boxes, 0);\n-  const TfLiteTensor* input_scores =\n-      GetInput(context, node, kInputTensorScores);\n+  const TfLiteTensor* input_scores;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputTensorScores, &input_scores));\n   TF_LITE_ENSURE_EQ(context, input_scores->type, kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_scores), 1);\n   TF_LITE_ENSURE_EQ(context, num_boxes, SizeOfDimension(input_scores, 0));\n \n   // Max output size.\n-  const TfLiteTensor* input_max_output_size =\n-      GetInput(context, node, kInputTensorMaxOutputSize);\n+  const TfLiteTensor* input_max_output_size;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorMaxOutputSize,\n+                                 &input_max_output_size));\n   TF_LITE_ENSURE_EQ(context, input_max_output_size->type, kTfLiteInt32);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_max_output_size), 0);\n   const bool is_max_output_size_const = IsConstantTensor(input_max_output_size);\n@@ -103,30 +108,43 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // IoU & Score thresholds.\n-  const TfLiteTensor* input_iou_threshold =\n-      GetInput(context, node, kInputTensorIouThreshold);\n+  const TfLiteTensor* input_iou_threshold;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorIouThreshold,\n+                                 &input_iou_threshold));\n   TF_LITE_ENSURE_EQ(context, input_iou_threshold->type, kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_iou_threshold), 0);\n-  const TfLiteTensor* input_score_threshold =\n-      GetInput(context, node, kInputTensorScoreThreshold);\n+  const TfLiteTensor* input_score_threshold;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorScoreThreshold,\n+                                 &input_score_threshold));\n   TF_LITE_ENSURE_EQ(context, input_iou_threshold->type, kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_score_threshold), 0);\n \n   if (is_soft_nms) {\n-    const TfLiteTensor* input_sigma =\n-        GetInput(context, node, kInputTensorSigma);\n+    const TfLiteTensor* input_sigma;\n+    TF_LITE_ENSURE_OK(\n+        context, GetInputSafe(context, node, kInputTensorSigma, &input_sigma));\n     TF_LITE_ENSURE_EQ(context, input_sigma->type, kTfLiteFloat32);\n     TF_LITE_ENSURE_EQ(context, NumDimensions(input_sigma), 0);\n \n     TF_LITE_ENSURE_EQ(context, NumOutputs(node), 3);\n-    TfLiteTensor* output_selected_indices =\n-        GetOutput(context, node, kSoftNMSOutputTensorSelectedIndices);\n+    TfLiteTensor* output_selected_indices;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetOutputSafe(context, node, kSoftNMSOutputTensorSelectedIndices,\n+                      &output_selected_indices));\n     output_selected_indices->type = kTfLiteInt32;\n-    TfLiteTensor* output_selected_scores =\n-        GetOutput(context, node, kSoftNMSOutputTensorSelectedScores);\n+    TfLiteTensor* output_selected_scores;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                             kSoftNMSOutputTensorSelectedScores,\n+                                             &output_selected_scores));\n     output_selected_scores->type = kTfLiteFloat32;\n-    TfLiteTensor* output_num_selected_indices =\n-        GetOutput(context, node, kSoftNMSOutputTensorNumSelectedIndices);\n+    TfLiteTensor* output_num_selected_indices;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetOutputSafe(context, node, kSoftNMSOutputTensorNumSelectedIndices,\n+                      &output_num_selected_indices));\n     output_num_selected_indices->type = kTfLiteInt32;\n     SetTensorSizes(context, output_num_selected_indices, {});\n \n@@ -139,11 +157,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n   } else {\n     TF_LITE_ENSURE_EQ(context, NumOutputs(node), 2);\n-    TfLiteTensor* output_selected_indices =\n-        GetOutput(context, node, kNMSOutputTensorSelectedIndices);\n+    TfLiteTensor* output_selected_indices;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kNMSOutputTensorSelectedIndices,\n+                               &output_selected_indices));\n     output_selected_indices->type = kTfLiteInt32;\n-    TfLiteTensor* output_num_selected_indices =\n-        GetOutput(context, node, kNMSOutputTensorNumSelectedIndices);\n+    TfLiteTensor* output_num_selected_indices;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                             kNMSOutputTensorNumSelectedIndices,\n+                                             &output_num_selected_indices));\n     output_num_selected_indices->type = kTfLiteInt32;\n     SetTensorSizes(context, output_num_selected_indices, {});\n \n@@ -179,42 +201,57 @@ void ResetUnusedElementsToZeroes(const int max_output_size,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const bool is_soft_nms = NumInputs(node) == 6;\n \n-  const TfLiteTensor* input_boxes = GetInput(context, node, kInputTensorBoxes);\n+  const TfLiteTensor* input_boxes;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputTensorBoxes, &input_boxes));\n   const int num_boxes = SizeOfDimension(input_boxes, 0);\n-  const TfLiteTensor* input_scores =\n-      GetInput(context, node, kInputTensorScores);\n-  const TfLiteTensor* input_max_output_size =\n-      GetInput(context, node, kInputTensorMaxOutputSize);\n+  const TfLiteTensor* input_scores;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputTensorScores, &input_scores));\n+  const TfLiteTensor* input_max_output_size;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorMaxOutputSize,\n+                                 &input_max_output_size));\n   const int max_output_size_value = *GetTensorData<int>(input_max_output_size);\n   TF_LITE_ENSURE(context, (max_output_size_value >= 0));\n   const bool is_max_output_size_const = IsConstantTensor(input_max_output_size);\n-  const TfLiteTensor* input_iou_threshold =\n-      GetInput(context, node, kInputTensorIouThreshold);\n+  const TfLiteTensor* input_iou_threshold;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorIouThreshold,\n+                                 &input_iou_threshold));\n   const float iou_threshold = *GetTensorData<float>(input_iou_threshold);\n-  const TfLiteTensor* input_score_threshold =\n-      GetInput(context, node, kInputTensorScoreThreshold);\n+  const TfLiteTensor* input_score_threshold;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorScoreThreshold,\n+                                 &input_score_threshold));\n   const float score_threshold = *GetTensorData<float>(input_score_threshold);\n \n   TfLiteTensor* output_selected_indices = nullptr;\n   TfLiteTensor* output_selected_scores = nullptr;\n   TfLiteTensor* output_num_selected_indices = nullptr;\n \n   if (is_soft_nms) {\n-    const TfLiteTensor* input_sigma =\n-        GetInput(context, node, kInputTensorSigma);\n+    const TfLiteTensor* input_sigma;\n+    TF_LITE_ENSURE_OK(\n+        context, GetInputSafe(context, node, kInputTensorSigma, &input_sigma));\n     const float soft_nms_sigma = *GetTensorData<float>(input_sigma);\n     if (soft_nms_sigma < 0) {\n       context->ReportError(context, \"Invalid sigma value for soft NMS: %f\",\n                            soft_nms_sigma);\n       return kTfLiteError;\n     }\n \n-    output_selected_indices =\n-        GetOutput(context, node, kSoftNMSOutputTensorSelectedIndices);\n-    output_selected_scores =\n-        GetOutput(context, node, kSoftNMSOutputTensorSelectedScores);\n-    output_num_selected_indices =\n-        GetOutput(context, node, kSoftNMSOutputTensorNumSelectedIndices);\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetOutputSafe(context, node, kSoftNMSOutputTensorSelectedIndices,\n+                      &output_selected_indices));\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                             kSoftNMSOutputTensorSelectedScores,\n+                                             &output_selected_scores));\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetOutputSafe(context, node, kSoftNMSOutputTensorNumSelectedIndices,\n+                      &output_num_selected_indices));\n     if (!is_max_output_size_const) {\n       SetTensorSizes(context, output_selected_indices, {max_output_size_value});\n       SetTensorSizes(context, output_selected_scores, {max_output_size_value});\n@@ -228,10 +265,12 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n         max_output_size_value, *output_num_selected_indices->data.i32,\n         output_selected_indices->data.i32, output_selected_scores->data.f);\n   } else {\n-    output_selected_indices =\n-        GetOutput(context, node, kNMSOutputTensorSelectedIndices);\n-    output_num_selected_indices =\n-        GetOutput(context, node, kNMSOutputTensorNumSelectedIndices);\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kNMSOutputTensorSelectedIndices,\n+                               &output_selected_indices));\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                             kNMSOutputTensorNumSelectedIndices,\n+                                             &output_num_selected_indices));\n     if (!is_max_output_size_const) {\n       SetTensorSizes(context, output_selected_indices, {max_output_size_value});\n     }"
    },
    "modified_file_44": {
        "mod_filename": "tensorflow/lite/kernels/numeric_verify.cc",
        "status": "modified",
        "add_lines": 6,
        "dele_lines": 2,
        "patch": "@@ -109,7 +109,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   node->temporaries = TfLiteIntArrayCreate(1);\n   node->temporaries->data[0] = op_data->cache_tensor_id;\n \n-  TfLiteTensor* dequantized = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* dequantized;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/0, &dequantized));\n   dequantized->type = op_context.ref->type;\n   dequantized->allocation_type = kTfLiteDynamic;\n \n@@ -142,7 +144,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Dequantize the input\n-  TfLiteTensor* dequantized = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* dequantized;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/0, &dequantized));\n   auto status = builtin::dequantize::DequantizeImpl<kernel_type>(\n       context, node, op_context.input, dequantized);\n   if (status != kTfLiteOk) {"
    },
    "modified_file_45": {
        "mod_filename": "tensorflow/lite/kernels/pack.cc",
        "status": "modified",
        "add_lines": 12,
        "dele_lines": 5,
        "patch": "@@ -38,7 +38,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), data->values_count);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input0 = GetInput(context, node, 0);\n+  const TfLiteTensor* input0;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input0));\n   const int dimension_size = NumDimensions(input0) + 1;\n   if (data->axis < 0) {\n     data->axis += dimension_size;\n@@ -55,7 +56,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n   // Make sure all inputs have the same shape and type.\n   for (int i = 1; i < data->values_count; ++i) {\n-    const TfLiteTensor* input = GetInput(context, node, i);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &input));\n     TF_LITE_ENSURE(context, HaveSameShapes(input0, input));\n     TF_LITE_ENSURE_TYPES_EQ(context, input0->type, input->type);\n   }\n@@ -72,13 +74,16 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, input0->type);\n \n   // Guarantee input/output quantization params match as we do not support\n   // packing quantized tensors.\n   for (int i = 0; i < data->values_count; i++) {\n-    const TfLiteTensor* input = GetInput(context, node, i);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &input));\n     TF_LITE_ENSURE_EQ(context, input->params.zero_point,\n                       output->params.zero_point);\n     TF_LITE_ENSURE_EQ(context, input->params.scale, output->params.scale);\n@@ -106,7 +111,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const TfLitePackParams* data =\n       reinterpret_cast<TfLitePackParams*>(node->builtin_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   switch (output->type) {\n     case kTfLiteFloat32: {\n       return PackImpl<float>(context, node, output, data->values_count,"
    },
    "modified_file_46": {
        "mod_filename": "tensorflow/lite/kernels/pooling.cc",
        "status": "modified",
        "add_lines": 16,
        "dele_lines": 8,
        "patch": "@@ -71,8 +71,10 @@ TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {\n \n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n@@ -368,8 +370,10 @@ TfLiteStatus AverageEval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   switch (input->type) {  // Already know in/out types are same.\n     case kTfLiteFloat32:\n       AverageEvalFloat<kernel_type>(context, node, params, data, input, output);\n@@ -399,8 +403,10 @@ TfLiteStatus MaxEval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   switch (input->type) {  // Already know in/out types are same.\n     case kTfLiteFloat32:\n       MaxEvalFloat<kernel_type>(context, node, params, data, input, output);\n@@ -430,8 +436,10 @@ TfLiteStatus L2Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   switch (input->type) {  // Already know in/out types are same.\n     case kTfLiteFloat32:\n       L2EvalFloat<kernel_type>(context, node, params, data, input, output);"
    },
    "modified_file_47": {
        "mod_filename": "tensorflow/lite/kernels/pow.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -54,9 +54,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n \n@@ -112,9 +118,15 @@ TfLiteStatus CheckValue(TfLiteContext* context, const TfLiteTensor* input) {\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (output->type) {\n     case kTfLiteInt32: {"
    },
    "modified_file_48": {
        "mod_filename": "tensorflow/lite/kernels/quantize.cc",
        "status": "modified",
        "add_lines": 8,
        "dele_lines": 4,
        "patch": "@@ -97,8 +97,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n \n   // TODO(b/128934713): Add support for fixed-point per-channel quantization.\n   // Currently this only support affine per-layer quantization.\n@@ -141,8 +143,10 @@ template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = static_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n \n   const RuntimeShape input_shape = GetTensorShape(input);\n   const RuntimeShape output_shape = GetTensorShape(output);"
    },
    "modified_file_49": {
        "mod_filename": "tensorflow/lite/kernels/range.cc",
        "status": "modified",
        "add_lines": 19,
        "dele_lines": 9,
        "patch": "@@ -83,9 +83,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 3);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* start = GetInput(context, node, kStartTensor);\n-  const TfLiteTensor* limit = GetInput(context, node, kLimitTensor);\n-  const TfLiteTensor* delta = GetInput(context, node, kDeltaTensor);\n+  const TfLiteTensor* start;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStartTensor, &start));\n+  const TfLiteTensor* limit;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kLimitTensor, &limit));\n+  const TfLiteTensor* delta;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kDeltaTensor, &delta));\n   // Make sure all the inputs are scalars.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(start), 0);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(limit), 0);\n@@ -103,7 +106,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_TYPES_EQ(context, limit->type, dtype);\n   TF_LITE_ENSURE_TYPES_EQ(context, delta->type, dtype);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = dtype;\n \n   if (IsConstantTensor(start) && IsConstantTensor(limit) &&\n@@ -130,11 +135,16 @@ void EvalImpl(const TfLiteTensor* start, const TfLiteTensor* delta,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* start = GetInput(context, node, kStartTensor);\n-  const TfLiteTensor* limit = GetInput(context, node, kLimitTensor);\n-  const TfLiteTensor* delta = GetInput(context, node, kDeltaTensor);\n-\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* start;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStartTensor, &start));\n+  const TfLiteTensor* limit;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kLimitTensor, &limit));\n+  const TfLiteTensor* delta;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kDeltaTensor, &delta));\n+\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_50": {
        "mod_filename": "tensorflow/lite/kernels/rank.cc",
        "status": "modified",
        "add_lines": 5,
        "dele_lines": 2,
        "patch": "@@ -31,8 +31,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = kTfLiteInt32;\n \n   // By design, the input shape is always known at the time of Prepare, even"
    },
    "modified_file_51": {
        "mod_filename": "tensorflow/lite/kernels/read_variable.cc",
        "status": "modified",
        "add_lines": 12,
        "dele_lines": 6,
        "patch": "@@ -34,12 +34,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->inputs->size, 1);\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n \n-  const TfLiteTensor* input_resource_id_tensor =\n-      GetInput(context, node, kInputVariableId);\n+  const TfLiteTensor* input_resource_id_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputVariableId,\n+                                          &input_resource_id_tensor));\n   TF_LITE_ENSURE_EQ(context, input_resource_id_tensor->type, kTfLiteInt32);\n   TF_LITE_ENSURE_EQ(context, NumElements(input_resource_id_tensor), 1);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputValue);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputValue, &output));\n   SetTensorToDynamic(output);\n \n   return kTfLiteOk;\n@@ -48,15 +51,18 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   Subgraph* subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n \n-  const TfLiteTensor* input_resource_id_tensor =\n-      GetInput(context, node, kInputVariableId);\n+  const TfLiteTensor* input_resource_id_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputVariableId,\n+                                          &input_resource_id_tensor));\n   int resource_id = input_resource_id_tensor->data.i32[0];\n   auto& resources = subgraph->resources();\n   auto* variable = resource::GetResourceVariable(&resources, resource_id);\n   TF_LITE_ENSURE(context, variable != nullptr);\n \n   TfLiteTensor* variable_tensor = variable->GetTensor();\n-  TfLiteTensor* output = GetOutput(context, node, kOutputValue);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputValue, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, variable_tensor->type, output->type);\n   TF_LITE_ENSURE_OK("
    },
    "modified_file_52": {
        "mod_filename": "tensorflow/lite/kernels/reduce.cc",
        "status": "modified",
        "add_lines": 41,
        "dele_lines": 14,
        "patch": "@@ -170,7 +170,9 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n   TfLiteIntArrayFree(node->temporaries);\n   node->temporaries = TfLiteIntArrayCreate(3);\n   node->temporaries->data[0] = op_data->scratch_tensor_index;\n-  TfLiteTensor* scratch_tensor = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* scratch_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n   scratch_tensor->type = kTfLiteInt32;\n   scratch_tensor->allocation_type = kTfLiteArenaRw;\n   TfLiteIntArray* index_size = TfLiteIntArrayCreate(1);\n@@ -180,11 +182,15 @@ TfLiteStatus InitializeTemporaries(TfLiteContext* context, TfLiteNode* node,\n \n   // Creates a temp tensor to store resolved axis given input data.\n   node->temporaries->data[1] = op_data->scratch_tensor_index + 1;\n-  TfLiteTensor* resolved_axis = GetTemporary(context, node, /*index=*/1);\n+  TfLiteTensor* resolved_axis;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/1, &resolved_axis));\n   resolved_axis->type = kTfLiteInt32;\n   // Creates a temp tensor to store temp sums when calculating mean.\n   node->temporaries->data[2] = op_data->scratch_tensor_index + 2;\n-  TfLiteTensor* temp_sum = GetTemporary(context, node, /*index=*/2);\n+  TfLiteTensor* temp_sum;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/2, &temp_sum));\n   switch (op_context->input->type) {\n     case kTfLiteFloat32:\n       temp_sum->type = kTfLiteFloat32;\n@@ -217,7 +223,9 @@ TfLiteStatus PrepareSimple(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_TYPES_EQ(context, op_context.axis->type, kTfLiteInt32);\n   TF_LITE_ENSURE_OK(context, InitializeTemporaries(context, node, &op_context));\n \n-  TfLiteTensor* resolved_axis = GetTemporary(context, node, /*index=*/1);\n+  TfLiteTensor* resolved_axis;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/1, &resolved_axis));\n   // Leaves work to Eval if axis is not constant; else resizes output.\n   if (!IsConstantTensor(op_context.axis)) {\n     SetTensorToDynamic(op_context.output);\n@@ -233,7 +241,8 @@ TfLiteStatus PrepareSimple(TfLiteContext* context, TfLiteNode* node) {\n \n TfLiteStatus PrepareAny(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteBool);\n   return PrepareSimple(context, node);\n }\n@@ -254,7 +263,9 @@ TfLiteStatus PrepareMeanOrSum(TfLiteContext* context, TfLiteNode* node) {\n     QuantizeMultiplier(real_multiplier, &data->multiplier, &exponent);\n     data->shift = exponent;\n   }\n-  TfLiteTensor* temp_sum = GetTemporary(context, node, /*index=*/2);\n+  TfLiteTensor* temp_sum;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/2, &temp_sum));\n   if (!IsConstantTensor(op_context.axis)) {\n     SetTensorToDynamic(temp_sum);\n     return kTfLiteOk;\n@@ -343,9 +354,15 @@ TfLiteStatus EvalMean(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   int num_axis = static_cast<int>(NumElements(op_context.axis));\n-  TfLiteTensor* temp_index = GetTemporary(context, node, /*index=*/0);\n-  TfLiteTensor* resolved_axis = GetTemporary(context, node, /*index=*/1);\n-  TfLiteTensor* temp_sum = GetTemporary(context, node, /*index=*/2);\n+  TfLiteTensor* temp_index;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/0, &temp_index));\n+  TfLiteTensor* resolved_axis;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/1, &resolved_axis));\n+  TfLiteTensor* temp_sum;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/2, &temp_sum));\n   // Resize the output tensor if the output tensor is dynamic.\n   if (IsDynamicTensor(op_context.output)) {\n     TF_LITE_ENSURE_OK(context,\n@@ -490,8 +507,12 @@ TfLiteStatus EvalLogic(TfLiteContext* context, TfLiteNode* node,\n                        OpContext* op_context, T init_value,\n                        T reducer(const T current, const T in)) {\n   int64_t num_axis = NumElements(op_context->axis);\n-  TfLiteTensor* temp_index = GetTemporary(context, node, /*index=*/0);\n-  TfLiteTensor* resolved_axis = GetTemporary(context, node, /*index=*/1);\n+  TfLiteTensor* temp_index;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/0, &temp_index));\n+  TfLiteTensor* resolved_axis;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/1, &resolved_axis));\n   // Resize the output tensor if the output tensor is dynamic.\n   if (IsDynamicTensor(op_context->output)) {\n     TF_LITE_ENSURE_OK(context,\n@@ -621,9 +642,15 @@ TfLiteStatus EvalSum(TfLiteContext* context, TfLiteNode* node) {\n   if (need_rescale) {\n     // Rescaling 8bit reduce sum.\n     int num_axis = static_cast<int>(NumElements(op_context.axis));\n-    TfLiteTensor* temp_index = GetTemporary(context, node, /*index=*/0);\n-    TfLiteTensor* resolved_axis = GetTemporary(context, node, /*index=*/1);\n-    TfLiteTensor* temp_sum = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* temp_index;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/0, &temp_index));\n+    TfLiteTensor* resolved_axis;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/1, &resolved_axis));\n+    TfLiteTensor* temp_sum;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/2, &temp_sum));\n     // Resize the output tensor if the output tensor is dynamic.\n     if (IsDynamicTensor(op_context.output)) {\n       TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_53": {
        "mod_filename": "tensorflow/lite/kernels/reshape.cc",
        "status": "modified",
        "add_lines": 16,
        "dele_lines": 6,
        "patch": "@@ -38,8 +38,11 @@ TfLiteStatus ResizeOutput(TfLiteContext* context, TfLiteNode* node) {\n   std::unique_ptr<TfLiteIntArray, void (*)(TfLiteIntArray*)>\n       scoped_output_shape(output_shape, TfLiteIntArrayFree);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Tensorflow's Reshape allows one of the shape components to have the\n   // special -1 value, meaning it will be calculated automatically based on the\n@@ -70,6 +73,7 @@ TfLiteStatus ResizeOutput(TfLiteContext* context, TfLiteNode* node) {\n inline TfLiteIntArray* GetOutputShapeFromTensor(TfLiteContext* context,\n                                                 TfLiteNode* node) {\n   const TfLiteTensor* shape = GetInput(context, node, kShapeTensor);\n+  if (shape == nullptr) return nullptr;\n \n   TfLiteIntArray* output_shape = TfLiteIntArrayCreate(shape->dims->data[0]);\n   for (int i = 0; i < output_shape->size; ++i) {\n@@ -103,7 +107,8 @@ inline TfLiteIntArray* GetOutputShapeFromParam(TfLiteContext* context,\n // Check if the shape tensor is valid. Shapes should be int32 vectors.\n inline bool ShapeIsVector(TfLiteContext* context, TfLiteNode* node) {\n   const TfLiteTensor* shape = GetInput(context, node, kShapeTensor);\n-  return (shape->dims->size == 1 && shape->type == kTfLiteInt32);\n+  return (shape != nullptr && shape->dims->size == 1 &&\n+          shape->type == kTfLiteInt32);\n }\n \n TfLiteIntArray* GetOutputShape(TfLiteContext* context, TfLiteNode* node) {\n@@ -122,7 +127,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // calculate their shapes now. String tensors don't benefit from having their\n   // shapes precalculated because the actual memory can only be allocated after\n   // we know all the content.\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   if (output->type != kTfLiteString) {\n     if (NumInputs(node) == 1 ||\n         IsConstantTensor(GetInput(context, node, kShapeTensor))) {\n@@ -135,8 +142,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // There are two ways in which the 'output' can be made dynamic: it could be\n   // a string tensor, or its shape cannot be calculated during Prepare(). In"
    },
    "modified_file_54": {
        "mod_filename": "tensorflow/lite/kernels/resize_bilinear.cc",
        "status": "modified",
        "add_lines": 14,
        "dele_lines": 6,
        "patch": "@@ -61,9 +61,13 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* size;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSizeTensor, &size));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // TODO(ahentz): Our current implementations rely on the inputs being 4D.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n@@ -96,9 +100,13 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteResizeBilinearParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* size;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSizeTensor, &size));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_55": {
        "mod_filename": "tensorflow/lite/kernels/resize_nearest_neighbor.cc",
        "status": "modified",
        "add_lines": 14,
        "dele_lines": 6,
        "patch": "@@ -60,9 +60,13 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* size;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSizeTensor, &size));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // TODO(ahentz): Our current implementations rely on the input being 4D,\n   // and the size being 1D tensor with exactly 2 elements.\n@@ -85,9 +89,13 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteResizeNearestNeighborParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* size;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSizeTensor, &size));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_56": {
        "mod_filename": "tensorflow/lite/kernels/reverse.cc",
        "status": "modified",
        "add_lines": 15,
        "dele_lines": 6,
        "patch": "@@ -35,8 +35,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* axis = GetInput(context, node, kAxisTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* axis;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kAxisTensor, &axis));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(axis), 1);\n   TF_LITE_ENSURE(context, NumDimensions(input) >= NumElements(axis));\n \n@@ -59,24 +61,31 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     context->ReportError(context, \"Current does not support more than 1 axis.\");\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TfLiteIntArray* output_shape = TfLiteIntArrayCopy(input->dims);\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, input->type);\n \n   return context->ResizeTensor(context, output, output_shape);\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* axis_tensor = GetInput(context, node, kAxisTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* axis_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kAxisTensor, &axis_tensor));\n   int axis = GetTensorData<int32_t>(axis_tensor)[0];\n   const int rank = NumDimensions(input);\n   if (axis < 0) {\n     axis += rank;\n   }\n \n   TF_LITE_ENSURE(context, axis >= 0 && axis < rank);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (output->type) {\n     case kTfLiteFloat32: {"
    },
    "modified_file_57": {
        "mod_filename": "tensorflow/lite/kernels/reverse_sequence.cc",
        "status": "modified",
        "add_lines": 22,
        "dele_lines": 10,
        "patch": "@@ -36,8 +36,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* seq_lengths = GetInput(context, node, kSeqLengthsTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* seq_lengths;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kSeqLengthsTensor, &seq_lengths));\n   TF_LITE_ENSURE_EQ(context, NumDimensions(seq_lengths), 1);\n \n   if (input->type != kTfLiteInt32 && input->type != kTfLiteFloat32 &&\n@@ -56,7 +59,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     return kTfLiteError;\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TfLiteIntArray* output_shape = TfLiteIntArrayCopy(input->dims);\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, input->type);\n \n@@ -65,9 +70,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n template <typename T, typename TS>\n TfLiteStatus ReverseSequenceImpl(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* seq_lengths_tensor =\n-      GetInput(context, node, kSeqLengthsTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* seq_lengths_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSeqLengthsTensor,\n+                                          &seq_lengths_tensor));\n   const TS* seq_lengths = GetTensorData<TS>(seq_lengths_tensor);\n \n   auto* params =\n@@ -86,7 +93,9 @@ TfLiteStatus ReverseSequenceImpl(TfLiteContext* context, TfLiteNode* node) {\n     TF_LITE_ENSURE(context, seq_lengths[i] <= SizeOfDimension(input, seq_dim));\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   reference_ops::ReverseSequence<T, TS>(\n       seq_lengths, seq_dim, batch_dim, GetTensorShape(input),\n@@ -98,8 +107,9 @@ TfLiteStatus ReverseSequenceImpl(TfLiteContext* context, TfLiteNode* node) {\n \n template <typename T>\n TfLiteStatus ReverseSequenceHelper(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* seq_lengths_tensor =\n-      GetInput(context, node, kSeqLengthsTensor);\n+  const TfLiteTensor* seq_lengths_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSeqLengthsTensor,\n+                                          &seq_lengths_tensor));\n   switch (seq_lengths_tensor->type) {\n     case kTfLiteInt32: {\n       return ReverseSequenceImpl<T, int32_t>(context, node);\n@@ -119,7 +129,9 @@ TfLiteStatus ReverseSequenceHelper(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (output->type) {\n     case kTfLiteFloat32: {"
    },
    "modified_file_58": {
        "mod_filename": "tensorflow/lite/kernels/rfft2d.cc",
        "status": "modified",
        "add_lines": 64,
        "dele_lines": 28,
        "patch": "@@ -73,16 +73,20 @@ static TfLiteStatus InitTemporaryTensors(TfLiteContext* context,\n   data->fft_double_working_area_id = first_new_index + 1;\n \n   // Set up FFT integer working area buffer.\n-  TfLiteTensor* fft_integer_working_area =\n-      GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n+  TfLiteTensor* fft_integer_working_area;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, kFftIntegerWorkingAreaTensor,\n+                                &fft_integer_working_area));\n   fft_integer_working_area->type = kTfLiteInt32;\n   // If fft_length is not a constant tensor, fft_integer_working_area will be\n   // set to dynamic later in Prepare.\n   fft_integer_working_area->allocation_type = kTfLiteArenaRw;\n \n   // Set up FFT double working area buffer.\n-  TfLiteTensor* fft_double_working_area =\n-      GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n+  TfLiteTensor* fft_double_working_area;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, kFftDoubleWorkingAreaTensor,\n+                                     &fft_double_working_area));\n   // fft_double_working_area is a double tensor. Ideally, double should be\n   // added into tflite data types. However, since fft_double_working_area is a\n   // temporary tensor, and there are no ops having double input/output tensors\n@@ -100,10 +104,13 @@ static TfLiteStatus InitTemporaryTensors(TfLiteContext* context,\n \n TfLiteStatus ResizeOutputandTemporaryTensors(TfLiteContext* context,\n                                              TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const int num_dims = NumDimensions(input);\n   TF_LITE_ENSURE(context, num_dims >= 2);\n-  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n+  const TfLiteTensor* fft_length;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFftLengthTensor, &fft_length));\n   const int32_t* fft_length_data = GetTensorData<int32_t>(fft_length);\n   // The lib, fft2d, can only handle fft_lengths of power of 2.\n   TF_LITE_ENSURE(context, IsPowerOfTwo(fft_length_data[0]));\n@@ -116,24 +123,30 @@ TfLiteStatus ResizeOutputandTemporaryTensors(TfLiteContext* context,\n   int half_fft_working_length = fft_working_length / 2;\n \n   // Resize output tensor.\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TfLiteIntArray* output_shape = TfLiteIntArrayCopy(input->dims);\n   output_shape->data[num_dims - 2] = fft_length_data[0];\n   output_shape->data[num_dims - 1] = fft_length_data[1] / 2 + 1;\n   TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_shape));\n \n   // Resize temporary tensors, fft_integer_working_area.\n-  TfLiteTensor* fft_integer_working_area =\n-      GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n+  TfLiteTensor* fft_integer_working_area;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, kFftIntegerWorkingAreaTensor,\n+                                &fft_integer_working_area));\n   TfLiteIntArray* fft_integer_working_area_shape = TfLiteIntArrayCreate(1);\n   fft_integer_working_area_shape->data[0] =\n       2 + static_cast<int>(sqrt(fft_working_length));\n   TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, fft_integer_working_area,\n                                               fft_integer_working_area_shape));\n \n   // Resize temporary tensors, fft_double_working_area.\n-  TfLiteTensor* fft_double_working_area =\n-      GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n+  TfLiteTensor* fft_double_working_area;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, kFftDoubleWorkingAreaTensor,\n+                                     &fft_double_working_area));\n   TfLiteIntArray* fft_double_working_area_shape = TfLiteIntArrayCreate(1);\n   fft_double_working_area_shape->data[0] =\n       half_fft_working_length + fft_width / 4;\n@@ -157,7 +170,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n   // Check type and shape of the input tensor\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   TF_LITE_ENSURE(context, NumDimensions(input) >= 2);\n   if (input->type != kTfLiteFloat32) {\n     context->ReportError(context,\n@@ -167,7 +181,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Check type and shape of the fft_length tensor\n-  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n+  const TfLiteTensor* fft_length;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFftLengthTensor, &fft_length));\n   const RuntimeShape fft_length_shape = GetTensorShape(fft_length);\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(fft_length), 1);\n@@ -183,17 +199,23 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_STATUS(InitTemporaryTensors(context, node));\n \n   // Set output type\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = kTfLiteComplex64;\n \n   // Exit early if fft_length is a non-const tensor. Set output tensor and\n   // temporary tensors to dynamic, so that their tensor sizes can be determined\n   // in Eval.\n   if (!IsConstantTensor(fft_length)) {\n-    TfLiteTensor* fft_integer_working_area =\n-        GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n-    TfLiteTensor* fft_double_working_area =\n-        GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n+    TfLiteTensor* fft_integer_working_area;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kFftIntegerWorkingAreaTensor,\n+                                  &fft_integer_working_area));\n+    TfLiteTensor* fft_double_working_area;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kFftDoubleWorkingAreaTensor,\n+                                  &fft_double_working_area));\n     SetTensorToDynamic(fft_integer_working_area);\n     SetTensorToDynamic(fft_double_working_area);\n     SetTensorToDynamic(output);\n@@ -325,11 +347,16 @@ void PrepareOutputBuffer(complex<float>* output_data, int fft_height,\n }\n \n TfLiteStatus Rfft2dHelper(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const float* input_data = GetTensorData<float>(input);\n-  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n+  const TfLiteTensor* fft_length;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFftLengthTensor, &fft_length));\n   const int32_t* fft_length_data = GetTensorData<int32_t>(fft_length);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   complex<float>* output_data = GetTensorData<complex<float>>(output);\n \n   int fft_height, fft_width;\n@@ -358,14 +385,18 @@ TfLiteStatus Rfft2dHelper(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Get buffer for integer working area.\n-  TfLiteTensor* fft_integer_working_area =\n-      GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n+  TfLiteTensor* fft_integer_working_area;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, kFftIntegerWorkingAreaTensor,\n+                                &fft_integer_working_area));\n   int* fft_integer_working_area_data =\n       GetTensorData<int>(fft_integer_working_area);\n \n   // Get buffer for double working area.\n-  TfLiteTensor* fft_double_working_area =\n-      GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n+  TfLiteTensor* fft_double_working_area;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, kFftDoubleWorkingAreaTensor,\n+                                     &fft_double_working_area));\n   // Get double value out of the memory of fft_double_working_area_data.\n   double* fft_double_working_area_data = reinterpret_cast<double*>(\n       GetTensorData<int64_t>(fft_double_working_area));\n@@ -393,10 +424,15 @@ TfLiteStatus Rfft2dHelper(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* fft_length;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFftLengthTensor, &fft_length));\n   const int32_t* fft_length_data = GetTensorData<int32_t>(fft_length);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type != kTfLiteComplex64) {\n     context->ReportError(context,"
    },
    "modified_file_59": {
        "mod_filename": "tensorflow/lite/kernels/round.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -30,8 +30,11 @@ constexpr int kInputTensor = 0;\n constexpr int kOutputTensor = 0;\n \n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n@@ -41,8 +44,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   optimized_ops::Round(GetTensorShape(input), GetTensorData<float>(input),\n                        GetTensorShape(output), GetTensorData<float>(output));"
    },
    "modified_file_60": {
        "mod_filename": "tensorflow/lite/kernels/scatter_nd.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 8,
        "patch": "@@ -74,9 +74,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 3);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* indices = GetInput(context, node, kIndices);\n-  const TfLiteTensor* updates = GetInput(context, node, kUpdates);\n-  const TfLiteTensor* shape = GetInput(context, node, kShape);\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n+  const TfLiteTensor* updates;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kUpdates, &updates));\n+  const TfLiteTensor* shape;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kShape, &shape));\n \n   switch (updates->type) {\n     case kTfLiteFloat32:\n@@ -96,7 +99,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     return kTfLiteError;\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = updates->type;\n \n   if (IsConstantTensor(shape)) {\n@@ -163,10 +168,15 @@ TfLiteStatus EvalScatterNd(TfLiteContext* context, const TfLiteTensor* indices,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* indices = GetInput(context, node, kIndices);\n-  const TfLiteTensor* updates = GetInput(context, node, kUpdates);\n-  const TfLiteTensor* shape = GetInput(context, node, kShape);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n+  const TfLiteTensor* updates;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kUpdates, &updates));\n+  const TfLiteTensor* shape;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kShape, &shape));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (indices->type) {\n     case kTfLiteInt32:"
    },
    "modified_file_61": {
        "mod_filename": "tensorflow/lite/kernels/segment_sum.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 9,
        "patch": "@@ -64,11 +64,15 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* data = GetInput(context, node, kInputDataTensor);\n-  const TfLiteTensor* segment_ids =\n-      GetInput(context, node, kInputSegmentIdsTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-\n+  const TfLiteTensor* data;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputDataTensor, &data));\n+  const TfLiteTensor* segment_ids;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputSegmentIdsTensor,\n+                                          &segment_ids));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE(context,\n                  data->type == kTfLiteInt32 || data->type == kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, segment_ids->type, kTfLiteInt32);\n@@ -82,10 +86,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* data = GetInput(context, node, kInputDataTensor);\n-  const TfLiteTensor* segment_ids =\n-      GetInput(context, node, kInputSegmentIdsTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* data;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputDataTensor, &data));\n+  const TfLiteTensor* segment_ids;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputSegmentIdsTensor,\n+                                          &segment_ids));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_62": {
        "mod_filename": "tensorflow/lite/kernels/select.cc",
        "status": "modified",
        "add_lines": 24,
        "dele_lines": 10,
        "patch": "@@ -61,11 +61,18 @@ TfLiteStatus SelectPrepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 3);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input_condition =\n-      GetInput(context, node, kInputTensorCondition);\n-  const TfLiteTensor* input_x = GetInput(context, node, kInputTensorX);\n-  const TfLiteTensor* input_y = GetInput(context, node, kInputTensorY);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input_condition;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensorCondition,\n+                                          &input_condition));\n+  const TfLiteTensor* input_x;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorX, &input_x));\n+  const TfLiteTensor* input_y;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorY, &input_y));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Input must be bool.\n   TF_LITE_ENSURE_TYPES_EQ(context, input_condition->type, kTfLiteBool);\n@@ -111,11 +118,18 @@ TfLiteStatus SelectPrepare(TfLiteContext* context, TfLiteNode* node) {\n \n TfLiteStatus SelectEval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n-  const TfLiteTensor* input_condition =\n-      GetInput(context, node, kInputTensorCondition);\n-  const TfLiteTensor* input_x = GetInput(context, node, kInputTensorX);\n-  const TfLiteTensor* input_y = GetInput(context, node, kInputTensorY);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input_condition;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensorCondition,\n+                                          &input_condition));\n+  const TfLiteTensor* input_x;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorX, &input_x));\n+  const TfLiteTensor* input_y;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensorY, &input_y));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n #define TF_LITE_SELECT(type, op)                                           \\\n   reference_ops::op(GetTensorShape(input_condition),                       \\"
    },
    "modified_file_63": {
        "mod_filename": "tensorflow/lite/kernels/shape.cc",
        "status": "modified",
        "add_lines": 5,
        "dele_lines": 2,
        "patch": "@@ -40,8 +40,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   auto* params = reinterpret_cast<TfLiteShapeParams*>(node->builtin_data);\n   switch (params->out_type) {"
    },
    "modified_file_64": {
        "mod_filename": "tensorflow/lite/kernels/skip_gram.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 5,
        "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n \n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n #include \"tensorflow/lite/string_util.h\"\n \n@@ -48,10 +49,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  TF_LITE_ENSURE_TYPES_EQ(context, GetInput(context, node, 0)->type,\n-                          kTfLiteString);\n-  TF_LITE_ENSURE_TYPES_EQ(context, GetOutput(context, node, 0)->type,\n-                          kTfLiteString);\n+  const TfLiteTensor* input_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input_tensor));\n+  TF_LITE_ENSURE_TYPES_EQ(context, input_tensor->type, kTfLiteString);\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output_tensor));\n+  TF_LITE_ENSURE_TYPES_EQ(context, output_tensor->type, kTfLiteString);\n   return kTfLiteOk;\n }\n \n@@ -91,7 +94,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   // Split sentence to words.\n   std::vector<StringRef> words;\n-  tflite::StringRef strref = tflite::GetString(GetInput(context, node, 0), 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  tflite::StringRef strref = tflite::GetString(input, 0);\n   int prev_idx = 0;\n   for (int i = 1; i < strref.len; i++) {\n     if (isspace(*(strref.str + i))) {"
    },
    "modified_file_65": {
        "mod_filename": "tensorflow/lite/kernels/slice.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 8,
        "patch": "@@ -113,10 +113,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 3);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* begin = GetInput(context, node, kBeginTensor);\n-  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* begin;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBeginTensor, &begin));\n+  const TfLiteTensor* size;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSizeTensor, &size));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Ensure validity of input tensor and its dimension.\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n@@ -142,10 +147,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* begin = GetInput(context, node, kBeginTensor);\n-  const TfLiteTensor* size = GetInput(context, node, kSizeTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* begin;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBeginTensor, &begin));\n+  const TfLiteTensor* size;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kSizeTensor, &size));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_66": {
        "mod_filename": "tensorflow/lite/kernels/space_to_depth.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -45,8 +45,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n \n@@ -80,8 +83,11 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteSpaceToDepthParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n #define TF_LITE_SPACE_TO_DEPTH(type, scalar)                               \\\n   tflite::SpaceToDepthParams op_params;                                    \\"
    },
    "modified_file_67": {
        "mod_filename": "tensorflow/lite/kernels/sparse_to_dense.cc",
        "status": "modified",
        "add_lines": 36,
        "dele_lines": 16,
        "patch": "@@ -143,12 +143,18 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 4);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* indices = GetInput(context, node, kIndicesTensor);\n-  const TfLiteTensor* output_shape =\n-      GetInput(context, node, kOutputShapeTensor);\n-  const TfLiteTensor* values = GetInput(context, node, kValueInputTensor);\n-  const TfLiteTensor* default_value =\n-      GetInput(context, node, kDefaultValueTensor);\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kIndicesTensor, &indices));\n+  const TfLiteTensor* output_shape;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n+  const TfLiteTensor* values;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kValueInputTensor, &values));\n+  const TfLiteTensor* default_value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kDefaultValueTensor,\n+                                          &default_value));\n \n   // TODO(renjieliu): Handle validate_indices.\n \n@@ -178,7 +184,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(\n       context, CheckDimensionsMatch(context, indices, output_shape, values));\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = values->type;\n   TF_LITE_ENSURE_EQ(context, NumDimensions(output_shape), 1);\n \n@@ -191,13 +199,21 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n template <typename T, typename TI>\n TfLiteStatus SparseToDenseImpl(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* indices = GetInput(context, node, kIndicesTensor);\n-  const TfLiteTensor* output_shape =\n-      GetInput(context, node, kOutputShapeTensor);\n-  const TfLiteTensor* values = GetInput(context, node, kValueInputTensor);\n-  const TfLiteTensor* default_value =\n-      GetInput(context, node, kDefaultValueTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kIndicesTensor, &indices));\n+  const TfLiteTensor* output_shape;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n+  const TfLiteTensor* values;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kValueInputTensor, &values));\n+  const TfLiteTensor* default_value;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kDefaultValueTensor,\n+                                          &default_value));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,\n@@ -238,8 +254,12 @@ TfLiteStatus EvalForIndexType(TfLiteContext* context, TfLiteNode* node,\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* indices = GetInput(context, node, kIndicesTensor);\n-  const TfLiteTensor* values = GetInput(context, node, kValueInputTensor);\n+  const TfLiteTensor* indices;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kIndicesTensor, &indices));\n+  const TfLiteTensor* values;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kValueInputTensor, &values));\n \n   switch (values->type) {\n     case kTfLiteFloat32:"
    },
    "modified_file_68": {
        "mod_filename": "tensorflow/lite/kernels/split.cc",
        "status": "modified",
        "add_lines": 8,
        "dele_lines": 3,
        "patch": "@@ -41,7 +41,9 @@ struct OpContext {\n \n TfLiteStatus UseDynamicOutputTensors(TfLiteContext* context, TfLiteNode* node) {\n   for (int i = 0; i < NumOutputs(node); ++i) {\n-    SetTensorToDynamic(GetOutput(context, node, i));\n+    TfLiteTensor* tensor;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &tensor));\n+    SetTensorToDynamic(tensor);\n   }\n   return kTfLiteOk;\n }\n@@ -65,7 +67,8 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n   for (int i = 0; i < NumOutputs(node); ++i) {\n     TfLiteIntArray* output_dims = TfLiteIntArrayCopy(input->dims);\n     output_dims->data[axis_value] = slice_size;\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_dims));\n   }\n \n@@ -85,7 +88,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                      input_type == kTfLiteInt8 || input_type == kTfLiteInt16 ||\n                      input_type == kTfLiteInt32);\n   for (int i = 0; i < NumOutputs(node); ++i) {\n-    GetOutput(context, node, i)->type = input_type;\n+    TfLiteTensor* tensor;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &tensor));\n+    tensor->type = input_type;\n   }\n \n   // If we know the contents of the 'axis' tensor, resize all outputs."
    },
    "modified_file_69": {
        "mod_filename": "tensorflow/lite/kernels/split_v.cc",
        "status": "modified",
        "add_lines": 8,
        "dele_lines": 3,
        "patch": "@@ -45,7 +45,9 @@ struct OpContext {\n \n TfLiteStatus UseDynamicOutputTensors(TfLiteContext* context, TfLiteNode* node) {\n   for (int i = 0; i < NumOutputs(node); ++i) {\n-    SetTensorToDynamic(GetOutput(context, node, i));\n+    TfLiteTensor* tensor;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &tensor));\n+    SetTensorToDynamic(tensor);\n   }\n   return kTfLiteOk;\n }\n@@ -113,7 +115,8 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n   for (int i = 0; i < NumOutputs(node); ++i) {\n     TfLiteIntArray* output_dims = TfLiteIntArrayCopy(input->dims);\n     output_dims->data[axis_value] = size_splits_vector.at(i);\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_dims));\n   }\n \n@@ -133,7 +136,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                      input_type == kTfLiteInt16 || input_type == kTfLiteInt32 ||\n                      input_type == kTfLiteInt64 || input_type == kTfLiteInt8);\n   for (int i = 0; i < NumOutputs(node); ++i) {\n-    GetOutput(context, node, i)->type = input_type;\n+    TfLiteTensor* tensor;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &tensor));\n+    tensor->type = input_type;\n   }\n \n   auto size_splits = op_context.size_splits;"
    },
    "modified_file_70": {
        "mod_filename": "tensorflow/lite/kernels/squared_difference.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -60,9 +60,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n   output->type = input2->type;\n@@ -101,9 +107,15 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   ruy::profiler::ScopeLabel label(\"SquaredDifference\");\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type == kTfLiteFloat32) {\n     EvalSquaredDifference<float>(context, node, data, input1, input2, output);"
    },
    "modified_file_71": {
        "mod_filename": "tensorflow/lite/kernels/sub.cc",
        "status": "modified",
        "add_lines": 18,
        "dele_lines": 6,
        "patch": "@@ -217,9 +217,15 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n   output->type = input2->type;\n@@ -435,9 +441,15 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteSubParams*>(node->builtin_data);\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  const TfLiteTensor* input2;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor2, &input2));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32 ||\n       output->type == kTfLiteInt64) {"
    },
    "modified_file_72": {
        "mod_filename": "tensorflow/lite/kernels/svdf.cc",
        "status": "modified",
        "add_lines": 66,
        "dele_lines": 30,
        "patch": "@@ -82,11 +82,14 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n   TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* weights_feature =\n-      GetInput(context, node, kWeightsFeatureTensor);\n-  const TfLiteTensor* weights_time =\n-      GetInput(context, node, kWeightsTimeTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* weights_feature;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n+                                          &weights_feature));\n+  const TfLiteTensor* weights_time;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n \n   TF_LITE_ENSURE(context,\n                  input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n@@ -108,8 +111,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n   }\n \n-  const TfLiteTensor* state = GetInput(context, node, kStateTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* state;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Check the shape of input state tensors.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n@@ -143,7 +149,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   scratch_size_array->data[0] = batch_size;\n   scratch_size_array->data[1] = num_filters;\n \n-  TfLiteTensor* scratch_tensor = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* scratch_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n \n   // The scratch buffer is of type int32 for full integer svdf and it's of type\n   // float32 for hybrid and float case.\n@@ -161,7 +169,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Tell interpreter to allocate temporary tensors to store quantized values\n     // of input tensors.\n     node->temporaries->data[1] = scratch_tensor_index + 1;\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &input_quantized));\n     input_quantized->type = weights_feature->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -172,7 +182,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     // Tell interpreter to allocate temporary tensors to store scaling factors.\n     node->temporaries->data[2] = scratch_tensor_index + 2;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -186,7 +198,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Used to store dequantized weights_time matrix for hybrid computation of\n     // matmul(state, weights_time), which occurs in floating point.\n     node->temporaries->data[3] = scratch_tensor_index + 3;\n-    TfLiteTensor* float_weights_time = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* float_weights_time;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n+                                                &float_weights_time));\n     float_weights_time->type = kTfLiteFloat32;\n     // Persistent so that we can compute the dequantized weights only once.\n     float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n@@ -199,7 +213,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n \n     node->temporaries->data[4] = scratch_tensor_index + 4;\n-    TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n     zero_points->type = kTfLiteFloat32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -211,7 +227,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n \n     node->temporaries->data[5] = scratch_tensor_index + 5;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n     row_sums->type = kTfLiteFloat32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[1] = {num_filters};\n@@ -228,7 +246,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     output_temp_size_array->data[0] = num_units;\n     output_temp_size_array->data[1] = batch_size;\n     node->temporaries->data[1] = scratch_tensor_index + 1;\n-    TfLiteTensor* output_temp = GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* output_temp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n     output_temp->type = kTfLiteInt32;\n     output_temp->allocation_type = kTfLiteArenaRw;\n     TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n@@ -263,17 +283,24 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n   OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* weights_feature =\n-      GetInput(context, node, kWeightsFeatureTensor);\n-  const TfLiteTensor* weights_time =\n-      GetInput(context, node, kWeightsTimeTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* weights_feature;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n+                                          &weights_feature));\n+  const TfLiteTensor* weights_time;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n   const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n \n-  TfLiteTensor* scratch = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* scratch;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/0, &scratch));\n \n   TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (weights_feature->type) {\n     case kTfLiteFloat32: {\n@@ -286,14 +313,21 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n       if (input->type == kTfLiteFloat32) {\n-        TfLiteTensor* input_quantized =\n-            GetTemporary(context, node, /*index=*/1);\n-        TfLiteTensor* scaling_factors =\n-            GetTemporary(context, node, /*index=*/2);\n-        TfLiteTensor* float_weights_time =\n-            GetTemporary(context, node, /*index=*/3);\n-        TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n-        TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+        TfLiteTensor* input_quantized;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                    &input_quantized));\n+        TfLiteTensor* scaling_factors;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                    &scaling_factors));\n+        TfLiteTensor* float_weights_time;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n+                                                    &float_weights_time));\n+        TfLiteTensor* zero_points;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/4,\n+                                                    &zero_points));\n+        TfLiteTensor* row_sums;\n+        TF_LITE_ENSURE_OK(\n+            context, GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n         // Dequantize weights time.\n         // TODO(alanchiao): this dequantization initialization only needs to\n         // happen once per model and should theoretically be placed in either\n@@ -322,7 +356,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n             input->quantization.params);\n         auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n             output->quantization.params);\n-        TfLiteTensor* output_temp = GetTemporary(context, node, /*index=*/1);\n+        TfLiteTensor* output_temp;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                    &output_temp));\n \n         // Currently supports only ReLU.\n         // TODO(jianlijianli): support other activations."
    },
    "modified_file_73": {
        "mod_filename": "tensorflow/lite/kernels/tile.cc",
        "status": "modified",
        "add_lines": 24,
        "dele_lines": 9,
        "patch": "@@ -49,9 +49,14 @@ TfLiteIntArray* MultiplyShapeDims(const TfLiteIntArray& shape,\n }\n \n TfLiteStatus ResizeOutput(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* multipliers = GetInput(context, node, kInputMultipliers);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* multipliers;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputMultipliers, &multipliers));\n \n   const int num_dimensions = NumDimensions(input);\n   const int num_multipliers = NumElements(multipliers);\n@@ -208,12 +213,17 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n-  const TfLiteTensor* multipliers = GetInput(context, node, kInputMultipliers);\n+  const TfLiteTensor* multipliers;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputMultipliers, &multipliers));\n   // Only int32 and int64 multipliers type is supported.\n   if (multipliers->type != kTfLiteInt32 && multipliers->type != kTfLiteInt64) {\n     context->ReportError(context,\n@@ -231,9 +241,14 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n-  const TfLiteTensor* multipliers = GetInput(context, node, kInputMultipliers);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n+  const TfLiteTensor* multipliers;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kInputMultipliers, &multipliers));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context, ResizeOutput(context, node));"
    },
    "modified_file_74": {
        "mod_filename": "tensorflow/lite/kernels/topk_v2.cc",
        "status": "modified",
        "add_lines": 33,
        "dele_lines": 13,
        "patch": "@@ -35,14 +35,16 @@ constexpr int kOutputIndexes = 1;\n \n namespace {\n TfLiteStatus ResizeOutput(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* top_k = GetInput(context, node, kInputTopK);\n+  const TfLiteTensor* top_k;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTopK, &top_k));\n   // INT32 number of top results is supported.\n   TF_LITE_ENSURE_TYPES_EQ(context, top_k->type, kTfLiteInt32);\n   // Check that the tensor contains only one value.\n   TF_LITE_ENSURE_EQ(context, NumElements(top_k), 1);\n   const int32 k = *GetTensorData<int32_t>(top_k);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const int num_dimensions = NumDimensions(input);\n   // Check that input has one or more dimensions.\n   TF_LITE_ENSURE_MSG(context, input->dims->size >= 1,\n@@ -59,8 +61,12 @@ TfLiteStatus ResizeOutput(TfLiteContext* context, TfLiteNode* node) {\n   }\n   output_indexes_shape->data[num_dimensions - 1] = k;\n   output_values_shape->data[num_dimensions - 1] = k;\n-  TfLiteTensor* output_indexes = GetOutput(context, node, kOutputIndexes);\n-  TfLiteTensor* output_values = GetOutput(context, node, kOutputValues);\n+  TfLiteTensor* output_indexes;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputIndexes, &output_indexes));\n+  TfLiteTensor* output_values;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputValues, &output_values));\n   // Force output types.\n   output_indexes->type = kTfLiteInt32;\n   output_values->type = input->type;\n@@ -195,36 +201,50 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 2);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output_values = GetOutput(context, node, kOutputValues);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output_values;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputValues, &output_values));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output_values->type);\n \n-  const TfLiteTensor* top_k = GetInput(context, node, kInputTopK);\n+  const TfLiteTensor* top_k;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTopK, &top_k));\n   TF_LITE_ENSURE_TYPES_EQ(context, top_k->type, kTfLiteInt32);\n \n   // Set output dynamic if the input is not const.\n   if (IsConstantTensor(top_k)) {\n     TF_LITE_ENSURE_OK(context, ResizeOutput(context, node));\n   } else {\n-    TfLiteTensor* output_indexes = GetOutput(context, node, kOutputIndexes);\n-    TfLiteTensor* output_values = GetOutput(context, node, kOutputValues);\n+    TfLiteTensor* output_indexes;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kOutputIndexes, &output_indexes));\n+    TfLiteTensor* output_values;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kOutputValues, &output_values));\n     SetTensorToDynamic(output_indexes);\n     SetTensorToDynamic(output_values);\n   }\n   return kTfLiteOk;\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  TfLiteTensor* output_values = GetOutput(context, node, kOutputValues);\n-  TfLiteTensor* output_indexes = GetOutput(context, node, kOutputIndexes);\n+  TfLiteTensor* output_values;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputValues, &output_values));\n+  TfLiteTensor* output_indexes;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputIndexes, &output_indexes));\n   if (IsDynamicTensor(output_values)) {\n     TF_LITE_ENSURE_OK(context, ResizeOutput(context, node));\n   }\n-  const TfLiteTensor* top_k = GetInput(context, node, kInputTopK);\n+  const TfLiteTensor* top_k;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTopK, &top_k));\n   const int32 k = top_k->data.i32[0];\n   // The tensor can have more than 2 dimensions or even be a vector, the code\n   // anyway calls the internal dimension as row;\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const int32 row_size = input->dims->data[input->dims->size - 1];\n   int32 num_rows = 1;\n   for (int i = 0; i < input->dims->size - 1; ++i) {"
    },
    "modified_file_75": {
        "mod_filename": "tensorflow/lite/kernels/transpose_conv.cc",
        "status": "modified",
        "add_lines": 48,
        "dele_lines": 21,
        "patch": "@@ -250,13 +250,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n   // Retrieve tensors\n-  const TfLiteTensor* output_shape =\n-      GetInput(context, node, kOutputShapeTensor);\n-  const TfLiteTensor* weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kDataInputTensor);\n+  const TfLiteTensor* output_shape;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &weights));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kDataInputTensor, &input));\n   const TfLiteTensor* bias = nullptr;\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Tensor sanity checks\n   TF_LITE_ENSURE_EQ(context, NumDimensions(output_shape), 1);\n@@ -306,7 +313,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TfLiteTensor* col2im = nullptr;\n   if (data->has_col2im) {\n     node->temporaries->data[data->col2im_index] = data->col2im_id;\n-    col2im = GetTemporary(context, node, user_data->col2im_index);\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, user_data->col2im_index, &col2im));\n   }\n \n   if (!IsConstantTensor(output_shape)) {\n@@ -326,8 +335,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   if (data->weights_are_transposed) {\n     node->temporaries->data[data->transposed_weights_index] =\n         data->transposed_weights_id;\n-    TfLiteTensor* transposed_weights =\n-        GetTemporary(context, node, user_data->transposed_weights_index);\n+    TfLiteTensor* transposed_weights;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, user_data->transposed_weights_index,\n+                         &transposed_weights));\n     if (!IsConstantTensor(weights)) {\n       SetTensorToDynamic(transposed_weights);\n     } else {\n@@ -339,8 +351,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       input->type == kTfLiteInt16) {\n     node->temporaries->data[data->scratch_tensor_index] =\n         data->scratch_tensor_id;\n-    TfLiteTensor* scratch_buffer =\n-        GetTemporary(context, node, data->scratch_tensor_index);\n+    TfLiteTensor* scratch_buffer;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                  &scratch_buffer));\n     if (input->type == kTfLiteInt16) {\n       scratch_buffer->type = kTfLiteInt64;\n     } else {\n@@ -549,15 +563,22 @@ void EvalQuantizedPerChannel16x8(\n template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   // Retrieve tensors (All should be allocated by now)\n-  const TfLiteTensor* output_shape =\n-      GetInput(context, node, kOutputShapeTensor);\n-  const TfLiteTensor* weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kDataInputTensor);\n+  const TfLiteTensor* output_shape;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &weights));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kDataInputTensor, &input));\n   const TfLiteTensor* bias =\n       (NumInputs(node) == 4)\n           ? GetOptionalInputTensor(context, node, kBiasTensor)\n           : nullptr;\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   TfLiteTensor* col2im = data->has_col2im\n                              ? GetTemporary(context, node, data->col2im_index)\n@@ -604,8 +625,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       break;\n     }\n     case kTfLiteUInt8: {\n-      TfLiteTensor* scratch_buffer =\n-          GetTemporary(context, node, data->scratch_tensor_index);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                    &scratch_buffer));\n       if (IsDynamicTensor(scratch_buffer)) {\n         TF_LITE_ENSURE_OK(context,\n                           ResizeTensor(context, output_shape, scratch_buffer));\n@@ -621,8 +644,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       break;\n     }\n     case kTfLiteInt8: {\n-      TfLiteTensor* scratch_buffer =\n-          GetTemporary(context, node, data->scratch_tensor_index);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                    &scratch_buffer));\n       if (IsDynamicTensor(scratch_buffer)) {\n         TF_LITE_ENSURE_OK(context,\n                           ResizeTensor(context, output_shape, scratch_buffer));\n@@ -636,8 +661,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       break;\n     }\n     case kTfLiteInt16: {\n-      TfLiteTensor* scratch_buffer =\n-          GetTemporary(context, node, data->scratch_tensor_index);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                    &scratch_buffer));\n       if (IsDynamicTensor(scratch_buffer)) {\n         TF_LITE_ENSURE_OK(context,\n                           ResizeTensor(context, output_shape, scratch_buffer));"
    },
    "modified_file_76": {
        "mod_filename": "tensorflow/lite/kernels/unidirectional_sequence_lstm.cc",
        "status": "modified",
        "add_lines": 161,
        "dele_lines": 72,
        "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n #include \"tensorflow/lite/kernels/cpu_backend_context.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/internal/kernel_utils.h\"\n #include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n@@ -88,14 +89,19 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     TF_LITE_ENSURE_EQ(context, input_to_input_weights->dims->data[1], n_input);\n   }\n \n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, lstm::full::kInputToForgetWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n+                   &input_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[1], n_input);\n \n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, lstm::full::kInputToCellWeightsTensor);\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n+                                          lstm::full::kInputToCellWeightsTensor,\n+                                          &input_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[1], n_input);\n@@ -110,16 +116,22 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n                       n_output);\n   }\n \n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToForgetWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n+                   &recurrent_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[0],\n                     n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[1],\n                     n_output);\n \n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToCellWeightsTensor);\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n+                   &recurrent_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[1],\n@@ -176,18 +188,24 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     TF_LITE_ENSURE_EQ(context, input_gate_bias->dims->data[0], n_cell);\n   }\n \n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, lstm::full::kForgetGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kForgetGateBiasTensor,\n+                            &forget_gate_bias));\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->data[0], n_cell);\n \n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, lstm::full::kCellGateBiasTensor);\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, lstm::full::kCellGateBiasTensor,\n+                                 &cell_gate_bias));\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->data[0], n_cell);\n \n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, lstm::full::kOutputGateBiasTensor);\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kOutputGateBiasTensor,\n+                            &output_gate_bias));\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->data[0], n_cell);\n \n@@ -229,27 +247,33 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n                               kTfLiteFloat32);\n     }\n \n-    const TfLiteTensor* forget_layer_norm_coefficients =\n-        GetInput(context, node, lstm::full::kForgetLayerNormCoefficientsTensor);\n-    TF_LITE_ENSURE(context, forget_layer_norm_coefficients != nullptr);\n+    const TfLiteTensor* forget_layer_norm_coefficients;\n+    TF_LITE_ENSURE_OK(\n+        context, GetInputSafe(context, node,\n+                              lstm::full::kForgetLayerNormCoefficientsTensor,\n+                              &forget_layer_norm_coefficients));\n     TF_LITE_ENSURE_EQ(context, forget_layer_norm_coefficients->dims->size, 1);\n     TF_LITE_ENSURE_EQ(context, forget_layer_norm_coefficients->dims->data[0],\n                       n_cell);\n     TF_LITE_ENSURE_TYPES_EQ(context, forget_layer_norm_coefficients->type,\n                             kTfLiteFloat32);\n \n-    const TfLiteTensor* cell_layer_norm_coefficients =\n-        GetInput(context, node, lstm::full::kCellLayerNormCoefficientsTensor);\n-    TF_LITE_ENSURE(context, cell_layer_norm_coefficients != nullptr);\n+    const TfLiteTensor* cell_layer_norm_coefficients;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetInputSafe(context, node,\n+                                   lstm::full::kCellLayerNormCoefficientsTensor,\n+                                   &cell_layer_norm_coefficients));\n     TF_LITE_ENSURE_EQ(context, cell_layer_norm_coefficients->dims->size, 1);\n     TF_LITE_ENSURE_EQ(context, cell_layer_norm_coefficients->dims->data[0],\n                       n_cell);\n     TF_LITE_ENSURE_TYPES_EQ(context, cell_layer_norm_coefficients->type,\n                             kTfLiteFloat32);\n \n-    const TfLiteTensor* output_layer_norm_coefficients =\n-        GetInput(context, node, lstm::full::kOutputLayerNormCoefficientsTensor);\n-    TF_LITE_ENSURE(context, output_layer_norm_coefficients != nullptr);\n+    const TfLiteTensor* output_layer_norm_coefficients;\n+    TF_LITE_ENSURE_OK(\n+        context, GetInputSafe(context, node,\n+                              lstm::full::kOutputLayerNormCoefficientsTensor,\n+                              &output_layer_norm_coefficients));\n     TF_LITE_ENSURE_EQ(context, output_layer_norm_coefficients->dims->size, 1);\n     TF_LITE_ENSURE_EQ(context, output_layer_norm_coefficients->dims->data[0],\n                       n_cell);\n@@ -291,7 +315,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Inferring batch size, number of outputs and sequence length and\n   // number of cells from the input tensors.\n-  const TfLiteTensor* input = GetInput(context, node, lstm::full::kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n   TF_LITE_ENSURE(context, input->dims->size > 1);\n   const auto* params =\n@@ -301,14 +327,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   const int n_batch = time_major ? input->dims->data[1] : input->dims->data[0];\n   const int n_input = input->dims->data[2];\n \n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, lstm::full::kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n+                   &input_to_output_weights));\n   const int n_cell = input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[1], n_input);\n \n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n+                   &recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_output_weights->dims->data[0],\n                     n_cell);\n@@ -320,7 +352,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                n_cell, is_layer_norm_lstm));\n \n   // Get the pointer to output, output_state and cell_state buffer tensors.\n-  TfLiteTensor* output = GetOutput(context, node, lstm::full::kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                           lstm::full::kOutputTensor, &output));\n \n   TfLiteTensor* output_state =\n       GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n@@ -351,7 +385,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       scratch_tensor_index + kScratchBuffer;\n \n   // Create a scratch buffer tensor.\n-  TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);\n+  TfLiteTensor* scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScratchBuffer,\n+                                              &scratch_buffer));\n   scratch_buffer->type = input->type;\n   scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -376,8 +412,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // output_state and cell_state tensors.\n     node->temporaries->data[kInputQuantized] =\n         scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = input_to_output_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -387,8 +424,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateQuantized] =\n         scratch_tensor_index + kOutputStateQuantized;\n-    TfLiteTensor* output_state_quantized =\n-        GetTemporary(context, node, kOutputStateQuantized);\n+    TfLiteTensor* output_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateQuantized,\n+                                       &output_state_quantized));\n     output_state_quantized->type = input_to_output_weights->type;\n     output_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(output_state_quantized->dims,\n@@ -401,8 +440,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kCellStateQuantized] =\n         scratch_tensor_index + kCellStateQuantized;\n-    TfLiteTensor* cell_state_quantized =\n-        GetTemporary(context, node, kCellStateQuantized);\n+    TfLiteTensor* cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kCellStateQuantized,\n+                                       &cell_state_quantized));\n     cell_state_quantized->type = input_to_output_weights->type;\n     cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(cell_state_quantized->dims, cell_state->dims)) {\n@@ -420,7 +461,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // the scaling factor of the matrix).\n     node->temporaries->data[kInputScalingFactors] =\n         op_data->scratch_tensor_index + kInputScalingFactors;\n-    TfLiteTensor* input_sf = GetTemporary(context, node, kInputScalingFactors);\n+    TfLiteTensor* input_sf;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kInputScalingFactors, &input_sf));\n     input_sf->type = kTfLiteFloat32;\n     input_sf->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {n_batch};\n@@ -432,8 +476,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateScalingFactors] =\n         op_data->scratch_tensor_index + kOutputStateScalingFactors;\n-    TfLiteTensor* output_state_sf =\n-        GetTemporary(context, node, kOutputStateScalingFactors);\n+    TfLiteTensor* output_state_sf;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kOutputStateScalingFactors,\n+                                  &output_state_sf));\n     output_state_sf->type = kTfLiteFloat32;\n     output_state_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_sf->dims, 1, scaling_dims)) {\n@@ -444,8 +490,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kProductScalingFactors] =\n         scratch_tensor_index + kProductScalingFactors;\n-    TfLiteTensor* prod_scaling_factors =\n-        GetTemporary(context, node, kProductScalingFactors);\n+    TfLiteTensor* prod_scaling_factors;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kProductScalingFactors,\n+                                       &prod_scaling_factors));\n     prod_scaling_factors->type = kTfLiteFloat32;\n     prod_scaling_factors->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(prod_scaling_factors->dims, 1,\n@@ -461,8 +509,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // this is used for diagonal matrices, only need to store n_cell values.\n     node->temporaries->data[kRecoveredCellWeights] =\n         scratch_tensor_index + kRecoveredCellWeights;\n-    TfLiteTensor* recovered_cell_weights =\n-        GetTemporary(context, node, kRecoveredCellWeights);\n+    TfLiteTensor* recovered_cell_weights;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                       &recovered_cell_weights));\n     recovered_cell_weights->type = kTfLiteFloat32;\n     recovered_cell_weights->allocation_type = kTfLiteArenaRw;\n     int recovered_cell_dims[1] = {n_cell};\n@@ -478,7 +528,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate a temporary tensor to store the accumulated int32 values.\n     node->temporaries->data[kAccumScratch] =\n         scratch_tensor_index + kAccumScratch;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {n_cell, n_batch};\n@@ -492,7 +544,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kInputZeroPoints] =\n         op_data->scratch_tensor_index + kInputZeroPoints;\n-    TfLiteTensor* input_zp = GetTemporary(context, node, kInputZeroPoints);\n+    TfLiteTensor* input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kInputZeroPoints, &input_zp));\n     input_zp->type = kTfLiteFloat32;\n     input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_zp->dims, 1, scaling_dims)) {\n@@ -503,8 +557,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateZeroPoints] =\n         op_data->scratch_tensor_index + kOutputStateZeroPoints;\n-    TfLiteTensor* output_state_zp =\n-        GetTemporary(context, node, kOutputStateZeroPoints);\n+    TfLiteTensor* output_state_zp;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateZeroPoints,\n+                                       &output_state_zp));\n     output_state_zp->type = kTfLiteFloat32;\n     output_state_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_zp->dims, 1, scaling_dims)) {\n@@ -514,7 +570,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        output_state_zp_size));\n     }\n     node->temporaries->data[kRowSums] = scratch_tensor_index + kRowSums;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRowSums, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_rows = use_cifg ? 6 : 8;\n@@ -542,25 +600,44 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n   const bool is_layer_norm_lstm = op_data->is_layer_norm_lstm;\n   const bool time_major = params->time_major;\n-  const TfLiteTensor* input = GetInput(context, node, lstm::full::kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n \n   const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, lstm::full::kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, lstm::full::kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, lstm::full::kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n+                   &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n+                                          lstm::full::kInputToCellWeightsTensor,\n+                                          &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n+                   &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n+                   &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n+                   &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n+                   &recurrent_to_output_weights));\n \n   const TfLiteTensor* cell_to_input_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kCellToInputWeightsTensor);\n@@ -571,27 +648,35 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* input_gate_bias =\n       GetOptionalInputTensor(context, node, lstm::full::kInputGateBiasTensor);\n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, lstm::full::kForgetGateBiasTensor);\n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, lstm::full::kCellGateBiasTensor);\n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, lstm::full::kOutputGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kForgetGateBiasTensor,\n+                            &forget_gate_bias));\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, lstm::full::kCellGateBiasTensor,\n+                                 &cell_gate_bias));\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kOutputGateBiasTensor,\n+                            &output_gate_bias));\n \n   const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kProjectionWeightsTensor);\n   const TfLiteTensor* projection_bias =\n       GetOptionalInputTensor(context, node, lstm::full::kProjectionBiasTensor);\n \n   // Index the scratch buffers pointers to the global scratch buffer.\n-  TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);\n+  TfLiteTensor* scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScratchBuffer,\n+                                              &scratch_buffer));\n \n   TfLiteTensor* output_state =\n       GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n-  TF_LITE_ENSURE(context, output_state != nullptr);\n+  TFLITE_DCHECK(output_state != nullptr);\n   TfLiteTensor* cell_state =\n       GetVariableInput(context, node, lstm::full::kCellStateTensor);\n-  TF_LITE_ENSURE(context, cell_state != nullptr);\n+  TFLITE_DCHECK(cell_state != nullptr);\n \n   const TfLiteTensor* input_layer_norm_coefficients =\n       is_layer_norm_lstm\n@@ -614,7 +699,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                      lstm::full::kOutputLayerNormCoefficientsTensor)\n           : nullptr;\n \n-  TfLiteTensor* output = GetOutput(context, node, lstm::full::kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                           lstm::full::kOutputTensor, &output));\n \n   // Copy out the LSTM specific params so they can be passed in the function.\n   TfLiteLSTMParams lstm_params;\n@@ -647,7 +734,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n       OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n-      TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kRowSums, &row_sums));\n       const int row_sums_size = row_sums->dims->data[0];\n       return lstm_eval::EvalHybrid(\n           input, input_to_input_weights,"
    },
    "modified_file_77": {
        "mod_filename": "tensorflow/lite/kernels/unidirectional_sequence_rnn.cc",
        "status": "modified",
        "add_lines": 68,
        "dele_lines": 28,
        "patch": "@@ -61,13 +61,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* input_weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* recurrent_weights =\n-      GetInput(context, node, kRecurrentWeightsTensor);\n-  const TfLiteTensor* bias = GetInput(context, node, kBiasTensor);\n-  const TfLiteTensor* hidden_state =\n-      GetInput(context, node, kHiddenStateTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* input_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTensor, &input_weights));\n+  const TfLiteTensor* recurrent_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, kRecurrentWeightsTensor, &recurrent_weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n+  const TfLiteTensor* hidden_state;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kHiddenStateTensor, &hidden_state));\n \n   // Check all the parameters of tensor match within themselves and match the\n   // input configuration.\n@@ -92,7 +99,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, hidden_state->dims->data[0], batch_size);\n   TF_LITE_ENSURE_EQ(context, hidden_state->dims->data[1], num_units);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Resize output.\n   TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(3);\n@@ -112,7 +121,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     TfLiteIntArrayFree(node->temporaries);\n     node->temporaries = TfLiteIntArrayCreate(6);\n     node->temporaries->data[0] = op_data->scratch_tensor_index;\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/0);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n+                                                &input_quantized));\n     input_quantized->type = input_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -121,8 +132,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        input_quantized_size));\n     }\n     node->temporaries->data[1] = op_data->scratch_tensor_index + 1;\n-    TfLiteTensor* hidden_state_quantized =\n-        GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &hidden_state_quantized));\n     hidden_state_quantized->type = input_weights->type;\n     hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(hidden_state_quantized->dims,\n@@ -134,7 +146,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                               hidden_state_quantized_size));\n     }\n     node->temporaries->data[2] = op_data->scratch_tensor_index + 2;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -145,7 +159,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        scaling_factors_size));\n     }\n     node->temporaries->data[3] = op_data->scratch_tensor_index + 3;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/3, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {num_units, batch_size};\n@@ -158,7 +174,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        accum_scratch_size));\n     }\n     node->temporaries->data[4] = op_data->scratch_tensor_index + 4;\n-    TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n     zero_points->type = kTfLiteInt32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -169,7 +187,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        zero_points_size));\n     }\n     node->temporaries->data[5] = op_data->scratch_tensor_index + 5;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[2] = {2, num_units};\n@@ -335,15 +355,24 @@ TfLiteStatus EvalHybrid(\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteSequenceRNNParams*>(node->builtin_data);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* input_weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* recurrent_weights =\n-      GetInput(context, node, kRecurrentWeightsTensor);\n-  const TfLiteTensor* bias = GetInput(context, node, kBiasTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* input_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTensor, &input_weights));\n+  const TfLiteTensor* recurrent_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, kRecurrentWeightsTensor, &recurrent_weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n   // The hidden_state is a variable input tensor that can be modified.\n   TfLiteTensor* hidden_state =\n-      const_cast<TfLiteTensor*>(GetInput(context, node, kHiddenStateTensor));\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+      GetVariableInput(context, node, kHiddenStateTensor);\n+  TF_LITE_ENSURE(context, hidden_state != nullptr);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (input_weights->type) {\n     case kTfLiteFloat32:\n@@ -353,12 +382,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteInt8: {\n       // TODO(mirkov): implement eval with quantized inputs as well.\n       auto* op_data = reinterpret_cast<OpData*>(node->user_data);\n-      TfLiteTensor* input_quantized = GetTemporary(context, node, 0);\n-      TfLiteTensor* hidden_state_quantized = GetTemporary(context, node, 1);\n-      TfLiteTensor* scaling_factors = GetTemporary(context, node, 2);\n-      TfLiteTensor* accum_scratch = GetTemporary(context, node, 3);\n-      TfLiteTensor* zero_points = GetTemporary(context, node, 4);\n-      TfLiteTensor* row_sums = GetTemporary(context, node, 5);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 0, &input_quantized));\n+      TfLiteTensor* hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, 1, &hidden_state_quantized));\n+      TfLiteTensor* scaling_factors;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 2, &scaling_factors));\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 3, &accum_scratch));\n+      TfLiteTensor* zero_points;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 4, &zero_points));\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, 5, &row_sums));\n       return EvalHybrid(input, input_weights, recurrent_weights, bias, params,\n                         input_quantized, hidden_state_quantized,\n                         scaling_factors, hidden_state, output, zero_points,"
    },
    "modified_file_78": {
        "mod_filename": "tensorflow/lite/kernels/unique.cc",
        "status": "modified",
        "add_lines": 17,
        "dele_lines": 9,
        "patch": "@@ -44,11 +44,14 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 2);\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output_unique_tensor =\n-      GetOutput(context, node, kOutputUniqueTensor);\n-  TfLiteTensor* output_index_tensor =\n-      GetOutput(context, node, kOutputIndexTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output_unique_tensor;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kOutputUniqueTensor,\n+                                           &output_unique_tensor));\n+  TfLiteTensor* output_index_tensor;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kOutputIndexTensor,\n+                                           &output_index_tensor));\n \n   // The op only supports 1D input.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 1);\n@@ -70,7 +73,8 @@ TfLiteStatus EvalImpl(TfLiteContext* context, const TfLiteTensor* input,\n   // Note that we prefer to use map than unordered_map as it showed less\n   // increase in the binary size.\n   std::map<T, int> unique_values;\n-  TfLiteTensor* output_indexes = GetOutput(context, node, 1);\n+  TfLiteTensor* output_indexes;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 1, &output_indexes));\n   std::vector<T> output_values;\n   I* indexes = GetTensorData<I>(output_indexes);\n   const T* data = GetTensorData<T>(input);\n@@ -88,7 +92,8 @@ TfLiteStatus EvalImpl(TfLiteContext* context, const TfLiteTensor* input,\n     }\n   }\n   // Allocate output tensor.\n-  TfLiteTensor* unique_output = GetOutput(context, node, 0);\n+  TfLiteTensor* unique_output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &unique_output));\n   std::unique_ptr<TfLiteIntArray, void (*)(TfLiteIntArray*)> shape(\n       TfLiteIntArrayCreate(NumDimensions(input)), TfLiteIntArrayFree);\n   shape->data[0] = unique_values.size();\n@@ -127,8 +132,11 @@ TfLiteStatus EvalImpl(TfLiteContext* context, const TfLiteTensor* input,\n }  // namespace\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, 0);\n-  TfLiteTensor* output_index_tensor = GetOutput(context, node, 1);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+  TfLiteTensor* output_index_tensor;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, 1, &output_index_tensor));\n   TF_LITE_ENSURE_EQ(context, NumElements(output_index_tensor),\n                     NumElements(input));\n "
    },
    "modified_file_79": {
        "mod_filename": "tensorflow/lite/kernels/unpack.cc",
        "status": "modified",
        "add_lines": 6,
        "dele_lines": 3,
        "patch": "@@ -38,7 +38,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), data->num);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   TF_LITE_ENSURE(context, NumElements(input) > 0);\n   int axis = data->axis;\n   if (axis < 0) {\n@@ -67,7 +68,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, data->num, input_shape->data[axis]);\n   for (int i = 0; i < data->num; ++i) {\n     TfLiteIntArray* copied_output_shape = TfLiteIntArrayCopy(output_shape);\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     TF_LITE_ENSURE_TYPES_EQ(context, output->type, input->type);\n     // Guarantee input/output quantization params match as we do not support\n     // rescaling of unpacked quantized tensors.\n@@ -98,7 +100,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const TfLiteUnpackParams* data =\n       reinterpret_cast<TfLiteUnpackParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   switch (input->type) {\n     case kTfLiteFloat32: {\n       UnpackImpl<float>(context, node, input, data->num, data->axis);"
    },
    "modified_file_80": {
        "mod_filename": "tensorflow/lite/kernels/where.cc",
        "status": "modified",
        "add_lines": 12,
        "dele_lines": 6,
        "patch": "@@ -56,9 +56,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* cond_tensor =\n-      GetInput(context, node, kInputConditionTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* cond_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputConditionTensor,\n+                                          &cond_tensor));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (cond_tensor->type != kTfLiteBool) {\n     context->ReportError(context,\n@@ -81,9 +84,12 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* cond_tensor =\n-      GetInput(context, node, kInputConditionTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* cond_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputConditionTensor,\n+                                          &cond_tensor));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   if (IsDynamicTensor(output)) {\n     TF_LITE_ENSURE_OK(context,"
    },
    "modified_file_81": {
        "mod_filename": "tensorflow/lite/kernels/while.cc",
        "status": "modified",
        "add_lines": 2,
        "dele_lines": 1,
        "patch": "@@ -195,7 +195,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n   }\n   for (int i = 0; i < num_inputs; ++i) {\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     if (op_data->body_has_dynamic_output_tensors) {\n       SetTensorToDynamic(output);\n     } else {"
    },
    "modified_file_82": {
        "mod_filename": "tensorflow/lite/kernels/zeros_like.cc",
        "status": "modified",
        "add_lines": 10,
        "dele_lines": 4,
        "patch": "@@ -32,17 +32,23 @@ constexpr int kOutputTensor = 0;\n TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = input->type;\n \n   return context->ResizeTensor(context, output,\n                                TfLiteIntArrayCopy(input->dims));\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   const int num_elements = NumElements(input);\n   switch (input->type) {\n     case kTfLiteInt64:"
    }
}