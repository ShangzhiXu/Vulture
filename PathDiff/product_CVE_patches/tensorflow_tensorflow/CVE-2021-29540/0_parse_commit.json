{
    "current_hash": "c570e2ecfc822941335ad48f6e10df4e21f11c96",
    "parent_hash": "1b0296c3b8dd9bd948f924aa8cd62f87dbb7c3da",
    "modified_file_0": {
        "mod_filename": "tensorflow/core/kernels/conv_grad_filter_ops.cc",
        "status": "modified",
        "add_lines": 13,
        "dele_lines": 0,
        "patch": "@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     // The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n "
    }
}