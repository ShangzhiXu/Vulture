{
    "current_hash": "953f28dca13c92839ba389c055587cfe6c723578",
    "parent_hash": "801c1c6be5324219689c98e1bd3e0ca365ee834d",
    "modified_file_0": {
        "mod_filename": "tensorflow/lite/kernels/maximum_minimum.cc",
        "status": "modified",
        "add_lines": 31,
        "dele_lines": 29,
        "patch": "@@ -157,35 +157,37 @@ template <KernelType kernel_type, typename OpType>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpContext op_context(context, node);\n \n-    switch (op_context.output->type) {\n-      case kTfLiteFloat32:\n-        TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\n-        break;\n-      case kTfLiteUInt8:\n-        TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt8:\n-        TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\n-        break;\n-      case kTfLiteInt32:\n-        TFLiteOperation<kernel_type, int32_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt64:\n-        TFLiteOperation<kernel_type, int64_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt16:\n-        TFLiteOperation<kernel_type, int16_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      default:\n-        context->ReportError(context,\n-                             \"Type %d is currently not supported by Maximum.\",\n-                             op_context.output->type);\n-        return kTfLiteError;\n-    }\n+  // If inputs have no element, shortcircuit.\n+  if (NumElements(op_context.input1) == 0 ||\n+      NumElements(op_context.input2) == 0) {\n+    return kTfLiteOk;\n+  }\n+\n+  switch (op_context.output->type) {\n+    case kTfLiteFloat32:\n+      TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteUInt8:\n+      TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt8:\n+      TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt32:\n+      TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt64:\n+      TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt16:\n+      TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);\n+      break;\n+    default:\n+      context->ReportError(context,\n+                           \"Type %d is currently not supported by Maximum.\",\n+                           op_context.output->type);\n+      return kTfLiteError;\n+  }\n   return kTfLiteOk;\n }\n "
    }
}